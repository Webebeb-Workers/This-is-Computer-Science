# 네트워크의 큰 그림

> [!NOTE]
> 노드와 간선으로 구성된 시스템, 컴퓨팅 장치들이 정보를 교환할 수 있게 해주는 통신 인프라

![](https://github.com/user-attachments/assets/1e6d3aa8-f773-4954-861c-09466c9ddaec)

이렇게 전개될 예정임.

## 네트워크의 기본 구조

<img width="600" alt="image" src="https://github.com/user-attachments/assets/dac5dc02-38c1-4a10-922b-b16c8a9ba2f2" />

네트워크는 **노드(장치)와 간선(연결)으로 구성된 그래프 형태의 자료구조**임. 데이터 교환을 위한 물리적, 논리적 경로를 제공하는 특성 제공.

### 네트워크 토폴로지

> [!NOTE]
> 네트워크 노드와 링크의 물리적/논리적 배치 방식, 각 방식은 고유한 장단점 보유

#### 주요 네트워크 토폴로지 유형

<img width="600" alt="image" src="https://github.com/user-attachments/assets/9604fd5e-cfa2-4c16-a7f2-6c7d3db9f21b" />

~~검색한 내용 추가로 작성~~

- **버스형**: 모든 노드가 하나의 전송 매체에 연결된 구조, 구현 간단하나 충돌 발생 가능성 존재
- **링형**: 각 노드가 양옆의 두 노드와만 연결된 원형 구조, 데이터 흐름 방향 예측 용이
- **성형**: 중앙 노드를 중심으로 다른 모든 노드가 연결된 구조, 중앙 장애 시 전체 네트워크 마비 위험
- **망형**: 모든 노드가 서로 직접 연결된 구조, 높은 신뢰성과 중복성 제공
- **트리형**: 계층적 구조로 노드 관리 효율적, 상위 계층 장애 시 하위 노드 통신 불가 단점

### 호스트 & 중간 노드

**네트워크에서 정보를 송수신하는 최종 장치**를 호스트라 부름. 클라이언트와 서버는 정보 요청/응답 역할에 따른 호스트 구분임.

- **클라이언트**: 정보나 서비스를 요청하는 호스트
- **서버**: 정보나 서비스를 제공하는 호스트

이러한 호스트 간 데이터 전송을 지원하는 중간 노드로 스위치, 라우터, 게이트웨이 등이 존재함.

## 네트워크의 규모와 분류: LAN & WAN

> [!NOTE]
>
> 1. **LAN**(Local Area Network): 제한된 지역 내 네트워크
> 2. **WAN**(Wide Area Network): 지리적으로 넓은 지역을 연결하는 네트워크

<img width="600" alt="image" src="https://github.com/user-attachments/assets/b174c389-c50e-4a35-a609-bb96a3eb3754" />

- **LAN**
  - 제한된 지리적 영역(건물, 캠퍼스) 내 구성
  - 높은 데이터 전송 속도 제공
  - 단일 조직의 관리하에 운영되는 특징
- **WAN**
  - 도시, 국가, 대륙 간 연결 제공
  - KT, SKT 등 ISP(인터넷 서비스 제공업체)에 의해 관리
  - 상대적으로 낮은 속도와 높은 지연시간 특성
  - 다양한 기술(광섬유, 위성 등) 활용

## 패킷 교환 네트워크

> [!NOTE]
> 데이터를 작은 단위(패킷)로 분할해 전송하고 목적지에서 재조립하는 통신 방식

### 패킷 구조/특징

패킷은 헤더, 페이로드, 트레일러로 구성된 기본 데이터 전송 단위임. 헤더에는 주소와 제어 정보, 페이로드에는 실제 전송할 데이터, 트레일러에는 오류 검출 정보가 포함됨.

<img width="600" alt="image" src="https://github.com/user-attachments/assets/405c475c-d702-46a8-8953-59fdb2a5f7e3" />

- **헤더**: 송수신 주소, 프로토콜 정보, 순서 번호 등 포함
- **페이로드**: 실제 전송하고자 하는 데이터 저장
- **트레일러**: 오류 검출 코드와 종료 표시 정보 포함

패킷 교환 방식을 채택한 이유는 '데이터를 쪼갤 수 있어서'임.

- **네트워크 자원의 효율적 활용**: 단일 링크를 여러 통신이 공유 가능
- **내결함성 향상**: 개별 패킷이 다른 경로로 우회 가능해 장애 상황에서도 통신 지속
- **비용 효율성**: 회선 교환 방식 대비 낮은 인프라 비용 실현

## 주소 체계 & 전송 방식

#### 네트워크 주소의 필요성

> [!NOTE]
> 네트워크 주소는 통신을 위한 장치 식별자로, IP 주소와 MAC 주소가 가장 대표적인 주소 체계임

네트워크에서 통신을 위해 장치들은 고유한 주소를 가져야 함. IP 주소는 네트워크 계층에서, MAC 주소는 데이터 링크 계층에서 사용되는 특성.

### 주요 전송 방식

이러한 네트워크 주소에 대한 수신자들의 유형을 정해 패킷을 보낼 수 있음.

<img width="600" alt="image" src="https://github.com/user-attachments/assets/628d7e42-2909-41a2-a621-3dd9f5991e95" />

- **유니캐스트**: 단일 송신자와 단일 수신자 간 일대일 통신 방식
- **브로드캐스트**: 네트워크 내 모든 호스트에게 데이터를 전송하는 일대다 방식
- **멀티캐스트**: 특정 그룹에 속한 호스트들에게만 데이터를 전송하는 방식
- **애니캐스트**: 동일 그룹 내 가장 가까운 호스트에게 데이터를 전송하는 방식

## 패킷 통신 과정

네트워크 내의 호스트는 서로가 주고받을 내용인 패킷을 이해할 수 있어야함. 그를 위해 정해놓은 규칙/약속이 있음.

### 프로토콜의 역할과 종류

> [!NOTE]
> 네트워크 통신을 위한 규칙과 절차의 집합, 데이터 교환을 표준화 및 호환성을 제공

주요 프로토콜들은 각각 고유한 목적과 특징을 가짐. HTTP는 웹 통신, TCP는 신뢰성 있는 데이터 전송, IP는 네트워크 간 라우팅을 담당하는 등의 역할 수행.

- **TCP/IP**: 인터넷의 기본 통신 프로토콜
- **HTTP/HTTPS**: 웹 페이지 접근을 위한 프로토콜
- **DHCP**: 자동 IP 주소 할당 프로토콜
- **DNS**: 도메인 이름을 IP 주소로 변환하는 프로토콜

등이 있음. 각각 고유한 역할이 있는 것으로 보임.

### 네트워크 참조 모델

> [!NOTE]
> 네트워크 통신 과정을 계층적으로 분리해 각 계층의 역할과 책임을 명확히 정의하는 추상화 방식

계층적 접근은 네트워크 설계와 문제 해결을 단순화하고, 서로 다른 시스템 간 호환성을 보장하는 이점 제공.

<img width="600" alt="image" src="https://github.com/user-attachments/assets/c6f9c2fc-77f0-4e83-8424-b8438918bd58" />

이러한 추상화 단계는 추후 OSI 모델, TCP/IP 모델로 그릴 수 있음.

## 네트워크 참조 모델 & 계층화 시스템

<img width="600" alt="image" src="https://github.com/user-attachments/assets/70161dc9-cdc4-427b-8628-b4c063228398" />

### OSI 모델(7계층)

> [!NOTE]
> OSI 모델은 국제 표준화 기구에서 정의한 네트워크 통신 과정을 7개 계층으로 분리한 개념적 모델

- **물리 계층**: 비트 신호 전송, 전기적/물리적 특성 정의
- **데이터 링크 계층**: 인접 노드 간 통신, MAC 주소 사용, 오류 검출
- **네트워크 계층**: 서로 다른 네트워크 간 통신 담당, IP 주소 사용, 라우팅
- **전송 계층**: 신뢰성 있는 종단간 통신 보장, 포트 번호 사용
- **세션 계층**: 통신 세션 설정/유지/종료 관리
- **표현 계층**: 데이터 형식 변환, 암호화, 압축 처리
- **응용 계층**: 사용자 인터페이스 제공, 네트워크 서비스 접근점

### TCP/IP 모델(4계층)

> [!NOTE]
> 실제 인터넷에서 사용되는 프로토콜 구현 중심 모델로, OSI 모델보다 단순화된 구조

- **네트워크 액세스 계층**: OSI의 물리, 데이터 링크 계층에 해당
- **인터넷 계층**: OSI의 네트워크 계층에 해당, IP 프로토콜 사용
- **전송 계층**: OSI의 전송 계층과 동일, TCP/UDP 프로토콜 사용
- **응용 계층**: OSI의 세션, 표현, 응용 계층을 통합

### 캡슐화와 역캡슐화

> [!NOTE]
>
> - 캡슐화: 상위 계층에서 하위 계층으로 데이터가 전달될 때 각 계층에서 헤더를 추가하는 과정
> - 역캡슐화: 수신 시 이를 역순으로 처리하는 과정

<img width="600" alt="image" src="https://github.com/user-attachments/assets/c002378d-ec33-4db9-91d2-e5a5906eedbc" />

#### 계층별 데이터 단위 명칭

- **응용 계층**: 데이터 또는 메시지
- **전송 계층**: 세그먼트(TCP) 또는 데이터그램(UDP)
- **네트워크 계층**: 패킷 또는 데이터그램
- **데이터 링크 계층**: 프레임
- **물리 계층**: 비트 또는 심볼

## 학습 예정 내용

### 물리 계층과 데이터 링크 계층

- 이더넷
- (물리 계층) 유무선 통신 매체
- (데이터 링크 계층) 이더넷 프레임
- 다양한 네트워크 장비
  - NIC
  - 허브
  - 스위치

### 네트워크 계층

- IP의 목적과 특징
- IP 주소의 구조
  - 클래스풀 주소 체계
  - 클래스리스 주소 체계와 서브넷 마스크
- IP 주소의 종류: 공인 IP 주소와 사설 IP 주소
- IP의 할당
  - 정적 할당
  - 동적 할당: DHCP
- ICMP
- ARP

### 전송 계층

- TCP
  - TCP의 목적과 특징
  - TCP의 연결 수립과 종료
  - TCP의 오류・흐름・혼잡 제어
  - TCP의 상태 관리
- UDP
  - UDP의 목적과 특징

### 응용 계층

- DNS
- URI/URL
- HTTP
  - HTTP 메시지 구조
  - HTTP 메소드
  - HTTP 상태 코드
  - HTTP 헤더
- HTTP 기반 기술
  - 쿠키
  - 캐시
  - 콘텐츠 협상
- HTTPS
- TLS/SSL

---

# 6. 응용 계층 - HTTP의 응용

HTTP 응용 기술은 기본 통신 메커니즘을 넘어 상태 관리, 캐싱, 보안 등 다양한 웹 서비스 구현을 가능하게 함.

## 쿠키

> [!NOTE]
> 서버에서 생성돼 클라이언트 측에 저장되는 <이름, 값> 쌍 형태의 데이터 <br>
> HTTP의 Stateless 특성을 보완하는 수단

### 쿠키의 기본 동작

- 서버가 응답 메시지의 `Set-Cookie` 헤더로 쿠키 생성해 클라이언트에 전송
- 클라이언트는 쿠키를 저장했다가 동일 서버에 요청 시 `Cookie` 헤더로 포함
- 브라우저에서 개발자 도구의 Application > Storage > Cookies에서 확인 가능

### 쿠키 속성

- **도메인과 경로 제한**: 특정 도메인과 경로에서만 쿠키 사용 가능
  ```
  Set-Cookie: name=minchul; domain=minchul.net
  Set-Cookie: name=minchul; path=/lectures
  ```
- **유효기간 설정**
  ```
  Set-Cookie: sessionID=abc123; Expires=Fri, 23 Aug 2024 09:00:00 GMT
  Set-Cookie: sessionID=abc123; Max-Age=2592000
  ```
- **보안 속성**
  - `Secure`: HTTPS를 통해서만 쿠키 송수신
  - `HttpOnly`: 자바스크립트를 통한 쿠키 접근 제한

> [!TIP]
> 쿠키와 유사하지만 서버로 자동 전송되지 않는 웹 스토리지(로컬 스토리지, 세션 스토리지)도 클라이언트 상태 관리에 활용 가능

## 캐시

2장의 메모리 캐싱과 비슷한 개념임.

> [!NOTE]
> 응답받은 자원의 사본을 임시 저장해 불필요한 대역폭 낭비와 응답 지연을 방지하는 기술

<img width="600" alt="image" src="https://github.com/user-attachments/assets/82de997c-ee65-4949-ba89-6f5e91d11b96" />

### 캐시 작동 원리

- 클라이언트가 서버로부터 자원을 받아 임시 저장
- 동일 자원 재요청 시 저장된 사본 활용으로 네트워크 부하 감소 및 응답 속도 향상
- 개인 전용 캐시(private cache)와 공용 캐시(public cache)로 구분

### 캐시 유효기간과 신선도

- **유효기간 설정**
  ```
  Expires: Tue, 06 Feb 2024 12:00:00 GMT
  Cache-Control: max-age=1200
  ```
- **신선도 검사 메커니즘**
  1. 날짜 기반 검사: `If-Modified-Since` 헤더 활용
     ```
     If-Modified-Since: Fri, 23 Aug 2024 09:00:00 GMT
     ```
  2. 엔티티 태그 기반 검사: `If-None-Match` 헤더와 `ETag` 활용
     ```
     If-None-Match: "abc"
     ```

### 서버 응답 패턴

1. **자원 변경 시**: `200 OK`와 함께 새 자원 반환
2. **자원 미변경 시**: `304 Not Modified`로 캐시 재사용 지시
3. **자원 삭제 시**: `404 Not Found` 반환

## 콘텐츠 협상

'표현' 계층, 표현이란 '송수신 가능한 자원의 형태'

> [!NOTE]
> 같은 자원에 대해 여러 표현이 있을 때, 클라이언트의 선호도에 따라 가장 적합한 자원 표현을 제공하는 기술

### 콘텐츠 협상 헤더

- `Accept`: 선호하는 미디어 타입 명시
- `Accept-Language`: 선호하는 언어 명시
- `Accept-Encoding`: 선호하는 인코딩 방식 명시

### 선호도 표현 방식

```
Accept-Language: ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7
Accept: text/html,application/xml;q=0.9,text/plain;q=0.6,*/*;q=0.5
```

- `q`: Quality Value로 0~1 사이 값(기본값 1), 값이 클수록 우선순위 높음

## 보안: SSL/TLS와 HTTPS

> [!NOTE]
> HTTPS는 HTTP에 SSL/TLS 프로토콜을 추가한 보안 강화 프로토콜<br>
> 인증과 암호화 기능 제공

### HTTPS 통신 과정

1. TCP 쓰리웨이 핸드셰이크
2. TLS 핸드셰이크
   - HTTP와 HTTPS의 핵심 차이점
   - 인증 및 암호화 키 교환 수행
3. 암호화된 메시지 송수신

### TLS 핸드셰이크 핵심 요소

<img width="600" alt="image" src="https://github.com/user-attachments/assets/8245bdc6-e862-4c6b-9f08-56b55c6c3e94" />

1. **암호화 통신을 위한 키 교환**
   - `ClientHello`: 지원 TLS 버전, 암호화 알고리즘, 해시 함수, 클라이언트 난수 제시
   - `ServerHello`: 선택된 TLS 버전, 암호 스위트, 서버 난수 응답
   - 암호 스위트: `TLS_AES_128_GCM_SHA256`와 같은 형태로 암호화 알고리즘과 해시 함수 조합 명시
2. **인증서 송수신과 검증**
   - `Certificate`: CA가 발급한 서버의 인증서 전송
   - `CertificateVerify`: 인증서의 유효성 증명을 위한 서명 검증
   - 인증 기관(CA): 제3자로서 서버의 신원을 보증하는 공인 기관
   - 브라우저는 인증서 뷰어를 통해 인증서 정보 확인 가능
3. **핸드셰이크 완료**
   - `Finished` 메시지로 핸드셰이크 과정 마무리
   - 이후 모든 통신은 협의된 키로 암호화돼 전송
   - TLS 1.3에서는 `Finished` 메시지와 함께 암호화된 애플리케이션 데이터 전송 가능

> [!TIP]
> TLS 1.3은 이전 버전보다 핸드셰이크 과정이 간소화돼 성능이 향상됐고, 중간자 공격에 대한 방어 등 보안성도 강화됨<br>
> 추가로 1.3은 Finished 메시지와 함께 암호화된 메시지(Application Data)를 보낼 수 있음

# 프록시와 안정적인 트래픽

실제 네트워크 환경에서 클라이언트와 서버는 직접 연결되지 않고, 다양한 중간 서버와 네트워크 장비를 통해 통신함.

## 오리진 서버와 중간 서버: 프록시 배치 구조 이해

<img width="600" alt="image" src="https://github.com/user-attachments/assets/2ae30a14-b224-4a72-8d1a-c32af25bbc1e" />

위 사진처럼 오리진 서버와 클라이언트 사이에 중간 서버가 위치함. 중간 서버의 대표격으로 '프록시'가 있음.

### 오리진 서버

> [!NOTE]
> 자원을 생성하고 클라이언트에게 권한이 있는 응답을 보낼 수 있는 HTTP 서버

- **권한 있는 응답 생성**: 자원을 직접 생성하고 관리하는 최종 서버
- **다중화된 배치**: 고가용성을 위해 여러 대의 서버로 구성되는 것이 일반적
- **중간 서버와의 구분**: 클라이언트 요청이 최종적으로 도달하는 목적지

### 포워드 프록시

- **역할과 위치**: 클라이언트의 대리자로서 오리진 서버보다 클라이언트에 가까이 위치
- **주요 기능**
  - 캐시 저장을 통한 성능 향상
  - 클라이언트 IP 주소 은폐
  - 접근 제어 및 콘텐츠 필터링
- **클라이언트 선택성**: 클라이언트가 어떤 프록시를 사용할지 직접 결정

### 게이트웨이, 리버스 프록시

- **역할과 위치**: 오리진 서버의 대리자로서 클라이언트보다 오리진 서버에 가까이 위치
- **주요 기능**
  - **리버스 프록시**
    - 오리진 서버의 대리자로서 동작
    - 클라이언트가 직접 서버에 접근하지 않도록 중개
    - 동일한 프로토콜(대개 HTTP) 내에서 통신 처리
    - 로드 밸런싱, 캐싱, 보안 기능 제공
  - **게이트웨이**
    - 서로 다른 프로토콜 간의 변환 처리
    - HTTP 요청을 다른 형식(데이터베이스 쿼리, 레거시 시스템 프로토콜 등)으로 변환
    - 이기종 시스템 간의 통합 지원
- **투명성**: 클라이언트는 리버스 프록시를 오리진 서버로 인식

걍 둘이 기능이 비슷함.

> [!TIP]
> 실무에서는 프록시와 게이트웨이의 경계가 모호해지는 경우가 많음, 프록시가 비-HTTP 서비스와 연결되면 게이트웨이의 역할을 수행하게 됨

## 고가용성: 안정적인 서비스 제공 전략

### 가용성이란

> [!NOTE]
> 시스템이 정상적으로 기능을 수행할 수 있는 시간의 비율

- **계산식**: 가용성 = 업타임 / (업타임 + 다운타임)
- **표현 방식**: '9'의 개수로 표현 (99.9%=3개, 99.99%=4개, 99.999%=5개)
- **주요 목표 수준**
  - <img width="600" alt="image" src="https://github.com/user-attachments/assets/7a2c8886-3948-4b90-bbf2-973e92023be6" />

### 결함 감내(Fault Tolerance)

- **정의**: 문제가 발생하더라도 계속 기능할 수 있는 시스템 능력
- **구현 방식**: 주로 서버 다중화와 부하 분산 전략 활용
- **페일오버**: 시스템 장애 발생 시 예비 시스템으로 자동 전환되는 기능

#### 헬스 체크 & 하트비트

- **헬스 체크**: 로드 밸런서가 서버의 정상 작동 여부를 주기적으로 검사
- **하트비트**: 서버 간 주기적 메시지 교환으로 상태 확인
- **탐지 방식**: HTTP, ICMP 등 다양한 프로토콜 활용 가능

<img width="450" alt="image" src="https://github.com/user-attachments/assets/31dd6de3-6399-42a0-ad71-d44970a25172" />

## 로드 밸런싱: 트래픽 분산 기술

<img width="600" alt="image" src="https://github.com/user-attachments/assets/04f2b42c-fd65-4b26-b429-dbca1dd22409" />

### 로드 밸런서의 역할

- **트래픽 분배**: 다중화된 서버 간에 요청을 균등하게 분산
- **구현 방식**: 하드웨어(L4/L7 스위치) 또는 소프트웨어(HAProxy, Nginx, Envoy) 형태로 구현
- **배치 위치**: 클라이언트와 서버 사이에 위치하여 중개 역할 수행

### 주요 로드 밸런싱 알고리즘

- **라운드 로빈**: 요청을 순차적으로 각 서버에 분배
  - 프로세스 스케쥴링에서 본 듯..
- **최소 연결**: 활성 연결이 가장 적은 서버에 요청 분배
- **IP 해시**: 클라이언트 IP 주소를 기반으로 일관된 서버 선택
- **가중치 기반**: 서버 성능에 따라 차등적으로 트래픽 분배
- **응답 시간**: 응답 속도가 가장 빠른 서버 우선 선택

### 가중치 기반 트래픽 분산

위 알고리즘은 서버 스펙이 다 같다는 전제 하에 있음. 하지만 서버 스펙이 다르다면 가중치를 고려한 알고리즘을 써야함.

<img width="600" alt="image" src="https://github.com/user-attachments/assets/b99a4455-c908-4cdd-851d-3c070abf6339" />

- **불균등 서버 환경**: 서버 성능이 다를 경우 균등 분배는 비효율적
- **가중치 적용**: 성능이 좋은 서버에 더 높은 가중치 부여
- **실제 구현**: 대부분의 로드 밸런서는 가중치 알고리즘 지원

## 스케일링: 시스템 확장 전략

스케일 업, 스케일 아웃, 오토스케일링이 있다.

### 스케일 업(수직적 확장)

<img width="600" alt="image" src="https://github.com/user-attachments/assets/793b293f-4ea9-45a8-a925-a637e6eb04c4" />

- **방식**: 기존 장비를 더 높은 사양으로 업그레이드
- **장점**
  - 설치와 구성이 단순함
  - 관리가 용이함
- **단점**
  - 확장 한계가 명확함
  - 단일 장애점 위험 존재
  - 비용 효율성이 떨어질 수 있음

### 스케일 아웃(수평적 확장)

<img width="600" alt="image" src="https://github.com/user-attachments/assets/57a152cd-7132-4ff3-be0c-3a195936a748" />

- **방식**: 동일한 기능을 수행하는 서버 수를 증가
- **장점**
  - 유연한 확장 및 축소 가능
  - 결함 감내 능력 향상
  - 점진적 투자 가능
- **단점**
  - 설치와 구성이 상대적으로 복잡함
  - 세션 관리 및 데이터 일관성 유지 어려움

### 오토스케일링

> [!NOTE]
> 트래픽 양에 따라 자동으로 시스템 규모를 조절하는 기능 <br>
> 클라우드 환경에서 특히 유용함

- **동작 원리**: 시스템 부하나 트래픽 양에 따라 자동으로 서버 증감
- **경제적 이점**: 필요한 시점에만 자원을 추가하여 비용 최적화
- **적용 대상**: 특정 시점 트래픽 급증(티켓팅, 수강신청) 또는 주기적 부하 변동(성수기/비수기) 상황에 적합

## Nginx를 활용한 로드 밸런싱 구현

### Nginx 설정 구조

- **주요 설정 파일**: `/etc/nginx/nginx.conf`(기본 설정)
- **확장 설정 디렉토리**: `/etc/nginx/conf.d/` 디렉토리의 `.conf` 파일
- **로그 저장 위치**: `/var/log/nginx/` 디렉토리
  - access log: 웹 서버가 수신한 개별 요청 관련 로그는 `'/var/1og/nginx/access.log'`에 남김
  - error log: 웹 서버와 관련한 오류 발생 시 오류 관련 로그는 `/war/log/nginx/errorlog'`에 남김

### 로드 밸런싱 설정 예시

```nginx
upstream backend {
    server 10.10.10.2:80 weight=1;    # 첫 번째 서버, 가중치 1
    server 10.10.10.3:80 weight=2;    # 두 번째 서버, 첫 번째 서버보다 2배 많은 트래픽 수신
    server 10.10.10.4:80 backup;      # 백업 서버, 다른 서버에 문제 발생 시에만 사용
}

server {
    listen 80;                        # 80번 포트에서 요청 수신
    server_name localhost;            # 서버 이름 설정

    location / {                      # 루트 경로(/)에 대한 설정
        proxy_pass http://backend;    # 요청을 'backend' 서버 그룹으로 전달
    }
}
```

- `upstream backend { ... }` : 로드 밸런싱할 서버 그룹 정의
- `weight=숫자` : 서버의 상대적 처리 비중 지정(기본값 1)
- `backup` : 주 서버에 문제 발생 시 사용할 예비 서버 지정
- `location /` : 루트 경로에 대한 요청 처리 규칙 정의
- `proxy_pass` : 지정된 서버 그룹으로 요청을 전달하는 지시자

### 로드 밸런싱 알고리즘 지정

```nginx
upstream backend {
    least_conn;                       # 최소 연결 알고리즘 지정
    server 10.10.10.2:80 weight=1;    # 첫 번째 서버, 가중치 1
    server 10.10.10.3:80 weight=2;    # 두 번째 서버, 첫 번째 서버보다 2배 많은 트래픽 수신
    server 10.10.10.4:80 backup;      # 백업 서버, 다른 서버에 문제 발생 시에만 사용
}
```

**알고리즘 옵션**은 아래와 같다.

- 라운드 로빈: 기본값(명시적 지정 불필요)
- `least_conn`: 최소 연결 알고리즘
- `ip_hash`: IP 기반 해시 알고리즘
- `random`: 무작위 선택 알고리즘

> [!NOTE] > **업스트림/다운스트림과 인바운드/아웃바운드 개념 구분**
>
> <img width="600" alt="image" src="https://github.com/user-attachments/assets/827318dd-c1e3-498a-b40d-393fb8d64f89" />
>
> - 업스트림: 클라이언트에서 오리진 서버로 향하는 데이터 방향
> - 다운스트림: 오리진 서버에서 클라이언트로 향하는 데이터 방향
> - 인바운드: 네트워크 외부에서 내부로 들어오는 트래픽
> - 아웃바운드: 네트워크 내부에서 외부로 나가는 트래픽
