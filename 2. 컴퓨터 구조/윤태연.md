# 1절. 컴퓨터 구조의 큰 그림

<img width="600" alt="image" src="https://github.com/user-attachments/assets/b37812b8-0f23-42a6-bf83-d2879cd1e5c8" />

## 컴퓨터가 이해하는 정보

컴퓨터는 프로그래밍 언어를 직접 이해하지 못하고, 데이터와 명령어라는 두 가지 형태의 **0과 1**로 이루어진 정보만 이해함.

- **데이터**
  - 숫자, 문자, 이미지, 동영상과 같은 정적인 정보로 명령의 대상이자 재료
  - 있는 그대로의 정보
- **명령어**
  - 데이터를 활용해 실행하는 정보로 수행할 동작을 지정
  - '더하라', '출력하라', '저장하라'와 같은 형태로 구성

## 컴퓨터의 핵심 부품

<img width="600" alt="image" src="https://github.com/user-attachments/assets/d0906159-76e8-4113-827d-9f4f84167ce8" />

### CPU (중앙처리장치)

데이터와 명령어를 읽고, 해석하고, 실행하는 핵심 부품으로 컴퓨터의 두뇌 역할을 담당함. 다음과 같은 구성 요소를 포함함.

<img width="600" alt="image" src="https://github.com/user-attachments/assets/85eb2246-59b1-4b70-af39-4275c2d3650a" />

- **산술논리연산장치(ALU)**: 사칙 연산, 논리 연산 등 연산을 수행하는 회로로 구성된 **계산기** 역할 담당
- **제어장치(CU)**: 명령어를 해석해 제어 신호를 내보내는 장치로 다른 부품을 작동시키는 전기 신호를 생성
- **레지스터**
  - CPU 내부의 작은 임시 저장장치로 데이터와 명령어 처리 과정의 값 저장
  - 여러 개의 레지스터가 각각 다른 역할을 수행
  - **CPU의 가장 중요한 구성 요소**
  - 얘만 봐도 프로그램이 어떻게 실행되는지 로우레벨에서 파악 가능

### 메모리(주기억장치)

> [!NOTE]
> 현재 실행 중인 프로그램을 구성하는 데이터와 명령어를 저장하는 부품 <br />
> CPU가 직접 접근 가능

<img width="600" alt="image" src="https://github.com/user-attachments/assets/901efafb-9078-4af7-9686-fafebf14fe03" />

#### 주요 특성

- **RAM(Random Access Memory)**: 일반적으로 메모리라고 부름, 주로 휘발성 특징을 가짐
- **ROM(Read Only Memory)**: 읽기 전용 메모리, 일부 중요 정보 저장에 사용
- **주소**: CPU가 원하는 정보에 빠르게 접근하기 위한 위치 식별자, 메모리의 정돈된 정보 관리에 필수적
- **휘발성**: 전원이 공급되지 않을 때 저장된 정보가 모두 지워지는 특성

#### 캐시 메모리

CPU가 조금이라도 더 빠르게 메모리에 저장된 값에 접근하기 위한 보조 저장장치임. CPU와 메모리 사이에 위치.

CPU 내부에 있기도 하고 외부에 있기도 하며, 여러 종류(L1, L2, L3 등)가 있음.

### 보조기억장치

> [!NOTE]
> 전원이 꺼져도 저장된 정보가 사라지지 않는 비휘발성 저장장치 <br />
> 메모리를 보조하는 역할 수행

<img width="600" alt="image" src="https://github.com/user-attachments/assets/53b48a03-4166-4649-aeae-e1428196332e" />

- **주요 종류**
  - **하드 디스크 드라이브(HDD)**: 자기 디스크 기반 저장장치
  - **SSD(Solid State Drive)**: 플래시 메모리 기반 저장장치, 빠른 접근 속도를 제공
  - **기타**: CD-ROM, DVD, USB 메모리, SD 카드 등
- **특징**: 보관할 프로그램 저장 및 프로그램 실행 시 해당 내용을 메모리로 복사해야 CPU가 처리 가능
- **RAID**: 안전하고 안정적으로 보조기억장치를 구성하는 기술로 중요 데이터 보호에 활용

### 입출력장치

컴퓨터 외부에 연결돼 내부와 정보를 교환하는 장치로 다음과 같이 구분됨.

- **입력장치**: 마우스, 키보드, 마이크 등 컴퓨터에 정보를 입력하는 장치
- **출력장치**: 모니터, 스피커, 프린터 등 컴퓨터의 정보를 받아 출력하는 장치

참고: 보조기억장치와 입출력장치는 완전히 배타적인 개념이 아니며, 보조기억장치는 메모리를 보조하는, 특별한 형태의 입출력장치로 볼 수 있음.
이들을 통틀어 주변장치라고 부르기도 함.

### 메인보드 & 버스

- **메인보드(마더보드)**: 컴퓨터 핵심 부품들을 고정하고 연결하는 기판으로 여러 부품을 연결할 수 있는 슬롯과 단자들이 있는 기판 형태
- **버스**
  - 부품들이 정보를 주고받는 통로, 버스의 종류는 다양함
  - 특히 **시스템 버스**는 CPU, 메모리 등 핵심 부품들을 연결하는 중요한 통로

<img width="600" alt="image" src="https://github.com/user-attachments/assets/af22c627-06ea-495c-a6bd-20c58c28695d" />

## 저장장치의 계층 구조

> [!NOTE]
> CPU와 가까운 저장장치는 빠르고 용량이 작으며 가격이 비싼 특성을 가지고, 멀어질수록 속도는 느려지지만 용량이 커지고 가격이 저렴해짐

<img width="600" alt="Image" src="https://github.com/user-attachments/assets/a8d053c0-8e95-4284-bcdb-4a0d1f5630af" />

- **계층 순서**: 레지스터 → 캐시 메모리(L1, L2, L3) → 메모리 → 보조기억장치 순으로 CPU와의 거리 증가
- **특성**: 각 계층별 저장장치는 속도, 용량, 가격 측면에서 서로 다른 장단점을 가지므로 모두 함께 사용하는 것이 효율적

참고: 저장장치 계층 구조는 얼마든 추가할 수 있으니 상위-하위 계층에 대해 어떤 특징들이 있는지 대략적으로 숙지하도록!

#### 마무리

<img width="600" alt="image" src="https://github.com/user-attachments/assets/b370bd91-76cc-4301-9734-a96953fd39ea" />

---

# 2절. 컴퓨터가 이해하는 정보

0과 1만을 이해하는 컴퓨터가 어떻게 문자와 숫자를 인식하는지, 그리고 그렇게 표 현된 정적인 데이터가 명령어에 의해 어떻게 실행되는지 학습.

## 0과 1로 이루어진 정보

> [!NOTE]
> 컴퓨터는 0과 1만을 이해할 수 있으며, 이러한 이진 정보를 통해 모든 데이터와 명령어를 표현함

- **비트(bit)**
  - 0과 1을 나타내는 가장 작은 정보 단위
  - N비트는 2^N개의 정보 표현 가능
- **바이트(byte)**
  - 8비트를 묶은 단위
  - 2^8=256개의 정보 표현이 가능
- **워드(word)**
  - CPU가 한 번에 처리할 수 있는 데이터 크기
  - 일반적으로 32비트 또는 64비트

#### 정보 용량 단위

| 단위   | 크기            |
| ------ | --------------- |
| 1 byte | 8비트           |
| 1 KB   | 1,000바이트     |
| 1 MB   | 1,000킬로바이트 |
| 1 GB   | 1,000메가바이트 |
| 1 TB   | 1,000기가바이트 |

## 데이터 - 0과 1로 숫자 표현하기

### 2진법 & 16진법

- **2진법**
  - 숫자 1을 넘어가는 시점에 자리올림, 0과 1로만 모든 수를 표현
  - 표기법: 숫자 뒤 `(2)` 또는 `0b` 접두사 사용
- **16진법**
  - 2진수 표현의 길이가 길어지는 단점을 보완하기 위해 사용, 10~15는 A~F로 표현
  - 표기법: `(16)` 또는 `0x` 접두사를.사용함.
- **활용 사례**: 16진법 사용
  - MAC 주소(A1:C2:E3:A5:C6:E7)
  - IPv6 주소(2001:0a1b:1234:0000:0000:abcd:1234:ff02)

> `그래서 컴퓨터가 이해하는 정보를 표현할 때는 2진수와 더불어 16진수도 함께 사용합니다.` <br />
> 16진수를 먹일 수 있는 컴퓨터는 어떤 종류일까요? CPU도 16진수를 이해할 수 있을까요?

### 소수 표현 방식

컴퓨터에서 소수 표현 시 발생하는 오차는 부동소수점 방식의 정밀도 한계에서 비롯함.

```py
a = 0.1
b = 0.2
c = 0.3

if a + b== c:
  print("Equal")
else:
  print("Not Equal")
```

결과는 `'Not Equal'`.. 왜 이럴까?

- **부동소수점**: 소수점이 고정되지 않은 표현 방식
  - `가수 × 기수^지수` 형태로 표현
- **정규화**: 가수의 정수부를 1로 통일(1.XXX 형태)해 저장 효율을 높임
- **저장 방식**: 지수부에는 바이어스(2^(k-1)-1) 값이 더해지고, 가수부에는 소수 부분만 저장됨.
- **오차 발생 원인**: 10진수 소수를 2진수로 정확히 표현할 수 없는 경우가 있어 근사값 사용으로 발생함.
- **IEEE 754 저장 형식**
  - 32비트(단정밀도): 1비트(부호) + 8비트(지수) + 23비트(가수)
  - 64비트(배정밀도): 1비트(부호) + 11비트(지수) + 52비트(가수)

[유튜브 참고](https://youtu.be/-GsrYvZoAdA?si=5yflXIGnH0AZg-Bf)

## 데이터 - 0과 1로 문자 표현하기

> [!NOTE]
> 문자 집합은 컴퓨터가 이해할 수 있는 문자들의 모음이며, 이를 0과 1로 변환하는 과정이 문자 인코딩

### 문자 인코딩/디코딩

- **문자 인코딩**: 문자를 컴퓨터가 이해하는 0과 1로 이루어진 코드로 변환하는 과정
- **문자 디코딩**: 0과 1로 표현된 문자 코드를 사람이 이해하는 문자로 변환하는 과정
- **코드 포인트**: 문자 인코딩에서 글자에 부여된 고유한 값

### 주요 문자 집합과 인코딩

- **아스키(ASCII)**: 영어 알파벳, 숫자, 일부 특수문자를 포함한 128개 문자를 7비트로 표현함
- **EUC-KR**: 한글을 지원하는 인코딩으로, 아스키는 1바이트, 한글은 2바이트로 표현하며 약 2,350개의 한글만 표현 가능
- **유니코드**: 전 세계 대부분의 문자를 통일된 방식으로 표현하는 표준으로, 다양한 인코딩 방식(UTF-8, UTF-16, UTF-32)을 사용

#### 참고: 자주 쓰는 아스키 코드

주요 ASCII 코드 (문자 및 숫자)는 아래와 같음. (정처기 대비)

|  문자   | ASCII (10진수) | ASCII (16진수) | 설명     |
| :-----: | :------------: | :------------: | -------- |
| **'0'** |     **48**     |      0x30      | 숫자 0   |
|   '1'   |       49       |      0x31      | 숫자 1   |
|   '2'   |       50       |      0x32      | 숫자 2   |
|   '3'   |       51       |      0x33      | 숫자 3   |
|   '4'   |       52       |      0x34      | 숫자 4   |
|   '5'   |       53       |      0x35      | 숫자 5   |
|   '6'   |       54       |      0x36      | 숫자 6   |
|   '7'   |       55       |      0x37      | 숫자 7   |
|   '8'   |       56       |      0x38      | 숫자 8   |
|   '9'   |       57       |      0x39      | 숫자 9   |
| **'A'** |     **65**     |      0x41      | 대문자 A |
|   'B'   |       66       |      0x42      | 대문자 B |
|   'C'   |       67       |      0x43      | 대문자 C |
|   'D'   |       68       |      0x44      | 대문자 D |
|   'E'   |       69       |      0x45      | 대문자 E |
|   'F'   |       70       |      0x46      | 대문자 F |
| **'a'** |     **97**     |      0x61      | 소문자 a |
|   'b'   |       98       |      0x62      | 소문자 b |
|   'c'   |       99       |      0x63      | 소문자 c |
|   'd'   |      100       |      0x64      | 소문자 d |
|   'e'   |      101       |      0x65      | 소문자 e |

**제어 문자 (Control Characters)**도 좀 나온다.

| 이름 | ASCII (10진수) | ASCII (16진수) | 설명            |
| :--: | :------------: | :------------: | --------------- |
| NUL  |       0        |      \x00      | Null 문자       |
| SOH  |       1        |      \x01      | Start of Header |
| STX  |       2        |      \x02      | Start of Text   |
| ETX  |       3        |      \x03      | End of Text     |

### Base64 인코딩

- 문자뿐만 아니라 이진 데이터까지 아스키 문자 형태로 표현할 수 있는 인코딩 방식임.
- 64진법을 사용하므로 6비트씩 나누어 하나의 문자로 변환함.
- 6비트씩 나누어 떨어지지 않는 경우 0으로 패딩하고 '='로 표시함.
- 이메일 첨부파일, 웹에서 이미지 데이터 전송 등에 활용됨.

## 명령어

> [!NOTE]
> 명령어는 컴퓨터가 수행할 동작(연산 코드)과 대상(오퍼랜드)으로 구성된 CPU가 이해하는 지시사항임

### 명령어의 구성

- **연산 코드(Opcode)**: 명령어가 수행할 동작을 지정하는 부분
- **오퍼랜드(Operand)**: 연산에 사용될 데이터 또는 데이터가 저장된 위치를 명시하는 부분
  - 데이터 자체(예: 10, 100)
  - 데이터 위치(예: 메모리 32번지, 레지스터 이름)

### 주요 연산 코드 유형

- **데이터 전송**: MOVE, STORE, LOAD, PUSH, POP 등
- **산술/논리 연산**: ADD, SUBTRACT, MULTIPLY, DIVIDE, AND, OR, NOT 등
- **제어 흐름 변경**: JUMP, CONDITIONAL JUMP, HALT, CALL, RETURN 등
- **입출력 제어**: READ, WRITE, START IO, TEST IO 등

### 기계어와 어셈블리어

- **기계어**: 0과 1로 표현된 CPU가 직접 이해하는 언어
- **어셈블리어**: 기계어를 사람이 읽기 쉬운 형태로 변환한 저수준 언어
- **특징**: 같은 프로그램이라도 CPU 아키텍처에 따라 다른 형태의 기계어와 어셈블리어로 표현됨(예: CISC와 RISC 기반 CPU)

### 명령어 사이클

- **인출 사이클**: 메모리에서 명령어를 CPU로 가져오는 단계
- **실행 사이클**: 인출한 명령어를 해석하고 실행하는 단계
- **간접 사이클**: 명령어 실행을 위해 메모리에 추가로 접근하는 단계(오퍼랜드 필드에 메모리 주소가 있을 경우)
- **인터럽트 사이클**: CPU 작업을 중단하고 인터럽트를 처리하는 단계

---

# 3절. CPU의 작동 원리

## 레지스터

> [!NOTE]
> CPU 내부에 존재하는 임시 저장 장치, 프로그램 실행에 필요한 데이터와 명령어를 저장하는 공간

### 주요 레지스터 종류 & 기능

#### 프로그램 카운터(명령어 포인터)

> [!NOTE]
> PC - Program Counter, 메모리에서 다음으로 읽어 들일 **명령어의 주소를 저장**하는 레지스터 <br />
> 보통 1씩 증가하며 프로그램이 **순차적으로 실행**함

메모리에 저장된 프로그램의 순차적 실행이 가능한 이유는 프로그램 카운터 값이 1씩 증가하기 때문임.
이때, 조건문의 참이나 리턴문처럼 순차적으로 실행되지 않을 수도 있는데 그때는 임의의 위치로 변경됨.

#### 명령어 레지스터

> [!NOTE]
> IR - Instruction Register, 메모리에서 읽어 들인, **해석할 명령어**를 저장하는 레지스터

CPU의 제어장치는 이 레지스터의 명령어를 해석해 **ALU 연산 지시**나 다른 부품으로 제어 신호를 보내 해당 부품을 작동시킴. 명령어 해석과 실행의 **시작점 역할**을 함.

#### 범용 레지스터

> [!NOTE]
> 다양하고 일반적인 상황에서 자유롭게 사용할 수 있는 레지스터

데이터, 명령어, 주소 모두를 저장할 수 있으며 일반적으로 CPU 내에 여러 개가 존재함. 연산 중간 결과나 자주 사용되는 값을 임시 저장하는 데 활용됨.

#### 플래그 레지스터

> [!NOTE]
> 연산 결과나 CPU 상태에 대한 부가 정보를 비트 단위로 저장하는 레지스터 <br />
> 각 비트는 특정 상태를 나타내는 플래그로 사용됨

- **부호 플래그**: 연산 결과의 부호 표시(1=음수, 0=양수)
- **제로 플래그**: 연산 결과가 0인지 표시(1=0, 0=0이 아님)
- **캐리 플래그**: 자리올림이나 빌림수 발생 여부 표시(1=발생, 0=미발생)
- **오버플로우 플래그**: 오버플로우 발생 여부 표시(1=발생, 0=미발생)
- **인터럽트 플래그**: 인터럽트 허용 여부 표시(1=가능, 0=불가능)
- **슈퍼바이저 플래그**: 커널/사용자 모드 구분(1=커널모드, 0=사용자모드)

이러한 플래그들은 조건분기 명령어에서 분기 여부를 결정하거나, CPU의 특수 상태를 관리하는 데 중요한 역할을 함.

#### 스택 포인터

> [!NOTE]
> 메모리 내 **스택** 영역의 최상단 **스택 데이터 위치**를 가리키는 특별한 레지스터

스택에서 데이터를 꺼내면(`pop`) 그 아래 데이터의 주소를 가리키게 되고, 데이터를 넣으면(`push`) 새로 넣은 데이터의 주소를 가리키게 됨.

> 스택은 프로그램 실행 중 임시 데이터를 저장하는 중요한 메모리 영역으로, 함수 호출 시 활성화 레코드(activation record)를 저장하는 데 주로 사용됨.

<img width="600" alt="image" src="https://github.com/user-attachments/assets/b572279a-3fd2-4a82-8eaa-2f02b0ea2dca" />

위 사진을 보면, 스택 포인터가 가리키고 있는 모습을 볼 수 있음. 이후에 `스택 데이터 3`을 꺼내오면 `스택 데이터 2`로 가리키게 될 것임.

함수 호출 시 반환 주소 저장, 지역 변수 관리 등에 스택이 활용되므로 스택 포인터는 **프로그램 실행 흐름(컨텍스트) 관리에 핵심적 역할**을 함.

## 인터럽트

> [!NOTE]
> CPU의 작업을 **방해**하는 신호로, CPU가 수행 중인 작업은 방해를 받아 잠시 중단됨 <br />
> 인터럽트는 **CPU의 효율적인 작업 처리와 예외 상황 대응에 필수**적인 메커니즘

인터럽트는 '방해하다, 중단시키다'라는 의미를 가지며, CPU가 현재 수행 중인 작업을 일시적으로 중단하고 다른 중요한 작업을 처리할 수 있게 하는 메커니즘임. 이는 컴퓨터 구조와 운영체제 이해에 핵심적인 개념임.

### 인터럽트의 종류

<img width="600" alt="image" src="https://github.com/user-attachments/assets/4967b686-b9c4-4441-aa4d-cacf836e7d85" />

#### 동기 인터럽트(예외)

> [!NOTE]
> CPU에 의해 발생하는 인터럽트 <br />
> 명령어 실행 과정에서 CPU 자신이 감지한 예외적 상황에서 발생

주로 프로그램 오류나 예상치 못한 상황에 대응하기 위해 사용된다.

- **0으로 나누기**: 산술 연산 중 0으로 나누려는 시도 발생 시
- **잘못된 메모리 접근**: 권한이 없는 메모리 영역이나 존재하지 않는 메모리 주소 접근 시
- **명령어 실행 오류**: 잘못된 형식의 명령어 실행 시도 시
- **페이지 폴트**: 필요한 메모리 페이지가 물리 메모리에 없어 가져와야 할 때

다시 말해, 동기 인터럽트는 현재 **실행 중인 명령어와 '동기화'돼 발생**하므로 동기 인터럽트라고 불림.
즉, 특정 명령어 실행의 직접적인 결과로 발생함.

#### 비동기 인터럽트(하드웨어 인터럽트)

> [!NOTE]
> CPU 외부, 주로 입출력장치에 의해 발생하는 인터럽트 <br />
> CPU의 현재 실행 흐름과 무관하게 비동기적으로 발생

마치 CPU에게 알림 역할을 함. 아래와 같은 상황에서 사용됨.

- **입출력 작업 완료 알림**: 프린터의 인쇄 완료, 디스크 읽기/쓰기 작업 완료 등
- **입력 장치 신호**: 키보드 키 입력, 마우스 클릭, 터치스크린 터치 등
- **타이머 만료 알림**: 일정 시간 경과 후 알림(운영체제의 시분할 처리에 중요)
- **하드웨어 오류 신호**: 전원 문제, 메모리 패리티 오류 등

하드웨어 인터럽트는 CPU가 다른 작업을 처리하는 동안 입출력 작업이 **병렬적으로 진행**될 수 있게 해 시스템 효율성을 크게 향상시킴.
이는 **폴링**(polling) 방식(CPU가 주기적으로 장치 상태 확인)과 대비되는 방식으로, 이 방식보다 인터럽트 방식을 사용함으로써 **CPU 시간을 절약**함.

> 일반적으로 '인터럽트'을 지칭하는 것이 이 `비동기 인터럽트 = 하드웨어 인터럽트`다. 하지만 책에서는 혼동을 방지하기 위해 자체 용어를 사용했다.

### 하드웨어 인터럽트 처리 과정

위에서 말했듯이, 하드웨어 인터럽트 처리는 CPU가 효율적으로 작동하기 위한 핵심 메커니즘이다.
그런데, 입출력장치의 속도는 CPU에 비해 현저히 느리기 때문에, 인터럽트 없이는 CPU가 입출력 완료를 기다리며 시간을 낭비하게 됨.
이를 핸들링하기 위한 인터럽트 처리 과정은 다음과 같음.

1. **인터럽트 요청 발생**: 입출력장치가 CPU에 인터럽트 요청 신호를 보냄
2. **현재 명령어 완료**: CPU는 현재 실행 중인 명령어를 완료함
3. **인터럽트 플래그 확인**: CPU는 플래그 레지스터의 인터럽트 플래그를 확인해 인터럽트 수용 가능 여부 결정
4. **현재 상태 백업**: 프로그램 카운터값 등 현재 프로그램 상태를 스택에 저장
5. **인터럽트 벡터 참조**: 인터럽트 요청 장치에서 제공한 인터럽트 벡터를 통해 적절한 인터럽트 서비스 루틴 위치 확인
6. **인터럽트 서비스 루틴 실행**: 해당 인터럽트에 대응하는 처리 프로그램 실행
7. **상태 복원 및 복귀**: 저장해둔 프로그램 상태를 복원하고 원래 프로그램으로 제어 반환

#### 인터럽트 요청 신호

> [!NOTE]
> 입출력장치가 **CPU에게 인터럽트의 가능 여부를 확인하는 신호**

이 신호는 CPU가 현재 수행 중인 **작업을 중단할 준비**가 돼 있는지 확인하는 첫 단계임. 인터럽트 요청은 주로 CPU의 특정 핀(인터럽트 요청 라인)을 통해 전달됨.

#### 인터럽트 플래그

위에서 얘기했듯이, CPU의 플래그 레지스터 내에 인터럽트 플래그가 있다.

> [!NOTE]
> 하드웨어 인터럽트를 받아들일지 무시할지를 결정 <br />
> 인터럽트 플래그가 활성화(1)돼 있으면 인터럽트를 수용하고, 비활성화(0)돼 있으면 무시

모든 하드웨어 인터럽트를 인터럽트 플래그로 제어할 수 있는 것은 아님. 특히 중요한 인터럽트(NMI)는 인터럽트 플래그 상태와 관계없이 처리됨.

- **막을 수 있는 인터럽트(Maskable Interrupt)**: 인터럽트 플래그로 제어 가능한 **일반적인** 인터럽트
- **막을 수 없는 인터럽트(Non-Maskable Interrupt)**: 정전이나 하드웨어 고장과 같은 심각한 상황에서 발생하는, 플래그와 무관하게 처리되는 **높은 우선순위** 인터럽트

#### 인터럽트 서비스 루틴(인터럽트 핸들러)

> [!NOTE]
> 특정 인터럽트가 발생했을 때 이를 처리하기 위한 프로그램

간단히 얘기해서, 인터럽트 서비스 루틴(ISR)은 '인터럽트가 발생하면 어떻게 행동해야 할지'를 알려 주는 프로그램이다.

이 프로그램은 각 메모리마다, 각 인터럽트 유형마다 별도의 서비스 루틴이 존재하고, 메모리에 저장돼 있음. 인터럽트 서비스 루틴은 아래와 같은 작업을 수행함.

- 인터럽트 원인 파악
- 필요한 데이터 처리 수행
- 입출력 장치와의 통신
- 오류 처리 및 복구
- 작업 완료 후 원래 프로그램으로 제어 반환

<img width="600" alt="image" src="https://github.com/user-attachments/assets/7bc39a7e-0548-40fb-9beb-9b5c40b28937" />

**ISR**은 **일반 함수**와 유사하게 작동하지만, **특별한 상황(인터럽트 발생)에 의해 호출된다는 차이**가 있음. 또한 ISR은 최소한의 작업만 수행하고 빠르게 반환하도록 설계되는 것이 일반적임.

#### 인터럽트 벡터

> [!NOTE]
> 인터럽트 서비스 루틴을 식별하기 위한 정보, 해당 루틴의 시작 주소 포함함 <br />
> CPU는 인터럽트 요청 장치로부터 인터럽트 벡터를 전달받아 적절한 서비스 루틴을 찾아 실행함

<img width="600" alt="image" src="https://github.com/user-attachments/assets/a0dd75ad-070f-4296-9e17-20a03c2219ef" />

시스템에는 **여러 인터럽트 서비스 루틴이 존재**하므로, 인터럽트 벡터는 각 인터럽트 유형에 대응하는 정확한 루틴을 찾기 위한 **인덱스 역할**을 함.
인터럽트 벡터 테이블(Interrupt Vector Table)은 이러한 벡터들의 모음으로, 메모리의 특정 영역에 저장됨.

#### 인터럽트 사이클 재설명

위에서 서술한, CPU의 완전한 명령어 처리 과정은 다음과 같은 사이클의 반복으로 이루어짐.

1. **인출 사이클(Fetch Cycle)**: 메모리에서 명령어를 가져옴
2. **실행 사이클(Execute Cycle)**: 가져온 명령어를 해석하고 실행함
3. **간접 사이클(Indirect Cycle)**: 필요한 경우 메모리 추가 접근(주로 간접 주소 지정)
4. **인터럽트 사이클(Interrupt Cycle)**: 인터럽트 발생 여부 확인 및 처리

<img width="600" alt="image" src="https://github.com/user-attachments/assets/30f96c7a-acde-4f0b-8730-6a801d1b4f47" />

> 참고: 인터럽트 사이클은 매 명령어 실행 사이클의 마지막에 수행되며, 인터럽트 요청이 있을 경우 이를 처리하기 위한 과정을 시작함.

이러한 구조로 인해 CPU는 명령어 실행과 인터럽트 처리를 효율적으로 조화시킬 수 있음.

### 예외의 세부 유형

동기 인터럽트(예외)는 그 처리 방식과 결과에 따라 종류가 나뉘어짐.

<img width="600" alt="image" src="https://github.com/user-attachments/assets/d912e229-c4ce-4148-b5c0-606ca8ecd4f5" />

**예외가 발생한 명령어부터** 실행? vs **예외가 발생한 명령어 다음부터** 실행?

#### 폴트(Fault)

> [!NOTE]
> 예외 처리 후 **예외가 발생한 명령어부터 실행**을 재개하는 예외 유형 <br />
> 명령어 실행 중 문제가 발생했지만, 문제 해결 후 같은 명령어를 **다시 실행**하면 **정상적으로 진행**될 수 있는 상황에서 사용됨

<img width="600" alt="image" src="https://github.com/user-attachments/assets/d61e06cb-7806-47d4-b3b4-83844ad6c5dc" />

대표적인 예는 페이지 폴트(Page Fault)로, 다음과 같은 과정으로 처리됨.

1. CPU가 메모리 접근 명령어 실행 시도
2. 필요한 데이터가 메모리에 없고 보조기억장치에 있음을 확인
3. 폴트 발생, 운영체제의 페이지 폴트 핸들러 실행
4. 운영체제가 보조기억장치에서 필요한 데이터를 메모리로 로드
5. 원래 명령어(폴트가 발생한 명령어)부터 실행 재개

폴트는 '**수정 가능한 오류**'로, 오류의 원인을 제거한 후 같은 명령어를 다시 실행함으로써 정상적인 프로그램 흐름을 계속할 수 있음.

#### 트랩(Trap)

> [!NOTE]
> 예외 처리 후 **예외가 발생한 명령어의 다음 명령어부터 실행**을 재개하는 예외 유형 <br />
> 예외 발생이 **예상**되었거나 **의도적**인 경우에 주로 사용됨

트랩 내에, 소프트웨어 인터럽트도 있다. 대표적인 예는 **디버깅 브레이크포인트**와 **시스템 콜**임.

- **브레이크포인트**: 디버깅 중 프로그램 실행을 특정 지점에서 일시 중단
  1. 디버거가 특정 명령어를 브레이크포인트 명령어로 변경
  2. CPU가 브레이크포인트 명령어 실행 시 트랩 발생
  3. 디버깅 작업 완료 후 원래 명령어의 다음 명령어부터 실행 재개
- **시스템 콜**: 사용자 프로그램이 운영체제 서비스를 요청할 때 사용
  1. 프로그램이 시스템 콜 명령어 실행
  2. 트랩 발생, 운영체제 커널로 제어 전환
  3. 운영체제가 요청된 서비스 수행
  4. 시스템 콜 다음 명령어부터 사용자 프로그램 실행 재개

트랩은 '**예상된 이벤트**'로, 명령어가 이미 성공적으로 실행되었으므로 다음 명령어부터 계속함.

#### 중단(Abort)

> [!NOTE]
> CPU가 실행 중인 **프로그램을 강제로 중단**시킬 수밖에 없는 심각한 오류 발견 시 발생하는 예외 <br />
> 일반적으로 프로그램 실행을 계속할 수 없는 **치명적 오류 상황**에서 발생함

- 하드웨어 고장 감지
- 심각한 메모리 손상 발견
- 복구 불가능한 시스템 오류

중단은 일반적으로 현재 실행 중인 프로그램을 종료시키고, 때로는 시스템 재시작이나 덤프 파일 생성 등의 추가 조치가 필요함.

## CPU 성능 향상 설계

클럭과 코어, 스레드 등 CPU의 성능 향상과 관련된 주요 개념 및 설계 기법, 그리고 이와 관련해 동시성과 병렬성의 정의 및 차이점에 대해 알아보자!

### CPU 클럭 속도

> [!NOTE]
> 컴퓨터의 **부품을 일사불란하게 움직일 수 있게 하는 시간의 단위** <br/>
> '똑딱-똑딱' 주기에 맞춰 데이터 이동, 연산 수행, 명령어 읽기 등이 이루어짐

클럭 속도는 헤르츠(Hz) 단위로 측정되며, 이는 클럭이 1초에 몇 번 반복되는지를 나타냄. 현대 **CPU**의 클럭 속도는 **기가헤르츠(GHz) 단위**로 측정되는 것이 일반적임(`1GHz = 10^9Hz`).

클럭 속도가 높을수록 CPU는 명령어 사이클을 더 빠르게 반복할 수 있지만, **발열** 문제로 인해 클럭 속도 증가만으로는 성능 향상에 한계가 존재함.

### (멀티) 코어

> [!NOTE]
> CPU 내에서 명령어를 읽어 들이고, 해석하고, 실행하는 부품

<img width="600" alt="image" src="https://github.com/user-attachments/assets/cbf3557b-6d81-48dc-82e4-2d1ded1ed743" />

전통적 관점에서는 CPU 하나에 하나의 처리 장치만 존재했으나, 현대 CPU에는 여러 개의 코어가 포함돼 있음. 코어 개수에 따라 싱글코어, 듀얼코어, 쿼드코어 등으로 명칭이 바뀜.

| 코어 개수 | 명칭                    |
| --------- | ----------------------- |
| 1         | 싱글코어(single-core)   |
| 2         | 듀얼코어(dual-core)     |
| 4         | 쿼드코어(quad-core)     |
| 6         | 헥사코어(hexa-core)     |
| 8         | 옥타코어(octa-core)     |
| 12        | 도데카코어(dodeca-core) |

### (멀티) 스레드

사전적 의미로 '실행 흐름의 단위'라고 하지만, 프로세스도 이와 비슷한 정의를 갖고 있기에 이 책에서는 하드웨어-소프트웨어 측면으로 나눠 설명하고 있음.

#### 하드웨어 스레드(논리 프로세서)

하드웨어적인 스레드 = 하드웨어 스레드

> [!NOTE]
> 하나의 **코어**가 동시에 처리하는 **명령어** 단위 <br />
> 멀티스레드 프로세서(CPU)는 **하나의 코어로 여러 명령어를 동시에 처리**할 수 있음

예를 들어, 2코어 4스레드 CPU는 2개의 물리적 코어로 4개의 명령어 흐름을 동시에 처리할 수 있음.
메모리 속 프로그램 입장에서는 하드웨어 스레드가 마치 독립적인 CPU처럼 보이므로 **논리 프로세서**라고도 부름.

<img width="600" alt="image" src="https://github.com/user-attachments/assets/e77685bd-7a69-4443-8715-18bfa41d923e" />

#### 소프트웨어 스레드

소프트웨어적인 스레드 = 스레드

> [!NOTE]
> 하나의 **프로그램**에서 독립적으로 실행되는 단위 <br />
> 메모리에 적재된 **프로그램의 여러 부분이 동시에 실행**될 수 있게 함

하드웨어 스레드가 하나인 CPU에서도 소프트웨어 스레드(멀티도 가능)를 통한 프로그램 실행이 가능함.

### 병렬성 & 동시성

하드웨어-소프트웨어 스레드는 병렬성 & 동시성으로 좀 더 명확히 알 수 있음.

#### 병렬성(Parallelism)

> [!NOTE]
> 작업을 **물리적으로 동시에 처리**하는 성질

예를 들어, 하드웨어 스레드가 4개인 CPU가 4개의 명령어를 실제로 동시에 실행하는 경우가 해당됨.

#### 동시성(Concurrency)

> [!NOTE]
> 작업을 **동시에 처리하는 것처럼** 보이게 하는 성질

CPU가 빠르게 여러 작업을 번갈아 가며 처리하는 경우, 사용자 입장에서는 매우 빠르게 처리돼 **동시에 처리되는 것처럼** 보이지만 물리적으로는 **한 시점에 하나의 작업만 처리**됨.

<img width="600" alt="image" src="https://github.com/user-attachments/assets/40658d3b-6b80-4dbf-8676-53063832ae9e" />

즉, **하드웨어 스레드**는 '**병렬성**'을 구현하기 위한 **물리적** 실행 단위에 가깝고, **소프트웨어 스레드**는 '**동시성**'을 구현하기 위한 **논리적** 실행 단위에 가까움.

### 파이프라이닝을 통한 명령어 병렬 처리

> [!NOTE]
> 여러 명령어를 **말 그대로 동시에 처리**해 **CPU를 한시도 쉬지 않고 작동시킴**으로써 CPU 성능을 향상시키는 기술

<img width="600" alt="image" src="https://github.com/user-attachments/assets/7a5552f1-e715-4fc4-bb54-dd4c4479c26f" />

하나의 명령어 처리 과정은 일반적으로 다음과 같은 단계로 나눌 수 있음.

1. 명령어 인출(Instruction Fetch)
2. 명령어 해석(Instruction Decode)
3. 명령어 실행(Execute Instruction)
4. 결과 저장(Write Back)

명령어 파이프라이닝은 공장의 생산 라인처럼 여러 명령어를 처리 단계별로 동시에 실행함. 예를 들어, 한 명령어가 해석 단계에 있을 때 다른 명령어는 인출 단계에, 또 다른 명령어는 실행 단계에 동시에 있을 수 있음. 이를 통해 CPU의 유휴 시간을 최소화하고 처리량을 늘릴 수 있음.

> 참고: CPU 내부에 **여러 개의 명령어 파이프라인을 배치**하는 것을 **슈퍼스칼라(Superscalar)** CPU or 프로세서라고 칭함. 현대의 CPU는 대부분 슈퍼스칼라 구조임.

또한, **명령어 집합 유형에 따라 파이프라이닝 특성**을 나눌 수 있음.

#### CISC(Complex Instruction Set Computer)

> [!NOTE]
> 다양하고 **다채로운 기능**을 지원하는 **복잡한 명령어**들로 구성된 명령어 집합

<img width="600" alt="image" src="https://github.com/user-attachments/assets/0adbb13e-71bb-49be-9600-92a2333b98b2" />

적은 수의 명령어로도 프로그램을 실행할 수 있지만, 명령어의 크기와 실행 시간이 일정하지 않아 파이프라이닝에 비효율적일 수 있다는 특성이 있다.

대표적으로 인텔의 x86 CPU가 이에 해당함.

#### RISC(Reduced Instruction Set Computer)

> [!NOTE]
> CISC에 비해 활용 가능한 **명령어 종류가 적으며**, **짧고 규격화**된 명령어를 지향

<img width="600" alt="image" src="https://github.com/user-attachments/assets/3e4742d7-6c81-42c7-93e0-ccc526bcaada" />

하나의 명령어가 1클럭 내외로 실행되도록 설계돼 파이프라이닝에 최적화됨. 같은 프로그램 실행에 더 많은 명령어가 필요하지만 처리 속도가 일정하고 예측 가능함.

애플의 M1 CPU가 대표적인 예임.

### 파이프라이닝이 CPU 성능 향상에 실패하는 경우

파이프라이닝이 실패해 성능 향상이 이루어지지 않는 상황을 파이프라인 위험(pipeline hazard)이라 한다. 3가지 종류가 존재한다.

#### 데이터 위험(Data Hazard)

명령어 간 데이터 의존성에 의해 발생.
예를 들어, 한 명령어의 결과가 다음 명령어의 입력으로 사용될 때, 첫 번째 명령어가 완료될 때까지 두 번째 명령어는 실행될 수 없음.
이러한 의존성이 있는 명령어들을 무작정 파이프라인에 넣으면 정확한 결과를 얻을 수 없음.

#### 제어 위험(Control Hazard)

프로그램 카운터의 갑작스러운 변화에 의해 발생.
JUMP, CONDITIONAL JUMP, 인터럽트 등으로 인해 프로그램 실행 흐름이 바뀌면, 이미 파이프라인에 들어간 명령어들이 무효화돼 파이프라인을 비우고 새로운 주소부터 다시 시작해야 함.

#### 구조적 위험(Structural Hazard)

명령어들을 겹쳐 실행하는 과정에서 서로 다른 명령어가 동시에 같은 CPU 부품(ALU, 레지스터 등)을 사용하려고 할 때 발생.
자원 위험(resource hazard)이라고도 부름.

---

# 4절. 메모리

## RAM 특성과 중요성

> [!NOTE]
> Random Access Memory, 메인 메모리로 사용되는 휘발성 저장장치 <br />
> 프로그램 실행에 직접적인 영향을 미치는 핵심 컴퓨터 부품

### RAM 기본 특성

- **휘발성 저장장치**로 전원이 꺼지면 저장된 데이터와 명령어가 모두 소멸
- CPU가 **실행할 대상**을 저장하는 부품, 보조기억장치와 달리 실행 중인 프로그램을 위한 공간
- 보조기억장치의 프로그램은 실행을 위해 반드시 RAM으로 복사돼야 함
- 그래서, RAM 용량이 커야 더 많은 프로그램을 로드하고, 보조기억장치와의 데이터 교환 횟수가 줄어 성능 향상으로 이어짐

### 임의 접근과 순차 접근의 비교

- **임의 접근(Random Access)**: 메모리의 어떤 위치든 동일한 시간에 직접 접근 가능한 방식
  - 100번지 접근 시 1~99번지를 거칠 필요 없이 바로 접근 가능함
  - 접근 위치와 상관없이 일정한 접근 시간이 보장됨
  - RAM의 'Random Access'는 이 특성에서 유래함
- **순차 접근(Sequential Access)**: 저장 위치에 도달하기 위해 처음부터 순차적으로 접근해야 하는 방식
  - 위치에 따라 접근 시간이 달라질 수 있음
  - 테이프 드라이브 등의 저장 매체에서 주로 사용됨

RAM은 임의 접근 방식을 사용하기 때문에 메모리 어느 위치든 균일한 접근 속도를 제공하며, 이는 프로그램 실행 속도에 직접적인 영향을 미침. 이러한 특성으로 인해 현대 컴퓨터의 주 메모리로 RAM이 널리 사용되는 것임.

## RAM의 종류

RAM은 프로그램을 실행하기 위해 유형에 따라 속도와 데이터 유지 특성이 다름.

### DRAM(Dynamic RAM)

- 시간이 지나면 저장된 데이터가 점차 사라지는 RAM
- 데이터 소멸 방지를 위해 일정 주기로 재활성화(다시 저장) 필요
- 소비 전력 낮음, 저렴한 가격, 높은 집적도로 대용량 메모리 설계에 적합
- 단점에도 불구하고 장점으로 인해 주 메모리로 사용되는 것이 일반적

### SRAM(Static RAM)

- 시간이 지나도 저장된 데이터가 사라지지 않는 RAM
- DRAM보다 속도가 빠른 장점이 있음
- 소비 전력이 큼, 가격이 비쌈, 집적도가 낮아 대용량으로 부적합
- 캐시 메모리 등 속도가 중요한 저용량 저장장치에 주로 사용

### SDRAM(Synchronous Dynamic RAM)

- 클럭 신호와 동기화된 보다 발전된 형태의 DRAM
- 클럭 타이밍에 맞춰 CPU와 정보를 주고받을 수 있는 특징을 가짐
- SDR SDRAM(Single Data Rate SDRAM)이라고도 불리며 한 클럭당 하나씩 데이터 전송이 가능

### DDR SDRAM(Double Data Rate SDRAM)

- 대역폭을 넓혀 속도를 향상시킨 SDRAM 유형
- SDRAM이 한 클럭당 한 번씩 데이터를 전송한다면, DDR SDRAM은 한 클럭당 두 번씩 전송 가능
- **DDR2 SDRAM**: DDR SDRAM보다 대역폭이 두 배 넓은 형태
- **DDR3 SDRAM**: DDR2 SDRAM보다 대역폭이 두 배 넓은 형태
- **DDR4 SDRAM**: DDR3 SDRAM보다 대역폭이 두 배 넓은 형태(SDRAM 대비 16배 넓은 대역폭)로 최근 일반적으로 사용되는 메모리

<img width="600" alt="image" src="https://github.com/user-attachments/assets/9ae710d0-88c4-4dd5-a604-fc1641d0f389" />

그 외에도 높은 대역폭과 고전력 특성을 가지고, 병렬 작업 최적화가 가능한 GDDR(GDDR6X 등)과 휴대성에 맞춰 발열, 저전력 특성을 가진 LPDDR(LPDDR5 등)도 있음.

## 빅 엔디안 & 리틀 엔디안

> [!NOTE]
> 컴퓨터가 메모리에 다중 바이트 데이터를 저장하는 순서에 관한 방식 <br />
> 시스템 아키텍처에 따라 다르게 적용됨

### 빅엔디안(Big-Endian)

<img width="600" alt="image" src="https://github.com/user-attachments/assets/a087c703-9534-488d-af7f-50125151504e" />

- 낮은 번지의 주소에 **상위 바이트부터 저장**하는 방식임
- MSB가 있는 바이트, 즉 중요하고 큰 데이터부터 저장해 나가는 방식임
- 일상적으로 숫자를 읽고 쓰는 순서와 동일해 **메모리 값을 직접 읽거나 디버깅할 때 편리**함
- 주소에 1A, 2B, 3C, 4D 순서로 있으면 그대로 1A2B3C4D로 읽을 수 있음

### 리틀엔디안(Little-Endian)

<img width="600" alt="image" src="https://github.com/user-attachments/assets/0d7d5c80-3060-4bca-85a8-b879a1df1b27" />

- 낮은 번지의 주소에 **하위 바이트부터 저장**하는 방식임
- LSB가 있는 바이트, 즉 덜 중요하고 작은 데이터부터 저장해 나가는 방식임
- 메모리 값을 직접 읽고 쓰기에는 불편하지만 **수치 계산이 편리**한 장점이 있음
- 123 + 456 더할 때처럼 가장 작은 값부터 계산해나가는 방식과 유사함

#### 참고: MSB & LSB

- **MSB(Most Significant Bit)**: 숫자의 크기에 가장 큰 영향을 미치는 유효 숫자, 가장 왼쪽에 위치한 비트
- **LSB(Least Significant Bit)**: 숫자의 크기에 가장 적은 영향을 미치는 유효 숫자, 가장 오른쪽에 위치한 비트

## 캐시 메모리

> [!NOTE]
> CPU와 메모리 사이의 속도 차이를 줄이기 위한, SRAM 기반의 고속 임시 저장장치 <br />
> CPU에서 자주 사용되는 데이터를 빠르게 접근할 수 있도록 함

<img width="600" alt="image" src="https://github.com/user-attachments/assets/ed8c9cfe-ad4d-4cff-9f91-7a35c5adaf3c" />

### 캐시 메모리 계층 구조

<img width="600" alt="image" src="https://github.com/user-attachments/assets/7a1e932b-fe22-4e4d-9ffb-f7cf65bffb26" />

- **L1 캐시**: 코어와 가장 가까운 최고속 캐시 메모리
- **L2 캐시**: L1 다음으로 가까운 캐시 메모리
- **L3 캐시**: 그 다음으로 가까운 캐시 메모리
- 일반적으로 L1과 L2 캐시는 코어 내부에, L3 캐시는 코어 외부에 위치함
- 캐시 메모리의 **크기 관계**: L1 < L2 < L3
- 캐시 메모리의 **속도 관계**: L3 < L2 < L1
- CPU가 데이터 검색 시 **우선순위**: L1 캐시 → L2 캐시 → L3 캐시

#### 분리형 캐시

<img width="600" alt="image" src="https://github.com/user-attachments/assets/2e78b0bf-3920-4c9f-817d-77ff42370374" />

- L1 캐시는 종종 **L1I 캐시**(명령어 저장용)와 **L1D 캐시**(데이터 저장용)로 구분
- 명령어와 데이터를 분리함으로써 캐시 효율성 증대가 가능!

### 캐시 히트와 캐시 미스

- **캐시 히트**: 캐시 메모리가 **예측**해 저장한 데이터가 CPU에 의해 **실제로 사용되는 경우**임
- **캐시 미스**: **틀린 예측**으로 인해 CPU가 **메모리로부터 필요한 데이터를 직접** 가져와야 하는 경우임
- **캐시 적중률**: 캐시가 히트되는 비율로, `캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)`로 계산됨
- 캐시 미스 발생 시 CPU 성능이 저하 !

### 참조 지역성의 원리

캐시 메모리는 참조 지역성의 원리에 따라 메모리로부터 가져올 데이터를 결정함.

- **시간 지역성**: CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있음(예: 변수의 반복적 사용)
- **공간 지역성**: CPU는 접근한 메모리 공간의 근처에 접근하려는 경향이 있음(예: 배열의 순차적 접근)

### 캐시 메모리 쓰기 정책과 일관성

> [!NOTE]
> 캐시 메모리에 데이터를 쓸 때 발생하는 주요 문제는 **캐시와 메인 메모리 간의 데이터 일관성 유지** <br />

이 문제 해결 방식에 따라 시스템 성능과 데이터 무결성이 영향을 받음

#### 캐시-메모리 데이터 불일치 상황

메모리 1000번지에 200이 저장되어 있고 캐시에도 같은 값이 있을 때, CPU가 이 값을 300으로 변경하면 문제가 발생함.

<img width="600" alt="image" src="https://github.com/user-attachments/assets/2d0b1ef2-82cf-458a-9156-6c6df919bc73" />

1. **메모리만 갱신할 경우**: 메모리에는 300, 캐시에는 200이 저장되어 일관성이 깨짐
2. **후속 명령어가 캐시 데이터 참조 시**: 예상과 다른 200이라는 값이 사용됨
3. **일관성 깨짐의 결과**: 프로그램 실행 결과 예측 불가, 버그 발생 가능성 증가

#### 즉시 쓰기(Write-Through) 방식

<img width="600" alt="image" src="https://github.com/user-attachments/assets/498ef4d5-0393-4650-845a-08348ad04c15" />

- **작동 원리**: 캐시와 메모리에 동시에 데이터를 쓰는 방식
- **장점**
  - 메모리가 **항상 최신 상태로 유지**
  - 캐시-메모리 간 데이터 일관성 보장이 **단순**함
  - 시스템 장애 발생 시 데이터 복구가 용이함
- **단점**
  - 매 쓰기 작업마다 메모리 접근이 필요해 **버스 트래픽 증가**
  - 메모리 접근 시간으로 인한 CPU 대기 시간 발생
  - 쓰기 작업이 빈번한 애플리케이션에서 성능 저하가 현저함

#### 지연 쓰기(Write-Back) 방식

<img width="600" alt="image" src="https://github.com/user-attachments/assets/aa7765d3-a73f-4fb4-92e0-d57a7dbfcd49" />

- **작동 원리**: 캐시에만 변경사항을 기록하고 특정 조건(캐시 퇴출, 일정 시간 경과 등)에서 메모리에 반영하는 방식
- **장점**
  - 메모리 접근 빈도 감소로 시스템 성능 향상
  - 여러 쓰기 작업을 묶어서 처리해 **버스 사용 효율성 증가**
  - 쓰기 작업이 빈번한 애플리케이션에 적합함
- **단점**
  - 캐시-메모리 간 일관성 관리가 **복잡**함
  - 갱신 타이밍 결정을 위한 추가 로직 필요
  - 시스템 장애 시 최신 데이터 손실 가능성 존재

#### 멀티코어 환경에서의 캐시 일관성 문제

- **다중 캐시의 일관성 문제**: 여러 코어가 각자의 캐시에 동일 메모리 위치의 사본을 가질 때 발생
- **캐시 일관성 프로토콜**: 다른 코어의 캐시 간 데이터 일관성을 유지하기 위한 규약
  - MESI, MOESI 등의 프로토콜이 널리 사용됨
  - 캐시 상태를 공유/독점/수정됨 등으로 표시해 관리
- **일관성 관리의 오버헤드**: 코어 간 통신과 상태 관리로 인한 추가 지연 발생

#### 캐싱의 본질적 트레이드오프

- **성능과 일관성의 균형**: 캐싱은 항상 접근 속도와 데이터 일관성 사이의 균형을 조정하는 문제
- **적용 범위**: 캐시 메모리뿐만 아니라 웹 캐시, 디스크 캐시 등 다양한 컴퓨팅 영역에서 동일한 원칙이 적용

<img width="600" alt="image" src="https://github.com/user-attachments/assets/68986f6b-ef08-4ee7-b15b-b8bcf74e53f6" />

> [!TIP]
> 캐시 메모리는 빠른 성능을 가지지만, 단순히 데이터를 임시 저장하는 공간이 아니라, 복잡한 일관성 관리 메커니즘이 필요한 시스템 <br />
> 어떤 쓰기 정책을 선택하느냐에 따라 성능과 신뢰성 간의 트레이드오프가 발생하므로, 시스템 용도, 요구사항에 맞는 최적의 정책 설계가 중요함
