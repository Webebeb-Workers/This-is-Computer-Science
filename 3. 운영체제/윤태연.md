# 2절. 프로세스와 스레드

## 프로세스의 유형 및 구성

> [!NOTE]
> 컴퓨터가 실행되는 순간부터 메모리에 적재돼 실행되는 **프로그램의 인스턴스** <br>
> 각 프로그램마다 **독립적인 실행 단위**

### 프로세스 유형

<img width="600" alt="image" src="https://github.com/user-attachments/assets/b5db6f03-f047-4892-ab53-02e2f8f483c6" />

- **포그라운드 프로세스**: 사용자가 보는 공간에서 상호작용하며 실행되는 프로세스
- **백그라운드 프로세스**: 사용자가 보지 못하는 곳에서 실행되는 프로세스
- **데몬**: 사용자와 별다른 상호작용 없이 주어진 작업만 수행하는 특별한 백그라운드 프로세스(윈도우에서는 서비스)

### 사용자 영역 구성

- **코드 영역(텍스트 영역)**: 실행 가능한 명령어가 저장되는 읽기 전용 공간
- **데이터 영역**: 프로그램 실행 동안 유지할 정적 변수나 전역 변수가 저장되는 공간
- **힙 영역**: **사용자가 직접 할당 가능**한 저장 공간, 메모리 누수 위험성 존재
  - 프로그램 실행 도중 비교적 자유롭게 할당해 사용 가능한 메모리 공간
  - 메모리 공간을 반환하지 않으면 **메모리 누수**(memory leak) 문제 발생
  - 일부 언어는 **가비지 컬렉션**(garbage collection) 기능으로 자동 메모리 관리
- **스택 영역**: **일시적 사용 값**(매개변수, 지역 변수, 함수 복귀 주소 등) 저장 공간
  - 스택 트레이스(stack trace): 특정 시점에 스택 영역에 저장된 함수 호출 정보로 디버깅에 유용

코드 영역과 데이터 영역은 크기가 변하지 않는 정적 할당 영역인 반면, 힙 영역과 스택 영역은 크기가 변할 수 있는 동적 할당 영역.

> [!TIP]
> BSS 영역은 데이터 영역과 유사하지만 초기화 여부에 차이가 있음 <br> > **초깃값이 있는 정적/전역 변수는 데이터 영역**에, **초깃값이 없는 데이터는 BSS 영역**에 저장

## PCB와 문맥 교환

### PCB(프로세스 제어 블록)

> [!NOTE]
> 프로세스를 식별할 수 있는 커널 영역 내 정보 구조체 <br>
> 새 프로세스가 메모리에 적재될 때 생성되고, 프로세스 종료 시 폐기됨

| PCB 구성 요소            | 설명                                     |
| ------------------------ | ---------------------------------------- |
| **프로세스 식별자**(PID) | 각 프로세스를 구분하는 고유 ID           |
| **프로세스 상태**        | 생성, 준비, 실행, 대기, 종료 중 하나     |
| **프로그램 카운터**(PC)  | 다음에 실행할 명령어의 위치              |
| **CPU 레지스터**         | 프로세스가 CPU를 사용할 때의 레지스터 값 |
| **CPU 스케줄링 정보**    | 우선순위, 스케줄링 큐 포인터 등          |
| **메모리 관리 정보**     | 기준 레지스터, 한계 레지스터 값 등       |
| **입출력 상태 정보**     | 프로세스에 할당된 입출력 장치 목록       |
| **계정 정보**            | CPU 사용 시간, 계정 번호 등              |

- 여러 PCB들은 커널 내에 프로세스 테이블 형태로 관리됨
- 좀비 프로세스(zombie process): 비정상 종료돼 자원은 회수됐으나 PCB가 테이블에 남아있는 상태

> [!TIP]
> 구조체(struct)란 서로 다른 자료형으로 이루어진 데이터를 하나로 묶어 활용할 수 있도록 하는 복합 자료형의 일종 <br>
> PCB는 이러한 구조체 형태로 구현, 리눅스에서는 `task_struct`라는 이름으로 구현

### 문맥 교환

<img width="600" alt="image" src="https://github.com/user-attachments/assets/f931028b-40d8-4030-bfc6-11b878238547" />

- **문맥**: 프로세스 수행 재개를 위해 기억해야 할 정보(프로그램 카운터, 레지스터 값, 메모리 정보 등)
- **문맥 교환**: 기존 프로세스의 문맥을 PCB에 백업하고, 새 프로세스의 문맥을 복구하는 과정
- **타이머 인터럽트**(timer interrupt)가 발생하면 CPU 사용 양보 후 다음 차례 대기
- 문맥 교환이 너무 잦으면 **캐시 미스** 발생 가능성 증가로 **성능 저하** 발생

#### 문맥 교환 과정 상세 설명

- **작동 원리**: 프로세스들은 한정된 시간 동안 번갈아가며 CPU를 할당받아 실행됨
- **CPU 자원 관리**: 운영체제가 각 프로세스에 CPU 자원을 할당하고 회수하는 방식으로 동작
- **인터럽트 기반 제어**: 프로세스의 CPU 사용 시간은 타이머 인터럽트에 의해 제한됨
- **문맥 백업 과정**: 프로세스 A에서 B로 전환 시, A의 프로그램 카운터, 레지스터 값, 메모리 정보, 열린 파일, 입출력장치 정보 등 중간 상태를 PCB에 백업
- **문맥 복구 과정**: 다음 실행할 프로세스 B의 PCB에서 문맥을 복구해 이전 실행 지점부터 재개
- **실행 흐름 관리**: 문맥 교환을 통해 여러 프로세스가 끊임없이 빠르게 번갈아 가며 실행되는 구조 구현

실제 예시를 보며 이해해보자.

<img width="600" alt="image" src="https://github.com/user-attachments/assets/dcdd1ce2-c226-40aa-8fca-c93703e7c8cd" />

1. **프로세스 A 실행**: CPU 할당받아 실행 중인 상태
2. **타이머 인터럽트 발생**: 할당된 시간 종료
3. **문맥 저장**: A의 현재 상태(레지스터 값, 프로그램 카운터 등)를 A의 PCB에 저장
4. **스케줄링**: 다음 실행할 프로세스 B 선택
5. **문맥 복원**: B의 PCB에서 이전에 저장된 상태 로드해 CPU 레지스터에 복원
6. **프로세스 B 실행**: B가 이전 실행 지점부터 수행 재개
7. **반복**: 다음 타이머 인터럽트 발생 시까지 프로세스 B 실행 후 다시 문맥 교환 발생

#### 문맥 교환의 오버헤드

- **캐시 미스**: 프로세스 전환 시 캐시 메모리에 저장된 정보가 무효화돼 새로운 프로세스 데이터를 메모리에서 가져와야 함
- **TLB 플러시**: 주소 변환 캐시(TLB) 정보가 초기화돼 메모리 접근 속도 저하
- **파이프라인 초기화**: CPU 명령어 파이프라인이 비워지고 새로운 프로세스의 명령어로 다시 채워지는 과정 필요
- **컨텍스트 저장/복구 시간**: PCB에 정보를 저장하고 불러오는 과정 자체에도 시간 소요
- **메모리 계층구조 충돌**: 서로 다른 프로세스 간 전환 시 캐시, 메모리 등의 계층구조에서 충돌 발생 가능

> 실제 작업보다 문맥 교환에 더 많은 시간이 소요되는 스래싱(thrashing) 현상이 발생함

## 프로세스의 상태

<img width="600" alt="image" src="https://github.com/user-attachments/assets/b798c969-2e8b-41cd-b337-663a3001196d" />

- **생성 상태(new)**: 프로세스 생성 중인 상태, 메모리 적재 및 PCB 할당 완료 상태
- **준비 상태(ready)**: CPU 할당받아 실행할 수 있지만 차례를 기다리는 상태 준비 상태에서 실행 상태로 전환되는 것을 **디스패치**(dispatch)라고 함
- **실행 상태(running)**: CPU 할당받아 실행 중인 상태 타이머 인터럽트 발생 시 준비 상태로 돌아가거나 입출력 요청 시 대기 상태로 전환
- **대기 상태(blocked)**: 입출력 작업 요청이나 바로 확보할 수 없는 자원 요청 등으로 실행 불가능한 상태 조건 충족 시 준비 상태로 이동
- **종료 상태(terminated)**: 프로세스가 종료된 상태, PCB와 사용 메모리 정리

> [!TIP]
> 프로세스가 실행 도중 입출력 작업을 진행해야한다고 가정 했을 때,
>
> - **블로킹 입출력(blocking I/O)**: 입출력 작업 수행 시 대기 상태로 전환돼 완료 시까지 기다림
> - **논블로킹 입출력(non-blocking I/O)**: 입출력 작업을 요청한 후 결과를 기다리지 않고 다음 명령 수행

## 멀티프로세스와 멀티스레드

### 멀티프로세스

- 동시에 여러 프로세스가 실행되는 환경
- 자원을 공유하지 않고 독립적으로 실행됨
- 한 프로세스에 문제가 생겨도 다른 프로세스에 영향 최소화

웹 브라우저의 탭이 대표적인 멀티프로세스 사례, 각 탭이 각각의 PID를 가지고 있음. 즉, 별도 프로세스로 실행됨.

### 멀티스레드

- 하나의 프로세스 내에서 여러 실행 흐름을 동시에 관리하는 기법
- 스레드 구성 요소: 스레드 ID, 프로그램 카운터, 레지스터 값, 스택
- 코드, 데이터, 힙 영역이나 열린 파일 등 프로세스 자원을 공유함
- 한 스레드 문제가 전체 프로세스에 영향을 줄 수 있음
- 스레드 간 자원 공유로 협력과 통신이 용이함
- 여러 스레드가 함께 작업할 경우 사용자 입력, 화면 출력, 백그라운드 처리 등 동시 수행 가능

> [!TIP]
> 스레드 조인(join)은 **생성된 스레드가 종료될 때까지 기다리는 기능** <br>
> 예를 들어 `main` 스레드가 `a` 스레드를 생성하고 join을 호출하면, `main` 스레드는 `a` 스레드가 종료될 때까지 대기 상태로 머물게 됨 <br>
> C++, 자바, 파이썬, Go 등 대부분의 프로그래밍 언어에서 스레드 생성 및 관리 기능 제공

## 프로세스 간 통신(IPC)

> [!NOTE]
> 프로세스 간 자원을 공유하고 데이터를 주고받는 방법 <br>
> 공유 메모리와 메시지 전달 두 가지 주요 방식이 존재

### 공유 메모리

- 프로세스 간 공유 메모리 영역을 통해 데이터 교환
- 각 프로세스가 자신의 메모리처럼 읽고 쓰는 방식으로 통신
- 메모리 영역을 확보하는 시스템 콜 기반 또는 공유 변수/파일 활용 가능
- **장점**: 커널 개입 최소화로 통신 속도가 빠름
- **단점**: 동시 읽기/쓰기 시 데이터 일관성 문제(레이스 컨디션) 발생 가능

### 메시지 전달

- 커널을 통해 데이터가 송수신되는 통신 방식
- 명확한 메시지 송수신 수단 구분(send/recv 시스템 콜 등)
- **장점**: 커널 도움으로 동기화 문제 고려 감소
- **단점**: 커널 경유로 통신 속도 상대적 저하

#### 메시지 전달 방식들

1. **파이프**
   - 프로세스 간 단방향 통신 도구
   - 한쪽에서 데이터 쓰면 반대쪽에서 읽는 구조
   - 양방향 통신 필요 시 파이프 2개 사용
   - 익명 파이프(unnamed pipe): 양방향 통신 미지원, 부모-자식 프로세스 간 통신만 가능
   - 지명 파이프(named pipe/FIFO): 양방향 통신 지원, 임의 프로세스 간 사용 가능
2. **시그널**
   - 이벤트 발생을 알리는 비동기적 신호
   - 시그널 발생 시 프로세스는 일시 중단 후 시그널 핸들러 실행
   - 프로세스가 시그널 발생 및 일부 핸들러 정의 가능
   - 다양한 시그널 유형 존재(SIGCHLD, SIGINT, SIGKILL 등)
   - 시그널 기본 동작: 종료, 무시, 코어 덤프 생성 후 종료
   - 코어 덤프(core dump): 비정상 종료 시 생성되는 메모리 상태 기록 파일, 디버깅에 활용
3. **원격 프로시저 호출(RPC)**
   - 다른 프로세스의 원격 코드 실행 기법
   - 언어나 플랫폼 독립적 작동
   - 성능 저하 최소화와 효율적 메시지 전달로 서버 간 통신에서 많이 사용됨
   - 구글의 gRPC 등 다양한 RPC 프레임워크 존재
4. **네트워크 소켓**
   - 네트워크를 통한 프로세스 간 통신 방식
   - 로컬 및 원격 프로세스 간 통신 가능

# 3절. 프로세스/스레드 동기화

> [!NOTE]
> 프로세스나 스레드가 공유 자원에 접근할 때 발생할 수 있는 문제를 해결하기 위한 기법들의 집합

자원의 일관성을 유지하고 올바른 실행 순서를 보장하기 위해 필수적.

## 공유 자원 & 임계 구역

<img width="600" alt="image" src="https://github.com/user-attachments/assets/566438e0-8e01-4a79-99d4-318ce0f4b67e" />

### 공유 자원

- **여러 프로세스나 스레드가 함께 사용하는 자원**
  - 메모리, 파일, 전역 변수, 입출력장치 등
- 프로세스 간 통신에서는 공유 메모리 공간을 통해 데이터 교환
- 스레드 간 통신에서는 같은 프로세스 내의 파일, 전역 변수 등을 공유 자원으로 활용
- 공유 자원에 대한 무분별한 접근은 데이터 불일치 문제를 야기할 수 있음

### 임계 구역

- **공유 자원에 접근하는 코드 중 동시에 실행하면 문제가 발생할 수 있는 영역**
  - 예시1: 프로세스 A가 공유 메모리에 데이터를 쓰고, 프로세스 B가 읽는 코드 영역
  - 예시2: 여러 스레드가 같은 파일을 수정하는 코드 영역
- 임계 구역에 동시 접근하면 자원의 일관성이 손상될 수 있어 순차적 접근이 필요함

### 레이스 컨디션

- **둘 이상의 프로세스/스레드가 임계 구역을 동시에 실행해 발생하는 문제 상황**
- 실행 순서에 따라 결과가 달라질 수 있어 예측 불가능한 동작을 초래함
  - 예시: 두 스레드가 공유 변수를 동시에 증가/감소시키면 최종값이 실행마다 달라질 수 있음
- 실제 코드에서는 값 증가/감소 연산이 원자적이지 않아 발생하는 문제

## 동기화 필요성 및 종류

레이스 컨디션에 의해 기대한 값이 나오지 않음. 이를 위해 프로세스 or 스레드 동기화를 이뤄야 함.

### 동기화 목적

임계구역에 아래와 같은 목적을 이뤄야 함.

- **실행 순서 제어**: 프로세스/스레드를 특정 조건이나 순서에 따라 올바르게 실행
  - 예: 공유 메모리에 데이터를 쓴 후에 읽기 작업이 수행돼야 함 (예시1의 예방책)
- **상호 배제**: 공유 자원에 하나의 프로세스/스레드만 접근하도록 제한
  - 예: 파일 수정 시 한 스레드만 접근해 일관성을 유지함 (예시2의 예방책)

## 동기화 기법

실행 순서 제어와 상호 배제를 지키기 위한 기법!

### 뮤텍스 락(Mutex Lock)

<img width="600" alt="image" src="https://github.com/user-attachments/assets/4eb6f6b6-e19c-40cd-9859-1d1d29c4c6bd" />

- **상호 배제(MUTual EXclusion)를 위한 기본적인 동기화 도구**
- 동작 원리
  - `lock.acquire()`: 임계 구역 진입 전 락 획득 시도, 다른 프로세스가 이미 획득한 경우 => 대기
  - 임계 구역 실행: 락을 획득한 프로세스만 실행 가능함
  - `lock.release()`: 임계 구역 종료 후 락 해제, 대기 중인 다른 프로세스가 획득 가능해짐

> [!TIP]
> 임계 구역에 접근하고자 한다면 반드시 락(lock)을 획득(acquire)해야 하고, <br>
> 임계 구역에서의 작업이 끝났다면 락을 해제(release)해야 한다.

### 세마포(Semaphore)

멈춤 신호와 가도 좋다는 신호를 받아 임계 구역 관리!

- **여러 개의 공유 자원을 관리할 수 있는 카운터 기반 동기화 도구**
- 변수 `S`(사용 가능한 자원 수)와 `wait()`/`signal()` 함수로 구성
- 동작 원리
  - `wait()`: S를 1 감소시키고, S가 0보다 작으면 호출한 프로세스를 대기 상태로 전환함
  - `signal()`: S를 1 증가시키고, S가 0 이하면 대기 중인 프로세스를 깨움
- 세마포 유형
  - 이진 세마포: S가 0과 1 값만 가지며 뮤텍스 락과 유사하게 동작
  - 카운팅 세마포: S가 여러 값을 가질 수 있어 다수의 자원 관리에 적합 (일반적)
- 사용 사례: 2개의 프린터 자원을 최대 2개 프로세스가 동시에 사용할 수 있게 관리할 때 유용

<img width="600" alt="image" src="https://github.com/user-attachments/assets/45863969-44cf-4610-b4a0-9f382db7f7bf" />

\+ 참고: 여기서 사용 가능한 자원 수는 임계구역에 들어갈 수 있는 프로세스 개수와 같다.

### 조건 변수(Condition Variable)

- **실행 순서 제어를 위한 동기화 도구, 특정 조건에 따라 프로세스 실행/대기 관리**
- 주요 함수
  - `wait()`: 호출한 프로세스/스레드를 대기 상태로 전환
  - `signal()`: wait()로 대기 중인 프로세스/스레드 하나를 깨움
- 사용 사례: 프로세스 A의 실행이 완료된 후에만 프로세스 B가 실행돼야 할 때 활용

### 모니터(Monitor)

- **공유 자원과 그 연산을 묶은 고수준 동기화 도구, 객체 지향적 접근 방식**
- 특징
  - 공유 자원에 접근하기 위해 정해진 인터페이스(함수)만 사용 가능
  - 모니터 내에는 한 번에 하나의 프로세스/스레드만 진입 가능
  - 조건 변수와 함께 사용해 실행 순서 제어도 가능
- 프로세스/스레드가 모니터에 진입하려면 대기 큐(FIFO)에서 차례를 기다려야 함
- 조건 변수와 함께 사용하면 특정 조건에 따른 실행 순서 제어가 가능

Java의 `synchronized` 키워드가 대표적임.

## 스레드 안전(Thread Safety)

- **멀티스레드 환경에서 동시 접근해도 문제가 발생하지 않는 코드 특성**
- 특징
  - 레이스 컨디션이 발생하지 않음
  - 함수, 변수, 객체가 여러 스레드에서 동시에 호출/접근해도 안전
- 스레드 안전(성) 예시
  - Java의 `Vector` 클래스: 내부 메서드가 synchronized로 구현돼 스레드 안전
  - Java의 `ArrayList` 클래스: 동기화되지 않아 스레드 안전하지 않음
- 테스트 결과: 같은 작업(10,000번 증가 + 10,000번 감소)을 수행해도
  - `Vector`는 항상 예상값(10,000)을 반환
  - `ArrayList`는 레이스 컨디션으로 인해 매번 다른 결과를 반환

## 교착 상태(Deadlock)

<img width="600" alt="image" src="https://github.com/user-attachments/assets/59af580b-171e-425c-b8a3-2dec5de3274d" />

- **둘 이상의 프로세스**가 서로 자원을 점유한 채 상대방의 **자원을 무한정 기다리는 상황**
- '**일어나지 않을 사건을 기다리며 프로세스의 진행이 멈춰 버리는 현상**'으로 정의
- 예시: 프로세스 A는 자원 X를 점유하고 자원 Y를 기다리는 동시에, 프로세스 B는 자원 Y를 점유하고 자원 X를 기다리는 상황

### 발생 조건

모두 만족해야 발생함.

1. **상호 배제(Mutual Exclusion)**: 한 번에 하나의 프로세스만 자원을 이용할 수 있음
   - 여러 프로세스가 동시에 같은 자원을 사용할 수 없는 경우 발생함
2. **점유와 대기(Hold and Wait)**: 자원을 점유한 상태에서 다른 자원을 기다리는 상황
   - 프로세스가 일부 자원을 할당받은 상태에서 다른 자원을 요청할 때 발생함
3. **비선점(No Preemption)**: 다른 프로세스의 자원을 강제로 빼앗을 수 없음
   - 프로세스가 작업을 마칠 때까지 할당된 자원을 양보하지 않을 때 발생함
4. **원형 대기(Circular Wait)**: 프로세스와 자원이 원형으로 대기 관계를 형성함
   - 프로세스 A→B→C→A 형태로 자원을 요청하는 순환적 의존 관계가 생길 때 발생함

\+ 예시는 아래 이미지를 볼 것. 해결 전 모습을 상상하면 충분함.

### 해결 방법

<img width="600" alt="image" src="https://github.com/user-attachments/assets/d909dd10-df8b-4a13-ae88-d6ff6383c1ee" />

#### 1. **교착 상태 예방(Prevention)**

- 4가지 발생 조건 중 **하나라도 성립하지 않게 시스템 설계**
- 방법
  - 모든 자원을 한 번에 요청/할당해 점유와 대기 조건 제거
  - 자원에 번호를 부여하고 오름차순으로만 할당해 원형 대기 방지
- 단점: 자원 활용률 저하, 처리량 감소 가능성 있음

#### 2. **교착 상태 회피(Avoidance)**

- **안전한 상태를 유지**하며 자원 할당
- 프로세스에게 필요한 최대 자원양을 미리 선언하게 하고, 할당 시 교착 상태 발생 가능성 검사
- **은행원 알고리즘**(Banker's Algorithm)이 대표적인 회피 기법
- 단점: 미래 자원 요청에 대한 정보가 필요하고 시스템 활용도 낮음

#### 3. **교착 상태 검출 및 회복(Detection and Recovery)**

- 자원을 자유롭게 할당하다가 **주기적으로 교착 상태를 검출**
- 교착 상태 발견 시 회복 전략 수행
  - 프로세스 강제 종료(일부 또는 전체)
  - 자원 선점: 교착 상태가 해소될 때까지 자원을 강제로 회수해 재할당
- 장점: 사전 제약 없이 자원을 효율적으로 사용할 수 있음
- 단점: 검출 오버헤드와 회복 비용 발생

교착 상태는 멀티태스킹 환경에서 발생할 수 있는 심각한 문제이므로, 운영체제는 이를 예방하거나 적절히 대응할 수 있는 메커니즘을 갖추어야 함. 현대 운영체제들은 주로 교착 상태 회피나 검출 및 회복 전략을 조합해 사용함.

# 4절. CPU 스케줄링

- **CPU 스케줄링**: 운영체제가 프로세스들에게 CPU 자원을 **배분**하는 방법
- **CPU 스케줄링 알고리즘**: CPU 배분 **절차**와 **규칙**을 정의
- **CPU 스케줄러**: 이러한 **알고리즘을 실행**하는 운영체제의 **구성요소**

> [!TIP]
> 실행의 문맥을 가진 모든 대상(프로세스, 스레드)이 스케줄링의 대상 <br>
> 책에서는 일반적인 의미로 프로세스를 스케줄링한다고 표현

## 우선순위 기반 스케줄링

- 운영체제는 프로세스별 우선순위를 PCB에 기록하고 이를 기준으로 자원 할당
- **CPU 활용률**: CPU가 실제 작업 처리에 사용된 시간의 비율
- 일반적으로 **입출력 작업이 많은 프로세스**에 높은 우선순위 부여!
  - 그 이유는 아래에

유닉스 계열 운영체제에서는 `ps -l` 명령어로, 윈도우에서는 Process Explorer 소프트웨어를 통해 프로세스 우선순위 확인이 가능하다.

### 입출력 집중 vs CPU 집중

각 제목의 프로세스 특성은 다르다.

- **입출력 버스트**: 입출력 작업을 기다리는 기간
- **CPU 버스트**: 프로세스가 CPU를 사용하는 작업 기간
- **입출력 집중 프로세스**: 비디오 재생이나 디스크 백업처럼 입출력 작업이 많아 대기 상태에 자주 진입함
- **CPU 집중 프로세스**: 복잡한 연산이나 그래픽 처리 같은 작업이 많아 실행 상태에 오래 머무름

> [!TIP]
> 입출력 집중 프로세스에 높은 우선순위를 부여하는 이유는 이러한 프로세스를 빨리 처리해 입출력 장치를 끊임없이 작동시킨 후, CPU 집중 프로세스에 CPU를 집중적으로 할당하는 것이 CPU 활용률을 높이는데 효과적이기 때문

## 스케줄링 큐

- 자원에 접근하려는 프로세스들의 **PCB를 관리하는 대기열**
- **준비 큐**: CPU 사용을 기다리는 프로세스들의 PCB가 대기하는 큐
- **대기 큐**: 입출력 등을 기다리는 프로세스들의 PCB가 대기하는 큐

CPU 자원, CPU 및 메모리 사용, 대기 상태 특정 입출력장치 사용 등의 프로세스들에게 모두 해당됨.

<img width="600" alt="image" src="https://github.com/user-attachments/assets/4f5f509f-8051-41db-981e-16e22cb634bd" />

#### 스케쥴링 큐는 무적권 FIFO?

자료구조 관점의 큐는 선입선출 구조이지만, 스케줄링에 사용되는 큐가 반드시 선입선출일 필요는 없음.

- 같은 입출력장치를 요구한 프로세스들은 동일한 **대기 큐**에서 기다림
- 입출력이 완료되면 해당 PCB는 대기 큐에서 제거되고 **준비 큐**로 이동

즉, 할당받은 시간이 모두 소모돼 타이머 인터럽트를 받아 준비 큐로 가거나, 입출력 작업 등의 대기 상태로 갈 경우 대기 큐로 간다.

<img width="600" alt="image" src="https://github.com/user-attachments/assets/955f3c1f-9caa-4fd7-aac7-0c8e0fafa003" />

## 스케줄링 방식

스케줄링은 프로세스의 실행이 끝나고 자원 최적화를 위해 실행된다.

### 선점형 스케줄링

- 운영체제가 실행 중인 프로세스로부터 **CPU를 강제로 빼앗아**(회수) **다른 프로세스에 할당**할 수 있는 방식
- 실행 도중 스케줄링이 발생하는 두 상황 예시
  1. 실행 상태에서 입출력 작업을 위해 **대기 상태**로 전환될 때
  2. 실행 상태에서 **타이머 인터럽트**가 발생해 준비 상태로 변경될 때
- **장점**: CPU 자원의 독점을 방지하고 **균등한 자원 분배** 가능
- **단점**: **컨텍스트 스위칭**으로 인한 오버헤드 발생

### 비선점형 스케줄링

- 프로세스가 **자발적**으로 **CPU를 반납**하기 전까지 계속 사용할 수 있는 방식
- 프로세스가 종료되거나 스스로 대기 상태에 접어들 때만 스케줄링이 발생
- **장점**: **컨텍스트 스위칭** 횟수가 적어 오버헤드 감소
- **단점**: 긴급한 작업이 **대기**해야 할 수 있음

## 주요 CPU 스케줄링 알고리즘

|                      | 유형   | 특징                            | 장점                  | 단점                            | 연관 알고리즘           |
| -------------------- | ------ | ------------------------------- | --------------------- | ------------------------------- | ----------------------- |
| **FCFS**             | 비선점 | 도착 순서대로 CPU 할당          | 구현 간단, 공정성     | 컨베이어 효과, 평균 대기시간 김 | -                       |
| **SJF**              | 비선점 | 가장 짧은 작업 먼저 실행        | 평균 대기시간 최소화  | CPU 시간 예측 어려움            | SRT(선점 버전)          |
| **HRN**              | 비선점 | 응답비율 기반 스케줄링          | SJF의 기아 상태 해결  | CPU 시간 예측 필요              | SJF의 개선 버전         |
| **SRT**              | 선점   | 남은 시간 가장 짧은 작업 우선   | 짧은 작업에 빠른 응답 | 문맥 교환 오버헤드              | SJF의 선점 버전         |
| **RR**               | 선점   | 시간 할당량 기반 순환           | CPU 독점 방지, 공평성 | 시간 할당량 설정 중요           | 다단계 피드백 큐의 기반 |
| **다단계 피드백 큐** | 선점   | 여러 준비 큐와 다른 시간 할당량 | 다양한 작업 특성 수용 | 구현 복잡, 매개변수 설정 어려움 | RR의 확장 버전          |

### 1. 선입 선처리 스케줄링(FCFS)

<img width="600" alt="image" src="https://github.com/user-attachments/assets/21f469b6-2593-4320-8728-5ed2f176534e" />

- 준비 큐에 도착한 순서대로 CPU를 할당하는 방식
- **호위 효과**: 실행 시간이 긴 프로세스로 인해 뒤의 프로세스들이 지연되는 현상

### 2. 최단 작업 우선 스케줄링(SJF)

- CPU 사용 시간이 가장 짧은 프로세스부터 실행하는 방식
- 기본적으로 비선점형이지만 선점형으로도 구현 가능

### 3. 라운드 로빈 스케줄링(RR)

- 각 프로세스에 정해진 시간(타임 슬라이스)만큼 CPU를 할당하는 선점형 방식
- 프로세스가 타임 슬라이스를 모두 사용하고도 완료되지 않으면 큐의 맨 뒤로 이동

### 4. 최소 잔여 시간 우선 스케줄링(SRTF)

- 최단 작업 우선과 라운드 로빈의 결합 형태
- 남은 실행 시간이 가장 적은 프로세스에 CPU를 할당하는 방식

### 5. 우선순위 스케줄링

- 우선순위가 높은 프로세스부터 실행하는 방식
- **아사 현상**: 우선순위가 낮은 프로세스가 계속 실행 기회를 얻지 못하는 문제
- **에이징**: 대기 시간에 따라 우선순위를 점진적으로 높이는 해결책

### 6. 다단계 큐 스케줄링

<img width="600" alt="image" src="https://github.com/user-attachments/assets/17329ae0-25bd-488c-8479-457777026fd4" />

- 우선순위별로 여러 개의 준비 큐를 사용하는 방식
- 우선순위가 높은 큐의 프로세스가 모두 처리된 후에야 낮은 우선순위 큐의 프로세스가 실행
- 프로세스는 큐 사이를 이동할 수 없어 아사 현상이 발생 가능

### 7. 다단계 피드백 큐 스케줄링

<img width="600" alt="image" src="https://github.com/user-attachments/assets/bca8761f-164e-4004-8ef2-48aaa251a4bf" />

- 다단계 큐와 유사하나 **프로세스가 큐 사이를 이동할 수 있는 방식**을 채택해 보완
- 새로운 프로세스는 최상위 큐에서 시작하며, 타임 슬라이스를 모두 사용하면 하위 큐로 이동
- 자연스럽게 CPU 집중 프로세스는 낮은 우선순위를, 입출력 집중 프로세스는 높은 우선순위를 가지게 됨
- 에이징 기법을 통해 낮은 우선순위 큐의 프로세스도 높은 우선순위 큐로 이동시켜 아사 현상 방지

## 리눅스 CPU 스케줄링

리눅스는 상황에 따라 더 다양한 알고리즘을 사용할 수 있다.

### 주요 스케줄링 정책

- **SCHED_FIFO**: 실시간성 프로세스를 위한 **선입선출** 방식
- **SCHED_RR**: 실시간성 프로세스를 위한 **라운드 로빈** 방식
- **SCHED_NORMAL**: 일반 프로세스용 **CFS**(Completely Fair Scheduler) 기반 방식
- **SCHED_BATCH**: 일반 프로세스만큼 자주 선점하지 않는 배치 작업용
- **SCHED_IDLE**: 우선순위가 매우 낮은 프로세스용

### CFS(Completely Fair Scheduler)

- 공정한 CPU 시간 분배를 목표로 하는 스케줄러
- **`vruntime`**: 프로세스의 가중치(우선순위)를 고려한 가상 실행 시간으로, 가장 작은 `vruntime`을 가진 프로세스가 우선 실행
- `vruntime` 계산식: `CPU 실행 시간 × (평균 가중치 ÷ 프로세스 가중치)`
- 프로세스의 가중치가 높을수록(**우선순위가 높을수록**) `vruntime`이 천천히 증가해 더 자주 선택

### 타임 슬라이스 할당

- CFS에서 타임 슬라이스는 프로세스의 가중치에 비례해 할당
- 계산식: `(프로세스 가중치 ÷ 전체 가중치) × 전체 타임 슬라이스 합`
- 우선순위가 높은 프로세스는 더 큰 타임 슬라이스 할당

> [!TIP]
> CFS는 **RB 트리**(Red-Black Tree) 자료구조를 활용해 `vruntime`이 가장 작은 프로세스를 효율적으로 선별 <br>
> 이 자료구조는 **최솟값과 최댓값을 빠르게 찾아내는** 데 최적화돼 있음! <br> > <img width="600" alt="image" src="https://github.com/user-attachments/assets/ac6c0106-2c62-4d7c-bb48-d5c0d414e1fa" />

# 5절. 가상 메모리

여기서는 물리적 메모리의 한계를 극복하고 외부 단편화 문제를 해결하기 위해 고안된 기술들을 살펴볼 예정. 운영체제가 현재 실행 중인 프로그램의 일부만 메모리에 적재하여 실제 메모리보다 큰 프로세스를 실행할 수 있게 하는 메모리 관리 기법 등.

보조기억장치를 메모리처럼 활용하거나 프로세스의 일부만 메모리에 적재하는 방식으로 동작함.

## 물리 주소 & 논리 주소

CPU와 프로세스는 메모리의 실제 물리 주소가 아닌 **논리 주소 체계**를 사용함.

<img width="600" alt="image" src="https://github.com/user-attachments/assets/4332098c-3e48-44dc-977d-6e7bd7045be0" />

- **물리 주소**: 하드웨어 상의 실제 메모리 주소
- **논리 주소**: 프로세스마다 부여되는, 0번지부터 시작하는 독립적 주소 체계

논리 주소와 물리 주소 간의 변환은 **메모리 관리 장치(MMU)가 담당**해 변환하고, 이를 통해 프로세스는 자신만의 주소 공간에서 독립적으로 동작 가능함.

## 스와핑

> [!NOTE]
> 현재 **실행되지 않는 프로세스**를 메모리에서 **보조기억장치의 스왑 영역**으로 내보내고, 해당 공간에 **다른 프로세스를 적재**하는 메모리 관리 방식 <br> <img width="600" alt="image" src="https://github.com/user-attachments/assets/d1921cc7-a864-4134-a5d1-d68eb674ea59" />

- **스왑 아웃**: 프로세스를 메모리에서 스왑 영역으로 내보내는 작업
- **스왑 인**: 스왑 영역에서 프로세스를 다시 메모리로 불러오는 작업

스왑 아웃되었던 프로세스는 스왑 인될 때 원래 위치와 다른 물리 주소에 적재될 수 있음.

## 외부 단편화와 연속 메모리 할당

**연속 메모리 할당 방식**에서는 프로세스가 메모리에 **연속적**으로 할당됨. 이 방식의 주요 문제는 **외부 단편화**임.

> [!NOTE]
> 외부 단편화: 프로세스들 사이에 생기는 작은 빈 공간들이 모여 **충분한 메모리** 크기가 있음에도 불구하고 **연속된 공간이 부족해 프로세스를 적재할 수 없는 현상** <br> <img width="600" alt="image" src="https://github.com/user-attachments/assets/d6d5b679-028f-45d0-9b9b-4e742be7463f" />

## 페이징을 통한 가상 메모리 관리

스와핑과 연속 메모리 할당은 문제 2개가 있음.

1. **외부 단편화**
2. 물리 메모리보다 **더 큰 프로세스 실행 불가**

이를 해결하고자 **가상 메모리가 도입**됨. 이로써 가상 주소 공간을 쓸 수 있는 것! 대표적인 가상 메모리 관리 기법은 **페이징**과 세그멘테이션(가변적 크기를 지닌 세그먼트로 분할)이 있음.

### 페이징 기본 개념

> [!NOTE]
> 프로세스의 **논리** 주소 공간을 **페이지라는 일정 크기**로 나누고, **물리** 메모리를 **동일한 크기의 프레임**으로 나눠 **페이지를 프레임에 불연속적으로 할당하는 가상 메모리 관리 기법** <br> <img width="600" alt="image" src="https://github.com/user-attachments/assets/1635d033-90a0-48cd-87fc-e1fe7a30e5ab" />

#### 페이징 주요 특징

<img width="600" alt="image" src="https://github.com/user-attachments/assets/b89e1234-3ca0-4f98-94f7-a906d6ffc47d" />

- 프로세스가 물리 메모리에 **불연속적**으로 **배치** 가능
  - 외부 단편화 문제 해결
- **페이지 단위로 스왑 인/아웃**(페이지 인/아웃) 가능
- 물리 메모리보다 큰 프로세스 실행 가능

하지만 이렇게 물리 메모리 내에 **불연속적**이고, 어떤 페이지가 어떤 프레임이 **적재**돼있는지 **모두 알기 어렵기** 때문에, **CPU가 다음으로 실행할 페이지를 찾지 못한다는 단점**이 있음.

### 페이지 테이블

위의 페이징 단점을 보완하기 위해, 프로세스의 페이지와 메모리에 실제로 적재된 프레임을 짝지어주는 페이지 테이블이 탄생함.

> [!NOTE]
> 프로세스의 **페이지**와 실제로 적재된 **프레임**을 **매핑**하는 **자료구조** <br>
> 각 프로세스마다 **별도로 유지**됨 <br> <img width="600" alt="image" src="https://github.com/user-attachments/assets/ca55f7a2-ec95-439a-8a48-b54a8958bdca" />

#### 페이지 테이블 엔트리 주요 구성 요소

<img width="600" alt="image" src="https://github.com/user-attachments/assets/ccfbbcba-c51a-404f-bc58-8eb8f4f1686a" />

- **페이지 번호 + 프레임 번호**: 기본적인 매핑 정보
- **유효 비트**: 페이지가 메모리에 있는지(1) 보조기억장치에 있는지(0) 표시
  - 이때, CPU가 0인, **보조기억장치**에 있는 **페이지**에 접근하면 **[페이지 폴트](#페이지-폴트)**라는 예외가 발생
- **보호 비트**: 읽기(r), 쓰기(w), 실행(x) 권한 지정
- **참조 비트**: CPU가 페이지에 접근했는지 여부 표시
- **수정 비트(더티 비트)**: 페이지 내용이 변경되었는지 여부 표시

#### 페이지 폴트

위 유효 비트에서 얘기했듯이, CPU가 0인, **보조기억장치**에 있는 **페이지**에 접근하면 **페이지 폴트**라는 예외가 발생함.

> [!NOTE] > **CPU가 접근**하려는 페이지가 **현재 메모리에 없을 때(유효 비트=0) 발생**하는 예외 상황

페이지 폴트 처리 과정은 아래와 같다.

1. CPU 작업 내역 백업
2. 페이지 폴트 처리 루틴 실행
   - 필요 페이지를 메모리로 가져오는, 유효비트를 1로 바꾸는 작업
3. 유효 비트를 1로 변경
4. 원래 작업 재개

#### PTBR(페이지 테이블 베이스 레지스터)

페이지 테이블만의 아주 특별한 레지스터가 있다.

> [!NOTE]
> 현재 실행 중인 **각 프로세스의 페이지 테이블 위치**를 가리키는 **레지스터** <br> > **문맥 교환** 시 함께 변경 <br> <img width="600" alt="image" src="https://github.com/user-attachments/assets/6f63a7af-7adc-4f54-99c9-629bd2d1c349" />

즉, 페이징 페이블을 사용하기 위한 CPU에 레지스터가 존재한다. 하지만 이 페이지 판독을 위해 페이지 테이블이 존재하는 메모리에 접근을 하다보니 단점이 생겼다.

#### 페이지 테이블 단점

페이지 테이블을 메모리에 적재(저장)할 경우 두 가지 주요 문제가 발생함.

1. **메모리 접근 횟수 증가**
   - 페이지 테이블 참조를 위한 메모리 접근 1회
   - 실제 데이터를 위한 메모리 접근 1회
   - 결과적으로 메모리 접근 시간이 2배로 증가
2. **메모리 용량 문제**
   - 프로세스 크기가 커질수록 페이지 테이블 크기도 증가
   - 모든 페이지 테이블을 메모리에 유지하면 상당한 메모리 낭비 발생

이 단점들을 보완하기 위해 페이징 테이블 최적화 기법은 아래와 같다.

**1. TLB(Translation Look-aside Buffer)**

> [!NOTE]
> 페이지 테이블의 캐시 메모리, 자주 사용되는 페이지 번호와 프레임 번호의 매핑 정보 저장 <br> <img width="600" alt="image" src="https://github.com/user-attachments/assets/b662c7b6-222d-4cbb-9bfc-c7c711319939" />

- **작동 원리**
  - 참조 지역성에 기반하여 최근 사용된 페이지 테이블 엔트리 저장
  - CPU가 먼저 TLB를 검색하여 페이지 번호 확인
- **성능 향상**
  - **TLB 히트**: TLB에서 페이지 번호 발견 시 즉시 프레임 번호 반환, 메모리 접근 1회로 감소
  - **TLB 미스**: TLB에 페이지 번호가 없을 경우 메모리의 페이지 테이블 참조 후 TLB 업데이트
- **효과**
  - TLB 히트율이 높을수록 평균 메모리 접근 시간 단축
  - 최신 시스템에서 TLB 히트율은 98~99%에 달해 메모리 접근 시간을 거의 절반으로 감소시킴

**2. 계층적 페이징(다단계 페이지 테이블)**

> [!NOTE] > **페이지 테이블 자체를 페이징**하여 필요한 부분만 **메모리에 유지**하는 기법 <br> <img width="600" alt="image" src="https://github.com/user-attachments/assets/785ec2bf-ac74-44d8-b167-f2d19d70b725" />

- **구조**
  - 외부 페이지 테이블(Outer Page Table): 최상위 페이지 테이블로 항상 메모리에 유지
  - 내부 페이지 테이블: 필요할 때만 메모리에 로드
- **장점**
  - 전체 페이지 테이블 중 실제 사용되는 부분만 메모리에 적재 가능
  - 메모리 사용량 대폭 감소
  - 필요에 따라 2단계, 3단계 등 여러 계층으로 구성 가능
- **단점**
  - 주소 변환 과정이 복잡해져 추가적인 메모리 접근 필요
  - TLB 없이는 성능 저하 가능성 있음

### 내부 단편화

이처럼 완벽한 페이징이라 외부 단편화 문제가 해결되지만, **내부 단편화라는 새로운 문제가 발생**함.

> [!NOTE]
> 내부 단편화: 프로세스 크기가 페이지 크기의 배수가 아닐 경우 마지막 페이지에서 발생하는 메모리 낭비 <br> <img width="600" alt="image" src="https://github.com/user-attachments/assets/848477b3-7b02-40b2-b3e3-bb497ab81fa6" />

- **예시**: 페이지 크기가 10KB인데 프로세스 크기가 107KB라면, 11개의 페이지(110KB)가 필요하고 마지막 페이지에 3KB가 낭비됨
- **트레이드오프**: 페이지 크기를 작게 하면 내부 단편화는 줄지만 페이지 테이블 크기가 증가하고, 디스크 I/O 효율이 감소함

### 페이지 테이블의 문제점과 최적화

페이지 테이블을 메모리에 저장할 경우 두 가지 주요 문제가 발생함:

1. **메모리 접근 횟수 증가**:

   - 페이지 테이블 참조를 위한 메모리 접근 1회
   - 실제 데이터를 위한 메모리 접근 1회
   - 결과적으로 메모리 접근 시간이 2배로 증가

2. **메모리 용량 문제**:
   - 프로세스 크기가 커질수록 페이지 테이블 크기도 증가
   - 모든 페이지 테이블을 메모리에 유지하면 상당한 메모리 낭비 발생

### 메모리 접근 최적화 기법

#### 1. TLB(Translation Look-aside Buffer)

> [!NOTE]
> TLB는 페이지 테이블의 캐시 메모리로, 자주 사용되는 페이지 번호와 프레임 번호의 매핑 정보를 저장함

- **작동 원리**:

  - 참조 지역성에 기반하여 최근 사용된 페이지 테이블 엔트리 저장
  - CPU가 먼저 TLB를 검색하여 페이지 번호 확인

- **성능 향상**:

  - **TLB 히트**: TLB에서 페이지 번호 발견 시 즉시 프레임 번호 반환, 메모리 접근 1회로 감소
  - **TLB 미스**: TLB에 페이지 번호가 없을 경우 메모리의 페이지 테이블 참조 후 TLB 업데이트

- **효과**:
  - TLB 히트율이 높을수록 평균 메모리 접근 시간 단축
  - 최신 시스템에서 TLB 히트율은 98~99%에 달해 메모리 접근 시간을 거의 절반으로 감소시킴

#### 2. 계층적 페이징(다단계 페이지 테이블)

> [!NOTE]
> 페이지 테이블 자체를 페이징하여 필요한 부분만 메모리에 유지하는 기법

- **구조**:

  - 외부 페이지 테이블(Outer Page Table): 최상위 페이지 테이블로 항상 메모리에 유지
  - 내부 페이지 테이블: 필요할 때만 메모리에 로드

- **장점**:

  - 전체 페이지 테이블 중 실제 사용되는 부분만 메모리에 적재 가능
  - 메모리 사용량 대폭 감소
  - 필요에 따라 2단계, 3단계 등 여러 계층으로 구성 가능

- **단점**:
  - 주소 변환 과정이 복잡해져 추가적인 메모리 접근 필요
  - TLB 없이는 성능 저하 가능성 있음

### 페이지 교체 알고리즘

메모리가 가득 찼을 때 어떤 페이지를 스왑 아웃할지 결정하는 알고리즘으로, 성능은 페이지 폴트 발생 빈도로 측정됨:

1. **FIFO(First-In First-Out)**:

   - 가장 오래 전에 메모리에 적재된 페이지부터 교체
   - 구현이 단순하지만 자주 사용되는 페이지도 교체될 수 있는 단점
   - Belady의 모순 현상 발생 가능(프레임 수를 늘렸는데 페이지 폴트가 증가하는 현상)

2. **최적(Optimal) 페이지 교체**:

   - 앞으로 가장 오랫동안 사용되지 않을 페이지를 교체
   - 이론적으로 최소의 페이지 폴트율 보장
   - 미래 참조를 예측해야 하므로 실제 구현은 불가능(벤치마크로 활용)

3. **LRU(Least Recently Used)**:
   - 가장 오랫동안 사용되지 않은 페이지 교체
   - 시간적 지역성 원리에 기반하여 좋은 성능 제공
   - 모든 메모리 참조를 기록해야 하므로 구현 비용이 높음
   - 실제로는 LRU 근사 알고리즘(Clock 알고리즘 등) 주로 사용

### 내부 단편화

페이징에서는 외부 단편화 문제가 해결되지만, 내부 단편화라는 새로운 문제가 발생함:

> [!NOTE]
> 내부 단편화: 프로세스 크기가 페이지 크기의 배수가 아닐 경우 마지막 페이지에서 발생하는 메모리 낭비

- **예시**: 페이지 크기가 4KB인데 프로세스 크기가 10KB라면, 3개의 페이지(12KB)가 필요하고 마지막 페이지에 2KB가 낭비됨
- **트레이드오프**: 페이지 크기를 작게 하면 내부 단편화는 줄지만 페이지 테이블 크기가 증가하고, 디스크 I/O 효율이 감소함

### 페이징 주소 체계

페이징 시스템에서 논리 주소는 `<페이지 번호, 변위>` 형태로 구성돼 물리 주소로 변환됨.

#### 페이징 시스템의 주소 변환 과정

<img width="600" alt="image" src="https://github.com/user-attachments/assets/d7128589-a38c-42b0-b57d-689bde9c2cca" />

- **논리 주소 구조**
  - **페이지 번호**: 접근할 페이지를 식별하는 상위 비트
  - **변위(Offset)**: 페이지 내 위치를 나타내는 하위 비트
- **주소 변환 과정**
  1. CPU가 논리 주소 `<페이지 번호, 변위>`를 생성
  2. **페이지 테이블**에서 **페이지 번호에 해당**하는 **프레임 번호 조회**
  3. 프레임 번호와 변위를 결합하여 물리 주소 `<프레임 번호, 변위>` 생성
  4. 생성된 물리 주소로 메모리 접근
- **변위 값**
  - 페이지 내에서의 **상대적 위치**를 나타냄
  - 페이지와 프레임 크기가 동일하므로 논리 주소와 물리 주소의 변위 값은 동일

만일, 페이지 크기가 4개 주소인 시스템에서 논리 주소 <5, 2>(5번 페이지, 변위 2)가 있다고 가정해보자.

1. 페이지 테이블에서 5번 페이지가 1번 프레임에 있음을 확인
2. 물리 주소는 `<1, 2>`(1번 프레임, 변위 2)로 변환
3. 1번 프레임은 물리 주소 8번지부터 시작하므로 최종 접근 주소는 10번지(8+2)

<img width="600" alt="image" src="https://github.com/user-attachments/assets/c8da27e2-a00b-427d-8877-d39ebe6a544a" />

## 스왑 아웃 기법: 페이지 교체 알고리즘

이전까진 요구되는 페이지(요구 페이징 시스템)만 적재하는 기법을 살펴봤다.

### 요구 페이징 시스템

> [!NOTE]
> 프로세스 실행 시 필요한 페이지만 메모리에 적재하는 기법으로, 메모리 사용량을 최적화함

**작동 과정**은 아래와 같다.

1. CPU가 논리 주소에 접근 시도
2. 페이지 테이블에서 해당 페이지의 유효 비트 확인
3. 유효 비트가 1이면 메모리에서 데이터 접근
4. 유효 비트가 0이면 페이지 폴트 발생하여 다음 단계 수행:
   - 현재 CPU 작업 내역 백업
   - 페이지 폴트 처리 루틴 호출
   - 보조기억장치에서 필요한 페이지를 빈 프레임에 적재
   - 페이지 테이블 업데이트(유효 비트 1로 설정)
   - 중단된 명령어부터 실행 재개

이러한 **순수 요구 페이징**은 처음에 어떤 페이지도 메모리에 적재하지 않고 시작하는 방식임. 초기 실행 시 다수의 페이지 폴트가 발생하지만 필요한 페이지가 메모리에 적재된 후 안정화됨.

하지만 이제 이렇게 적재된 페이지들을 적절하게 스왑 아웃 시켜야 한다. 그에 대한 기법도 설명하고 있다.

### 페이지 교체 알고리즘

> [!NOTE]
> 메모리가 가득 찼을 때 **어떤 페이지를 스왑 아웃할지 결정**하는 알고리즘 <br>
> 성능은 **페이지 폴트 발생 빈도**로 측정, 좋은 알고리즘은 **페이지 폴트를 최소화**함

1. **FIFO(First-In First-Out)**
   - 가장 **오래 전에 메모리에 적재**된 페이지부터 교체
   - 구현이 단순하지만 자주 사용되는 페이지도 교체될 수 있는 단점
   - Belady의 모순 현상 발생 가능(프레임 수를 늘렸는데 페이지 폴트가 증가하는 현상)
2. **최적(Optimal) 페이지 교체**
   - **앞으로 가장 오랫동안 사용되지 않을 페이지**를 교체
   - 이론적으로 최소의 페이지 폴트율 보장
   - 미래 참조를 예측해야 하므로 실제 구현은 불가능(벤치마크로 활용)
3. **LRU(Least Recently Used)**
   - **가장 오랫동안 사용되지 않은 페이지** 교체
   - 시간적 지역성 원리에 기반하여 좋은 성능 제공
   - 모든 메모리 참조를 기록해야 하므로 구현 비용이 높음
   - 실제로는 **LRU 근사** 알고리즘(**Clock 알고리즘** 등) 주로 사용

> [!WARNING]
> 만일 페이지 교체 알고리즘이 비효율적이라 페이지 폴트가 많이 일어나면 **스래싱**이 일어남 <br>
> 스래싱(Thrashing): 과도한 페이지 폴트로 **CPU가 실제 작업보다 페이지 교체에 더 많은 시간을 소모하는 현상**

> [!TIP]
> 페이지 폴트는 처리 방식과 비용에 따라 두 가지로 구분됨
>
> 1. **메이저 페이지 폴트**
>    - 보조기억장치에서 페이지를 읽어와야 하는 경우
>    - 디스크 I/O가 필요하므로 처리 비용이 매우 높음(수 밀리초)
>    - 전형적인 페이지 폴트로, CPU가 접근하려는 페이지가 메모리에 없을 때 발생
> 2. **마이너 페이지 폴트**
>    - 페이지가 이미 물리 메모리에 있지만 페이지 테이블에 반영되지 않은 경우
>    - 보조기억장치 접근 없이 페이지 테이블만 업데이트하므로 처리 비용이 낮음
>    - 다른 프로세스와 공유된 메모리나 메모리 매핑 파일 등에서 주로 발생
