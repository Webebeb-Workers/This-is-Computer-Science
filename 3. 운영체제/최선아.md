# 2. 프로세스와 스레드

- 메모리에는 컴퓨터가 실행되는 순간 다양한 프로세스들이 적재되어 실행됨

## 프로세스의 유형

- 프그라운드 프로세스: 사용자가 보는 공간에서 사용자와 상호작용하며 실행되는 프로세스
- 백그라운드 프로세스:사용자가 보지 못하는 곳에서 실행되는 프로세스
  - 데몬(서비스): 사용자와 상호작용 없이 주어진 작업만 수행하는 특별한 백그라운드 프로세스

## 메모리 정보

![Image](https://github.com/user-attachments/assets/b6352048-f7cd-4a03-b4e3-bd2dfaa8406c)

- 프로세스 유형을 막론하고 하나의 프로세스를 구성하는 메모리 내의 정보는 크게 다르지 않음
- 커널 영역: 프로세스 제어 블록(PCB) 정보가 저장
- 사용자 영역: 코드 영역, 데이터 영역, 힙 영역, 스택 영역 저장

### 1. 코드 영역

- 실행 가능한 명령어가 저장되는 공간
- 텍스트 영역이라고도 부름
- 쓰기 금지 공간(read-only)
- 정적 할당 영역: 프로그램 실행 도중 크기가 변하지 않음

### 2. 데이터 영역

- 프로그램이 실행되는 동안 유지할 데이터가 저장되는 공간
- 정적 변수, 전역 변수가 저장됨
- BSS: 초기값이 있는 데이터는 데이터 영역에 저장, 초기값이 없는 데이터는 BSS 영역에 저장됨
- 정적 할당 영역: 프로그램 실행 도중 크기가 변하지 않음

### 3. 힙 영역

- 프로그램을 만드는 사용자(개발자)가 직접 할당 가능한 저장 공간
- 프로그램 실행 도중 비교적 자유롭게 할당하여 사용 가능한 메모리 공간
- 메모리 공간을 할당한 후 반환하지 않으면 메모리 낭비인 메모리 누수 문제 초래
- 가비지 컬렉션: 프로그래밍 언어에서 자체적으로 메모리를 해제하는 기능을 제공하기도 함

### 4. 스택 영역

- 일시적으로 사용할 값들이 저장되는 공간
- 함수의 실행이 끝나면 사라지는 매개변수, 지역변수, 함수 복귀 주소 등이 저장됨
- 스택 트레이스: 특정 시점에 스택 영역에 저장된 함수 호출 정보가 저장됨
  - 문제의 발생 지점을 추적할 수 있어, 디버깅에 유용함
    ![Image](https://github.com/user-attachments/assets/8ead8b0b-66b3-4d37-94fd-7b84f768b813)

## PCB와 문맥 교환

### PCB란

- PCB(Process Control Block): 운영체제가 메모리에 적재된 다수의 프로세스를 관리하기 위한, 프로세스를 식별할 수 있는 커널 영역 내의 정보
- 프로세스와 관련한 다양한 정보를 내포하는 구초제로, 새로운 프로세스가 메모리에 적재됐을 때 커널 영역에 만들어지고, 프로세스의 실행이 끝나면 폐기됨
- PCB에 담기는 정보
  - PID: 프로세스 식별 번호
  - 프로세스가 실행과정에서 사용한 레지스터 값
  - 프로세스 상태
  - CPU 스케줄링 정보: 어떤 순서로 CPU를 할당받을지
  - 메모리 관련 정보: 프로세스의 메모리상 적재 위치
  - 프로세스가 사용한 파일 및 입출력장치 관련 정보
- 예시(리눅스 운영체제의 PCB인 task_struct 구조체)
  ![Image](https://github.com/user-attachments/assets/02362b8d-1d11-41b3-9dfc-fdd459a25f42)

### 프로세스 테이블

![Image](https://github.com/user-attachments/assets/1835f447-879f-452f-8c04-18f584eb4b49)

- 프로세스 테이블: 여러 PCB들이 관리되는 형태, 실행중인 PCB들의 모음
- 새롭게 실행되는 프로세스가 있으면 해당 프로세스의 PCB를 프로세스 테이블에 추가하고, 필요한 자원을 할당함
- 종료되는 프로세스가 있다면 사용중이던 자원을 해제하고 PCB에도 프로세스 테이블에서 삭제됨
- 좀비 프로세스: 프로세스가 비정상 종료되어 사용한 자원이 회수되었음에도 프로세스 테이블에 종료된 프로세스의 PCB가 남아있는 프로세스

### 문맥

- 메모리에 적재된 프로세스들은 한정된 시간 동안 번갈아 가며 실행됨
- 프로세스가 실행된다: 운영체제에 의해 CPU의 자원을 할당받았다는 뜻
- 프로세스의 CPU 사용 시간은 타이머 인터럽트에 의해 제한됨
  - 타이머 인터럽트(타임아웃 인터럽트): 시간이 끝났음을 알림
- 프로세스는 자신의 차례가 되면 정해진 시간만큼 CPU를 이용하고, 타이머 인터럽트가 발생하면 자신의 차례를 양보하고 다음 차례가 올 때까지 기다림
- 다시 차례가 왔을 때 이전까지 실행했던 내용을 이어서 재개하기 위해 프로그램 카운터, 레지스터 값, 메모리 정보 등 지금까지의 중간 정보를 **백업**해야함
- 문맥: 프로세스의 수행을 재개하기 위해 기억해야 할 정보

### 문맥 교환

![Image](https://github.com/user-attachments/assets/48a1ccf5-c062-4d49-b106-a78536d1fa0f)

- 프로세스가 CPU를 사용할 수 있는 시간이 다 되거나 인터럽트가 발생하면 운영체제는 해당 프로세스의 PCB에 문맥을 백업하고 뒤이어 실행할 프로세스의 문맥을 복구함
- 문맥 교환: 기존 프로세스의 문맥을 PCB에 백업하고, PCB에서 문맥을 복구하여 새로운 프로세스를 실행하는 것
- 여러 프로세스가 끊임없이 빠르게 번갈아 가며 실행되는 원리
- 프로세스 간에 너무 잦은 문맥 교환이 발생하면 캐시 미스가 발생할 가능성이 높아져 메모리에 접근할 일이 많아지고, 이는 큰 오버헤드로 이어질 수 있음

## 프로세스의 상태

![Image](https://github.com/user-attachments/assets/6827641c-5b12-46d3-b0ff-f854743e2687)

- 하나의 프로세스는 여러 상태를 거치며 실행됨
- 운영체제는 PCB를 통해 프로세스의 상태를 인식하고 관리함
- 대표적인 상태: 생성, 준비, 실행, 대기, 종료

### 생성 상태

- 프로세스를 생성 중인 상태로, 메모리에 적재되어 PCB를 할당받은 상태
- 생성 상태를 거쳐 실행할 준비가 완료된 프로세스는 준비 상태가 되어 CPU의 할당을 기다림

### 준비 상태

- CPU를 할당받아 실행할 수 있지만, 자신의 차례가 아니기 때문에 기다리고 있는 상태
- 준비 상태인 프로세스가 CPU를 할당받으면 실행 상태가 되며, 준비 상태인 프로세스가 실행 상태로 전환되는 것을 디스패치(dispatch) 라고 함

### 실행 상태

- CPU를 할당받아 실행중인 상태
- 일정 시간동안만 CPU를 사용할 수 있음
- 타이머 인터럽트가 발생하여 프로세스가 할당된 시간을 모두 사용하면 다시 준비 상태가 됨
- 실행 도중 입출력장치를 사용하여 입출력장치의 작업이 끝날 때까지 기다려야 하면 대기 상태가 됨

### 대기 상태

- 프로세스가 입출력 작업을 요청하거나 바로 확보할 수 없는 자원을 요청하는 등 곧장 실행이 불가능한 조건에 놓이는 경우 대기 상태가 됨
- 입출력 작업을 요청하는 경우가 대표적임
- 대기 상태였던 해당 프로세스는 입출력 작업이 완료되는 등 실행 가능한 상태가 되면 다시 준비 상태가 되어 CPU 할당을 기다림

### 종료 상태

- 프로세스가 종료된 상태
- 프로세스가 종료되면 운영체제는 PCB와 프로세스가 사용한 메모리를 정리함

## 멀티프로세스와 멀티스레드

### 멀티프로세스

- 동시에 여러 프로세스가 실행되는 것
- 각기 다른 프로세스들이 기본적으로 자원을 공유하지 않고, 독립적으로 실행됨 -> 한 프로세스의 실행 과정에서 문제 발생하더라도 다른 프로세스에 영향 x

### 멀티스레드

![Image](https://github.com/user-attachments/assets/3540e9a4-5647-430e-b78e-a7209eb1e735)

- 프로세스를 동시에 실행하는 여러 스레드
- 하나의 스레드는 스레드를 식별할 수 있는 고유 정보인 스레드 ID, 프로그램 카운터, 레지스터 값, 스택 등으로 구성됨
- 스레드마다 각각의 프로그램 카운터 값과 스택을 가지고 있기 때문에 스레드마다 다음에 실행할 주소를 가질 수 있고, 연산 과정의 임시 저장 값을 가질 수 있음

### 멀티프로세스 vs 멀티스레드

- 가장 큰 차이점은 자원의 공유 여부임
- 서로 다른 프로세스들은 기본적으로 자원을 공유하지 않기 때문에 독립적으로 실행됨 -> 한 프로세스에 문제 생겨도 다른 프로세스에 지정 없거나 적음
- 같은 프로세스를 실행하는 여러 스레드들은 프로세스의 자원을 공유함 -> 한 스레드에 생긴 문제가 프로세스 전체의 문제가 될 수 있음
  - 코드/데이터/힙 영역, 열린 파일 등을 공유하기 때문에 쉽게 협력하고 통신할 수 있음

## 프로세스 간 통신

![Image](https://github.com/user-attachments/assets/a750779f-2fcc-43fb-a006-1d412df515cd)

- IPC(Inter-Process Communication): 프로세스 간에도 자원을 공유하고 데이터를 주고 받을 수 있는 방법
- 프로세스 간 통신이 이루어지는 방식: 공유 메모리, 메시지 전달

### 공유 메모리

- 데이터를 주고받는 프로세스가 공통적으로 사용할 메모리 영역을 두는 방식
- 공유 메모리라는 특별한 메모리 공간을 할당하여 프로세스가 해당 메모리 공간을 공유하여 읽고 쓸 수 있도록 함
- 공유 메모리 영역을 확보하는 시스템 콜을 기반으로 수행될 수도 있고, 간단하게 프로세스가 공유하는 변수나 파일을 활용할 수도 있음
- 각 프로세스가 마치 자신의 메모리 영역을 읽고 쓰는 것처럼 통신함
- 프로세스가 주고받는 데이터가 커널 영역을 거치지 않는 경우가 많음
- 각 프로세스가 단순히 각자의 메모리 영역을 읽고 쓰는 것일 뿐이므로 메시지 전달 방식보다 통신 속도가 빠름
- 레이스 컨디션: 메모리 영역을 동시에 읽고 쓸 경우, 데이터의 일관성이 훼손될 수 있음

### 메시지 전달

- 프로세스 간에 주고받을 데이터를 커널을 거쳐 메시지의 형태로 주고받는 방식
- 메시지를 보내고 받는 시스템콜이 명확하게 정해져있음
  - send(): 메시지를 보내는 시스템 콜
  - recv(): 메시지를 받는 시스템 콜
- 커널의 도움을 받으므로 레이스 컨디션, 동기화 등의 문제를 고려하는 일이 상대적으로 적음
- 데이터가 커널을 통해 송수신 되므로 공유 메모리 기반보다 통신 속도가 느림
- 대표적인 수단: 파이프, 시그널, 소켓, 원격 프로시저 호출(RPC) 등이 있음

> RPC가 뭐지

#### 파이프

![Image](https://github.com/user-attachments/assets/b4d1d7ae-4be7-4ffb-b58f-c65e713088fe)

- 단방향 프로세스 간의 통신 도구
- 양방향 통신을 수행할 경우, 읽기용 파이프와 쓰기용 파이프 2개 필요
- 익명 파이프: 양방향 통신을 지원하지 않고, 부모 프로세스와 자식 프로세스 간에만 통신 가능
- 지명 파이프: 양방향 통신을 지원하며, 임의의 프로세스 간에도 통신 가능

#### 시그널

![Image](https://github.com/user-attachments/assets/1dbd172c-b26c-4766-868c-21621ff96cdf)

- 프로세스에게 특정 이벤트가 발생했음을 알리는 비동기적 신호
- 시그널 자체는 IPC만을 위한 개념이 아니라 '시그널을 적절히 활용해 IPC를 수행할 수 있다' 임
- 리눅스 운영체제의 대표적인 시그널 예시
  - 대부분 인터럽트 관련 시그널이지만, 사용자 정의 시그널도 가능
    | 시그널 | 설명 | 기본 동작 |
    |-------|------|---------|
    | SIGCHLD | 자식 프로세스 종료 | 무시 |
    | SIGILL | 허용하지 않은 명령어 실행 | 코어 덤프 생성 후 종료 |
    | SIGINT | 키보드 인터럽트(Ctrl + C) | 종료 |
    | SIGKILL | 프로세스 종료(핸들러 재정의 불가능) | 종료 |
    | SIGSEGV | 잘못된 메모리 접근 | 코어 덤프 생성 후 종료 |
    | SIGTERM | 프로세스 종료(핸들러 재정의 가능) | 종료 |
    | SIGUSR1 | 사용자 정의 시그널 | 종료 |
    | SIGUSR2 | | 종료 |
- 프로세스는 시그널이 발생하면 인터럽트 처리 과정과 유사하게 하던일을 잠시 중단하고, 시그널 처리를 위한 **시그널 핸들러**를 실행한 뒤 실행을 재개함
- 프로세스는 직접 특정 시그널을 발생시킬 수 있고, 일부 시그널 핸들러를 (재)정의 할 수도 있음
- 시그널을 이용하는 방법은 직접적으로 메시지를 주고받지는 않지만, 비동기적으로 원하는 동작을 수행할 수 있는 좋은 수단임
- 코어 덤프: 주로 비정상적으로 종료하는 경우에 생성되는 파일로, 프로그램이 특정 시점에 작업하던 메모리 상태가 기록됨

  ```
  $ coredumpctl info
  PID: 7990 (python3)
  UID: 1000 (minchu1)
  GID: 1000 (minchu1)
  Signal: 11 (SEGV)
  Timestamp: Mon 2024-02-26 15:40:36 KST (1min 1s ago)
  Command Line: python3 coredumped.py
  Executable: /usr/bin/python3.8
  Control Group: /user.slice/user-1000.slice/session-33.scope
  Unit: session-33.scope
  Slice: user-1000.slice
  Session: 33
  Owner UID: 1000 (minchu1)
  Boot ID: abcdeabcde1234512345abcde12345ab
  Machine ID: abcde12345abcde12345abcde12345ab
  Hostname: homeserver
  Storage: /var/lib/systemd/coredump/core.python3.1000.abcdeabc...2345000000000000.123
  Message: Process 7990 (python3) of user 1000 dumped core.
    Stack trace of thread 7990:
    #0 0x00007f220dcb3f45 n/a (\_ctypes.cpython-38-x86_64-linux-gnu.so + 0x9f45)
    #1 0x00007f220e8efff5 n/a (libffi.so.7 + 0x6ff5)
    #2 0x00007f220e8ef40a n/a (libffi.so.7 + 0x640a)
    ...
    #15 0x0000000000673abb n/a (python3.8 + 0x273abb)
    #16 0x0000000000673b61 n/a (python3.8 + 0x273b61)
    #17 0x00000000006747e7 PyRun_SimpleFileExFlags (python3.8 + 0x2747e7)
    #18 0x000000000006b4072 Py_RunMain (python3.8 + 0x2b4072)
    #19 0x000000000006b43fd Py_BytesMain (python3.8 + 0x2b43fd)
    #20 0x00007f220e717083 \_\_libc_start_main (libc.so.6 + 0x24083)
    #21 0x000000000005da67e \_start (python3.8 + 0x1da67e)
  ```

> 재정의 가능/불가능한 시그널에는 뭐가 있을까?
> 특정 프로세스로 시그널을 어떻게 보낼 수 있는걸까?

#### 이 외의 방법들

- 이외에도 원격 프로시저 호출(RPC)나 네트워크 소켓을 통해 IPC를 수행할 수도 있음

**RPC**

- 원격 코드를 실행하는 IPC 기술
- 한 프로세스 내의 특정 코드 실행이 로컬 프로시저 호출이라면, 다른 프로세스의 원격 코드 실행이 원격 프로시저 호출인 셈
- RPC를 통해 프로그래밍 언어나 플랫폼과 무관하게 성능 저하를 최소화하고, 메시지 송수신이 가능하기 때문에 대규모 트래픽 처리 환경, 특히 서버 간 통신 환경에서 사용되는 경우가 많음

> RPC 자체가 뭔지 잘 이해가 안감

# 3. 동기화와 교착 상태

<img width="521" alt="Image" src="https://github.com/user-attachments/assets/192c45d0-56e8-4ecf-b32f-0f3ca2c2ce76" />

- 공유 자원: 프로세스 혹은 스레드가 공유하는 자원으로, 메모리나 파일이 될 수도 있고, 전역 변수나 입출력 장치가 될 수도 있음
- 임계 구역: 공유 자원에 접근하는 코드 중 동시에 실행했을 때 문제가 발생할 수 있는 코드
  - 즉, 동시에 실행되는 프로세스나 스레드가 동시에 임계 구역에 진입하여 실행되면 문제가 발생할 수 있음
- 레이스 컨디션: 프로세스 혹은 스레드가 동시에 임계 구역의 코드를 실행하여 문제가 발생하는 상황
  - 레이스 컨디션이 발생하면 자원의 일관성이 손상될 수 있기 때문에 2개 이상의 프로세스 혹은 스레드가 임계 영역에 진입하고자 한다면 둘 중 하나는 대기해야함
- 동기화: 레이스 컨디션을 방지하면서 임계 구역을 관리하기 위한 방법
  - 실행 순서 제어: 프로세스 및 스레드를 올바른 순서로 실행하기
  - 상호 배제: 동시에 접근해서는 안 되는 자원에 하나의 프로세스 및 스레드만 접근하기

## 프로세스 간 통신에서 임계 구역

- 프로세스 공유 메모리에 무언가를 쓰기 전에 메모리를 읽으려 할 경우 아직 쓰이지 않은 메모리이기 때문에 문제가 될 수 있음

- 즉, 프로세스 A의 '공유 메모리 공간에 데이터를 쓰는 코드'와 프로세스 B의 '공유 메모리 공간을 읽는 코드'는 임계 구역임
  <img width="500" alt="Image" src="https://github.com/user-attachments/assets/9e0bb504-b6fa-4752-ba45-2e131583900a" />
  - 실행 순서 제어를 위한 동기화가 필요함

## 스레드 간 통신에서 임계 구역

- 동시에 파일을 수정하는 스레드의 경우, 스레드 A와 B가 동시에 수행될 경우, 스레드 A의 작업 내역이 반영되지 않을 수 있음
  <img width="568" alt="Image" src="https://github.com/user-attachments/assets/3ebd50f9-58b5-49c6-846d-442e562be709" />

  - 각 스레드가 파일을 수정하는 코드는 임계 구역이 되며 상호 배제를 위한 동기화가 필요함

- 혹은 실행 도중에 문맥 교환이 발생하면 스레드 A의 작업이 반영되지 않을 수 있음
  <img width="571" alt="Image" src="https://github.com/user-attachments/assets/b2da367a-93d1-42ce-b05b-f075be95551c" />

  - 각 스레드가 파일을 수정하는 코드는 임계 구역이 되며 상호 배제를 위한 동기화가 필요함

## 동기화 기법

- 실행 순서 제어와 상호 배제를 보장하기 위한 동기화 기법 어떤 것이 있는지 알아보자

### 뮤텍스 락

- 뮤텍스 락: 동시에 접근해서는 안되는 자원에 동시 접근이 불가능하도록 상호 배제를 보장하는 동기화 도구 즉, 상호배제를 위한 락
- 원리: 임계 구역에 접근하고자 한다면 반드시 락(lock)을 획득해야 하고, 임계 구역에서의 작업이 끝났다면 락을 해제해야 함
- 작동 원리
  - 프로세스 및 스레드가 공유하는 변수(lock)와 2개의 함수(acquire, release)로 구현됨
  - acquire(): 락을 획득하기 위한 함수로, 특정 락에 대해 한 번만 호출이 가능한 함수
  - release(): 획득한 락을 해제하기 위한 함수
  - 임계 구역에 진입하려면 lock.acquire()을 호출해야하고, 이후 다른 프로세스 및 스레드가 lock.acquire()를 호출해도 락을 획득할 수 없고 락이 해제될 때 까지 기다려야 함
  - 임게 구역의 작업이 끝나면 락을 해제하기 위해 lock.release()를 호출하며, 대기하는 프로세스 혹은 스레드가 비로소 락을 획득하고 임계 구역에 진입하게 됨
  ```
  lock.acquire()
  // 임계 구역
  // lock.release()
  ```
- 예시: 공유 자원 1개, P1과 P2가 공유 자원에 접근하려는 프로세스, P1과 P2 순서로 임계 구역에 접근하는 상황
  <img width="559" alt="Image" src="https://github.com/user-attachments/assets/eb110672-45f1-4525-bd72-d3fd82f11933" />

### 세마포

- 세마포: 공유 자원이 여러 개 있는 상황에서도 동기화 해주는 도구
  - 뮤텍스 락은 공유 자원이 하나일 때만 고려하는 동기화 도구
- 작동 원리
  - 변수 S: 사용 가능한 공유 자원의 개수를 나타내는 변수
  - wait(): 임계 구역 진입 전 호출하는 함수
  - signal: 임계 구역 진입 후 호출하는 함수
  ```
  wait()
  // 임계 구역
  signal()
  ```
- 종류:
  - 이진 세마포: S가 0과 1의 값을 가지는 세마포, 사실상 뮤텍스 락과 유사하게 동작함
  - 카운팅 세마포: 공유 자원이 여러 개일 때 사용할 수 있는 세마포
  - 보통 세마포는 카운팅 세마포를 의미하는 경우가 많음

#### wait 함수

- wait 함수 호출 시
  1. '사용 가능한 공유 자원의 개수'를 나타내는 변수 S를 1 감소
  2. 변수 S의 값이 0보다 작은지 여부 확인하고, 0 이상이면 wait()를 호출한 프로세스 및 스레드는 임계 구역에 진입함.
  3. 0 미만이면 wait()를 호출한 프로세스 및 스레드는 대기 상태로 전환되어 임계 구역에 진입할 수 없게 됨
  ```
  wait() {
    S--;   // 1
    if(S < 0) { // 2
      sleep(); // 3
    }
  }
  ```

#### signal 함수

- signal은 함수 호출 시
  1. '사용 가능한 공유 자원의 개수'를 나타내는 변수 S를 1 증가
  2. 변수 S의 값이 0 이하인지를 확인하고 0이하이면 임계 구역에 진입하기 위해 대기하는 프로세스 또는 스레드가 존재하는 의미이므로
  3. 대기 상태로 접어든 프로세스 중 하나를 준비 상태로 전환함
  ```
  signal() {
    S++
    if(S <= 0) {
      wakeup(p)
    }
  }
  ```

#### 예시

- 공유 자원 2개, 접근 하려는 프로세스 3개(P1, P2, P3), P1 -> P2 -> P3 순서로 임계 구역 접근하는 상황

<img width="560" alt="Image" src="https://github.com/user-attachments/assets/7ee6cd9d-b671-4ae1-a046-2e3e437c1e7d" />

### 조건 변수와 모니터

#### 조건 변수

- 조건 변수: 실행 순서 제어를 위한 동기화 도구로, 특정 조건 하에 프로세스를 실행/일시 중단함으로써 프로세스나 스레드의 실행 순서를 제어할 수 있음
- 작동 원리
  - wait(): 호출한 프로세스 및 스레드의 상태를 대기 상태로 전환하는 함수
  - signal(): wait()으로 일시 중지된 프로세스 및 스레드의 실행을 재개하는 함수
  - 즉, 아직 특정 프로세스가 실행될 조건이 되지 않았을 때는 wait()을 통해 실행을 중단하고, 특정 프로세스가 실행될 조건이 충족됐을 때 signal()을 통해 실행을 재개함
- 예시:
  - cv라는 조건 변수가 있고, 프로세스 P1의 실행 도중에 조건 변수 cv에 대해 wait() 함수를 호출했다고 가정하자. 이 프로세스는 다른 스레드가 cv.signal()을 호출하기 전까지 대기 상태임
    <img width="242" alt="Image" src="https://github.com/user-attachments/assets/ccdc5614-65ca-4cfa-bbbc-b8d7575d3f68" />

> 182p. 예제코드 헷갈림, t1에서 cond.await()하고 t2에서 lock.lock하고 있는데 t1에서 lock.unlock 실행되지 않은 상태 아닌가? 어떻게 가능한거지?

#### 모니터

<img width="569" alt="Image" src="https://github.com/user-attachments/assets/9c1a61a9-7d07-4816-a626-0205379a4358" />

- 모니터: 공유 자원과 그 공유 자원을 다루는 함수로 구성된 동기화 도구로, 상호 배제를 위한 동기화뿐만 아니라 실행 순서 제어를 위한 동기화까지 가능함
- 작동 원리:
  - 프로세스 및 스레드는 공유 자원에 접근하기 위해 반드시 정해진 공유 자원 연산을 통해 모니터 내로 진입해야 함
  - 모니터 안에 진입하여 실행되는 프로세스 및 스레드는 항상 하나여야 함
  - 이미 모니터 내로 진입하여 실행 중인 프로세스 및 스레드가 있다면 큐에서 대기해야 함

#### 조건 변수와 모니터를 함께 활용

- 조건 변수와 모니터를 함께 활용하면 실행 순서 제어를 위한 동기화도 구현 할 수 잇음
- 예시: 동시에 실행되는 프로세스 A, B 중 반드시 A가 먼저 실행되고, 다음으로 B가 실행돼야 한다는 조건
  - 프로세스 B는 모니터 내에서 실행되기 전 프로세스 A의 실행이 끝났는지 검사 후 모니터 내로 진입하여 실행됨
    <img width="572" alt="Image" src="https://github.com/user-attachments/assets/2b90d27a-52aa-4550-9970-4a8127c8db7a" />
  - 만약 프로세스 B가 프로세스 A보다 먼저 모니터 내로 진입했을 경우, 특정 조건변수에 대해 cv.wait()를 호출해서 프로세스 B를 대기 상태로 접어들게 함
    <img width="535" alt="Image" src="https://github.com/user-attachments/assets/b7efe8ce-ae78-42d4-a7d0-962ca26982e3" />
  - 프로세스 B가 대기하고 있는 사이 프로세스 A가 모니터 내로 진입하여 실행될 수 있고, 실행 이후 cv.signal()을 호출하여 대기 상태에 있던 프로세스 B를 모니터 안으로 재진입시킬 수 있음
    <img width="575" alt="Image" src="https://github.com/user-attachments/assets/211efda9-b476-4cf8-8504-4fa00525ab34" />
  - 즉, 반드시 프로세스 A -> 프로세스 B 순서로 실행되므로 실행 순서 제어를 위한 동기화가 이루어짐

> 모니터랑 위의 세마포/뮤텍스 락과는 뭐가 다른거지??

### 스레드 안전

- 스레드 안전: 멀티스레드 환경에서 어떤 변수나 함수, 객체에 동시 접근이 이루어져도 실행에 문제가 없는 상태
  - 레이스 컨디션이 발생했다면 스레드 안전하지 않은 것을 의미
- 예시
  - 자바 Vector의 add 메서드 코드 내부가 모니터 기반의 동기화를 제공하는 synchronized 키워드로 구현돼있음 -> 여러 스레드가 동시에 실행돼도 안전함
  - 자바 ArrayList의 add 메서드는 코드 내부에 synchronized 키워드가 없음 -> 스레드 안전성이 보장되지 않기 때문에 여러 스레드로 동시에 실행하면 레이스 컨디션 발생할 수 있음

## 교착 상태

<img width="276" alt="Image" src="https://github.com/user-attachments/assets/ba7e5e6d-0e02-480d-875b-9aef5d39a203" />

- 프로세스를 실행하기 위해서는 자원이 필요함
- 2개 이상의 프로세스가 각자 가지고 있는 자원을 무작정 기다리면 어떤 프로세스도 진행할 수 없는 교착 상태가 발생할 수 있음
- 교착 상태: 일어나지 않을 사건을 기다리며 프로세스의 진행이 멈춰 버리는 현상
- 프로세스 A는 자원 X를 점유한 채 프로세스 B가 점유하고 있는 자원 Y의 사용이 끝나기를 기다리고, 프로세스 B는 자원 Y를 점유한 채 프로세스 A가 점유한 자원 X의 사용이 끝나기를 기다리면 결국 두 프로세스는 서로가 가진 자원을 기다리다가 프로세스를 실행하지 못할 수 있음 즉, 교착 상태 발생

### 교착 상태의 발생 조건

- 교착 상태가 발생하는 상황의 4가지 필요 조건: 상호 배제 ,점유와 대기, 비선점, 원형 대기
- 4가지 조건이 모두 만족할 때 교착 상태가 발생할 가능성이 생김
- 하나라도 만족하지 않는다면 교착 상태는 발생하지 않음

#### 1. 상호 배제

- 자원을 한 번에 하나의 프로세스만 사용 가능한 상황

#### 2. 점유와 대기

- 한 프로세스가 어떤 자원을 할당받은 상태에서 다른 자원을 할당받기를 기다리는 상황

#### 3. 비선점

- 어떤 프로세스도 다른 프로세스의 자원을 강제로 빼앗지 못하는 상황

#### 4. 원형 대기

<img width="575" alt="Image" src="https://github.com/user-attachments/assets/fee4a8f6-e51c-47b5-93ac-5f988841c2f3" />

- 프로세스와 프로세스가 요청한 자원이 원의 형태를 이루는 경우

### 교착 상태의 해결 방법

- 예방: 운영체제는 애초에 교착 상태의 발생 조건에 부합하지 않도록 자원을 분배하는 방식으로 교착 상태를 예방할 수 있음
- 회피: 교착 상태가 발생하지 않을 정도로 자원을 할당하다가 교착 상태의 위험이 있을 때 자원을 할당하지 않는 방식으로 교착 상태를 회피
- 검출한 후 회복: 자원을 제약 없이 할당하다가 교착 상태를 검출한 후 회복할 수도 있음

#### 1. 교착 상태 예방

- 교착 상태를 발생시키는 4가지 필요 조건 중 하나를 충족하지 못하게 하는 방법
- 예시

  - 한 프로세스에 필요한 자원들을 몰아주고, 그 다음에 다른 프로세스에 필요한 자원을 몰아주기 -> 점유와 대기 조건 만족 x
  - 할당 가능한 모든 자원에 번호를 매기고 오름차순으로 할당 -> 원형 대기 조건 x
    <img width="569" alt="Image" src="https://github.com/user-attachments/assets/9beae10a-9a9e-42bd-b1b1-2e7a0e4b0587" />

  > 이게 무슨 소리지?

#### 2. 교착 상태 회피

- 교착 상태가 발생하지 않을 정도로만 자원을 할당하는 방법
- 예시: 은행원 알고리즘

#### 3. 교착 상태 검출 후 회복

- 교착 상태의 발생을 인정하고 처리하는 사후 조치
- 운영체제는 프로세스가 자원을 요구할 때마다 그때 그때 자원을 할당하고 주기적으로 교착 상태의 발생 여부를 검사함
- 교착 상태가 검출되면 프로세스를 자원 선점을 통해 회복시키거나, 교착 상태에 놓인 프로세스를 강제 종료함으로써 회복시킴
- 자원 선점을 통한 회복: 교착 상태가 해결될 때까지 다른 프로세스로부터 강제로 자원을 빼앗아 한 프로세스에 몰아서 할당하는 것

# 4. CPU 스케줄링

- 운영체제는 다양한 프로세스와 스레드에 CPU의 사용을 배분함으로써 CPU 자원을 관리함
- CPU 스케줄링: CPU 배분 방법
- CPU 스케줄러: CPU 스케줄링 알고리즘을 결정하고 수행하는 운영체제의 일부분

## 우선순위

- 모든 프로세스는 CPU의 자원을 필요로 하기 때문에 운영체제는 공정하고 합리적인 방법으로 CPU의 자원을 프로세스에 할당해야 함
- 프로세스들은 우선순위가 다르기 때문에 단순히 돌아가면서 CPU를 배분하는 것은 공정하지 않음
- 운영체제는 프로세스별 우선순위를 판단하여 PCB에 명시하고, 우선순위가 높은 프로세스에는 CPU 자원을 더 빨리, 더 많이 할당함
- 사용자가 일부 프로세스의 우선순위를 직접 높일 수도 있음
- ps 명령어를 통해 프로세스의 우선순위를 확인할 수 있음

### 우선순위 할당 방식

- CPU 활용률: 전체 CPU의 가동 시간 중 작업을 처리하는 시간의 비율
- 운영체제는 높은 CPU 활용률을 유지하기 위해 기본적으로 입출력 작업이 많은 프로세스의 우선순위를 높게 유지함
- 대부분의 프로세스들은 CPU와 입출력장치를 모두 사용해 실행과 대기 상태를 오가며 실행됨
- CPU 버스트: 프로세스가 CPU를 이용하는 작업
- 입출력 버스트: 입출력장치를 기다리는 작업
- 프로세스마다 입출력장치를 이용하는 시간과 CPU를 이용하는 시간의 양에는 차이가 있음
  - 입출력 집중 프로세스(입출력 작업이 많은 프로세스): 비디오 재생, 디스크 백업
  - CPU 집중 프로세스(CPU 작업이 많은 프로세스): 복잡한 수학 연산, 그래픽 처리 작업

#### 입출력 집중 프로세스와 CPU 집중 프로세스

- 입출력 집중 프로세스는 입출력을 위한 대기 상태에 더 많이 머무르지만, CPU 집중 프로세스는 실행 상태에 더 많이 머무름
- 입출력 집중 프로세스를 가능한 빨리 실행시켜 끊임없이 입출력장치를 작동시킨 다음, CPU 집중 프로세스에 집중적으로 CPU를 할당하는 것이 합리적
- 이렇듯 상황에 맞게 프로세스마다 우선순위를 부여해 CPU를 배분하는 것이 효율적임

### 스케줄링 큐

<img width="352" alt="Image" src="https://github.com/user-attachments/assets/acb60d40-651a-44b3-a8d2-226f6cd831fa" />

- 운영체제는 프로세스들에게 '자원을 이용하고 싶으면 줄을 서서 기다릴 것'을 요구함
- 이 줄은 스케줄링 큐를 통해 구현되며 PCB를 큐에 삽입하여 줄 세움
- 운영체제는 큐에 삽입된 순서대로 실행하되, 우선순위가 높은 프로세스부터 먼저 실행함. 실행되는 프로세스가 할당받은 시간을 모두 소모할 경우(타이머 인터럽트 받을 경우) 준비 큐로 다시 이동하고, 실행 도중 입출력 작업을 수행하는 등 대기상태로 접어들어야 할 경우 대기 큐로 이동함

<img width="470" alt="Image" src="https://github.com/user-attachments/assets/9ea1bad6-45dc-45ae-959c-5ff3afc715a5" />

#### 준비 큐

- CPU를 이용하고 싶은 프로세스의 PCB가 서는 줄
- CPU의 차례를 기다림

#### 대기 큐

<img width="566" alt="Image" src="https://github.com/user-attachments/assets/510110ca-7c14-44b9-ba33-d7cc12d16428" />

- 대기 상태에 접어든 프로세스의 PCB가 서는 줄
- 입출력 작업을 수행하게 되면 대기큐에서 대기 상태로 입출력 완료 인터럽트를 기다리게 됨
- 같은 입출력장치를 요구한 프로세스들은 같은 대기큐에서 기다림
- 입출력이 완료되어 완료 인터럽트가 발생하면 운영체제는 대기 큐에서 작업이 완료된 PCB를 찾고, 이 PCB를 준비 상태로 변경한 뒤 대기 큐에서 제거

## 선점형 스케줄링과 비선점형 스케줄링

- 스케줄링은 기본적으로 프로세스의 실행이 끝나면 이뤄지지만 프로세스가 종료되지 않았음에도 실행 도중 스케줄링이 수행될 때도 있음

  1. 실행 상태에서 입출력 작업을 위해 대기 상태로 전환될 때
  2. 실행 상태에서 타이머 인터럽트가 발생해 준비 상탤 변경될 때

- 선점형 스케줄링은 1,2 상황에서 모두 발생 가능
- 비선점형 스케줄링은 1 상황에서만 발생 가능

### 선점형 스케줄링

- 운영체제가 프로세스로부터 CPU 자원을 강제로 빼앗아 다른 프로세스에 할당할 수 있는 스케줄링
- 타이머 인터럽트 기반 스케줄링: 선점형 스케줄링의 일종, 프로세스마다 정해진 시간만큼 CPU를 이용하고 운영체제가 CPU 자원을 빼앗아 다음 프로세스에게 할당하는 방식이기 때문
- 장점: 더 급한 프로세스가 끼어들어 CPU를 사용할 수 있기 때문에 한 프로세스의 독점을 막고 여러 프로세스에 골고루 CPU 자원을 배분할 수 있음
- 단점: 문맥 교환 과정에서 오버헤드가 발생할 수 있음

### 비선점형 스케줄링

- 어떤 프로세스가 CPU를 사용하고 있을 때 그 프로세스가 종료되거나 스스로 대기 상태에 들어가기 전까지 다른 프로세스가 끼어들 수 없는 스케줄링 방식
- 장점: 문맥 교환 횟수가 적어서 상대적으로 오버헤드 발생이 적음
- 단점: 어떤 프로세스가 CPU를 사용중이라면 당장 CPU를 사용해야하는 프로세스라도 무작정 기다리는 수밖에 없음

## CPU 스케줄링 알고리즘

- CPU 스케줄링 알고리즘: 운영체제가 프로세스에 CPU를 배분하는 방법
- 각 스케줄링 알고리즘들의 작동 방식과 장단점을 이해하자

### 1. 선입 선처리 스케줄링

<img width="568" alt="Image" src="https://github.com/user-attachments/assets/9a4956c4-cf2c-47fb-a73d-118c9ff82ce6" />

- 단순히 준비 큐에 삽입된 순서대로 먼저 CPU를 요청한 프로세스부터 CPU를 할당하는 스케줄링 방식
- 단점: 프로세스들이 기다리는 시간이 매우 길어질 수 있음
- 호위 효과: 먼저 삽입된 프로세스의 오랜 실행 시간으로 인해 나중에 삽입된 프로세스의 실행이 지연되는 문제

### 2. 최단 작업 우선 스케줄링

- 준비 큐에 삽입된 프로세스 중 CPU를 이용하는 시간의 길이가 가장 짧은 프로세스부터 먼저 실행하는 스케줄링 방식
- 기본적으로 비선점형 스케줄링 알고리즘이지만 '최소 잔여 시간 우선 스케줄링' 처럼 선점형으로 구현될 수도 있음

> CPU를 이용하는 시간의 길이가 짧다는건 어떻게 미리 알 수 있을까?

### 3. 라운드 로빈 스케줄링

- 선입 선처리 스케줄링에 타임 슬라이스라는 개념이 더해진 스케줄링 방식
- 타임 슬라이스: 프로세스가 CPU를 사용하도록 정해진 시간
- 즉, 큐에 삽입된 순서로 프로세스들이 CPU를 이용하되, 정해진 타임 슬라이스만큼만 CPU를 이용하는 선점형 스케줄링 방식
- 프로세스가 정해진 시간을 모두 사용하고도 완료되지 않으면 문맥 교환이 발생해 다시 큐의 맨 뒤에 삽입됨

### 4. 최소 잔여 시간 우선 스케줄링

- 최단 작업 우선 스케줄링 방식 + 라운드 로빈 스케줄링 방식
- 프로세스가 정해진 타임 슬라이스만큼 CPU를 이용하되, 남아 있는 작업 시간이 가장 적은 프로세스를 먼저 실행

### 5. 우선순위 스케줄링

- 프로세스에 우선순위를 부여하고, 가장 높은 우선순위를 가진 프로세스부터 실행하는 스케줄링 방식
- 아사 현상: 우선순위가 낮은 프로세스는 계속해서 실행이 연기되는 현상
- 에이징: 아사 현상을 방지하기 위한 기법, 오랫동안 대기한 프로세스의 우선순위를 점차 높이는 방식

### 6. 다단계 큐 스케줄링

<img width="569" alt="Image" src="https://github.com/user-attachments/assets/0b3cfcf0-a7af-4a6d-a5ba-d44668f636a4" />

- 우선순위 스케줄링의 발전된 형태, 우선순위별로 여러 개의 준비큐를 사용하는 스케줄링 방식
- 우선순위가 가장 높은 큐에 있는 프로세스 먼저 처리 -> 그 다음 우선순위가 높은 큐에 있는 프로세스 처리 -> ...
- 단점: 프로세스들이 큐 사이를 이동할 수 없어서 우선순위가 낮은 프로세스의 작업이 계속해서 연기될 수 있음

### 7. 다단계 피드백 큐 스케줄링

<img width="572" alt="Image" src="https://github.com/user-attachments/assets/4f048644-5619-4da6-897d-dee6e1784482" />

- 다단계 큐 스케줄링 + 프로세스들이 큐 사이를 이동할 수 있음
- 새롭게 진입하는 프로세스는 우선순위가 가장 높은 우선순위 큐에 삽입되고 타임 슬라이스 동안 실행됨 -> 실행이 끝나지 않으면 다음 우선순위 큐에 삽입되어 실행됨
- 즉, 오래 CPU를 사용해야 하는 프로세스의 우선순위가 점차 낮아지게 됨
- 자연스럽게 비교적 CPU를 오래 사용해야 하는 CPU 집중 프로세스들은 우선순위가 낮아지고, 비교적 CPU를 적게 사용하는 입출력 집중 프로세스들은 우선순위가 높은 큐에서 실행이 끝나게 됨
- 에이징 기법 적용 가능: 아사 현상을 예방하기 위해 낮은 우선순위 큐에서 오래 기다리고 있는 프로세스들을 높은 우선순위 큐로 이동 -> 비교적 CPU를 오래 사용하지 못한 프로세스의 우선순위가 높아짐

## 리눅스 CPU 스케줄링

- 리눅스에서는 상황에 따라 다양한 스케줄링 알고리즘이 사용될 수 있음
- 스케줄링 정책: 새로운 프로세스를 언제 어떻게 선택하여 실행할지를 결정하기 위한 규칙 집합

| 스케줄링 정책 | 적용 상황                                                                      |
| ------------- | ------------------------------------------------------------------------------ |
| SCHED_FIFO    | 실시간성 프로세스에 적용되는 정책<br>(매우 높은 우선순위를 할당함)             |
| SCHED_RR      | 실시간성 프로세스에 적용되는 정책                                              |
| SCHED_NORMAL  | 일반적인 프로세스에 적용되는 정책                                              |
| SCHED_BATCH   | 일반적인 프로세스만큼 자주 선점하지 않는 배치 작업에 적용되는 정책             |
| SCHED_IDLE    | 우선순위가 매우 낮은 프로세스에 적용되는 정책<br>(매우 낮은 우선순위를 할당함) |

### SCHED_FIFO, SCHED_RR

- FIFO(선입 선출), RR(라운드 로빈)
- RT(Real Time) 스케줄러에 의해 이뤄지는 스케줄링
- 실시간성이 강조된 프로세스에 적용되는 스케줄링 정책

### SCHED_NORMAL

- 일반적인 프로세스에 적용되는 스케줄링 정책
- CFS라는 CPU 스케줄러에 의해 스케줄링이 이뤄짐
- CFS: 프로세스에 대해 '완전히 공평한 CPU 시간 배분'을 지향하는 CPU 스케줄러
- 리눅스에서는 프로세스마다 가상 실행 시간(vruntime) 정보를 유지하는데, CFS는 이 vruntime이 가장 작은 프로세스부터 스케줄링함
- vruntime: 프로세스의 가중치를 고려한 가상의 실행 시간, 프로세스의 우선순위가 높아질수록 가중치가 높아지고 가중치가 높을수록 vruntime이 줄어들기 때문에 먼저 스케줄링될 확률이 높음

  <img width="344" alt="Image" src="https://github.com/user-attachments/assets/69d9bdff-0bca-4077-b710-92e798c3befb" />

  > CPU를 할당받아 실행된 시간은 뭘로 계산하는거지?

- CFS로 스케줄링되는 프로세스들의 타임 슬라이스는 프로세스의 가중치에 따라 결정됨. 프로세스 우선순위가 높을수록 가중치도 높아지고 가중치가 높아지면 타임 슬라이스도 크게 할당받게됨

<img width="523" alt="Image" src="https://github.com/user-attachments/assets/eb79b3e7-6bf7-4a5a-892e-ca4ad27278f9" />

- vruntime과 가중치는 리눅스에서 `proc/<PID>/sched` 라는 파일을 출력하는 명령어를 통해 확인할 수 있음
  <img width="262" alt="Image" src="https://github.com/user-attachments/assets/e0dbd8fc-06e0-46c1-9b53-45f5192aaf69" />
- 커널(CFS 스케줄러)은 수많은 프로세스 중 vruntime이 가장 작은 프로세스를 빠르게 선별하기 위해 Red Black 트리라는 자료구조를 활용함
  <img width="383" alt="Image" src="https://github.com/user-attachments/assets/8d20f78e-7543-4e68-aa33-227a787d090d" />
  - Red Black 트리는 여러 값 중 최소값과 최대값을 빠르고 효율적으로 찾아낼 수 있는 자료구조의 일종임

# 5. 가상 메모리

- CPU는 어떻게 메모리에 적재된 프로세스의 주소를 인식하고 관리할까?

## 물리 주소와 논리 주소

- CPU와 프로세스는 메모리의 하드웨어 상 실제 주소인 **물리 주소**가 아니라 논리 주소 체계를 이용함
- **논리 주소**는 프로세스마다 부여되는 0번지부터 시작하는 주소 체계를 말함
- 실제로 정보가 저장되어 있는 하드웨어 상의 메모리와 상호작용하기 위해서는 논리 주소와 물리 주소간의 변환이 이뤄져야함
- **메모리 관리 장치 MMU(Memory Management Unit)**: CPU와 메모리 사이에 위치하여 CPU가 이해하는 논리 주소를 메모리가 이해하는 물리 주소로 변환함

  <img width="443" alt="Image" src="https://github.com/user-attachments/assets/d9f017cb-b692-41ea-9dc6-dd0e18e0ba7a" />

## 스와핑과 연속 메모리 할당

### 스와핑

<img width="577" alt="Image" src="https://github.com/user-attachments/assets/a61ee456-98e6-49f4-ac03-d1f43f3114a8" />

- **스왑 영역**: 메모리에 적재된 프로세스들 중 현재 실행되고 있지 않은 프로세스를 임시로 쫓아내는 곳, 보조기억장치의 일부 영역임
  - 실행되고 있지 않은 프로세스: 입출력 작업을 요구하며 대기 상태가 되거나 오랫동안 사용되지 않은 프로세스
- **스와핑**: 프로세스를 쫓아낸 자리에 생긴 메모리 상의 빈 공간에 다른 프로세스를 적재하여 실행하는 메모리 관리 방식
- **스왑 아웃**: 현재 실행되지 않는 프로세스가 메모리에서 스왑 영역으로 옮겨지는 것
- **스왑 인**: 스왑 영역에 있는 프로세스가 다시 메모리로 옮겨오는 것
- 스왑 아웃 됐던 프로세스가 다시 스왑 인 될때는 스왑 아웃 되기 전의 물리 주소와는 다른 주소에 적재될 수 있음

## 연속 메모리 할당과 외부 단편화

- **연속 메모리 할당**: 프로세스에 연속적인 메모리 공간을 할당하는 방식

  <img width="209" alt="Image" src="https://github.com/user-attachments/assets/aab33af5-d86a-4008-bf16-4cf42e36dcf3" />

- 연속 메모리 할당은 **외부 단편화** 문제를 가짐. 아래 사진에서 현재 이 메모리에 빈 공간은 총 50MB인데 크기가 50MB인 프로세스를 적재하는 것은 불가능함

<img width="274" alt="Image" src="https://github.com/user-attachments/assets/1c1dfd4e-70cc-4ecf-bf02-c105f2d8e594" />

- 프로세스들이 메모리에 연속적으로 할당되는 환경에서는 프로세스의 실행과 종료를 반복하며 메모리 사이 사이에 빈 공간이 생기게 됨
- **외부 단편화**: 빈 공간보다 프로세스가 더 커서 적재하기 어려운 상황으로 인한 메모리 낭비 현상

## 페이징을 통한 가상 메모리 관리

- 스와핑과 연속 메모리 할당은 2가지 문제 내포
  1. 적재와 삭제를 반복하며 프로세스들 사이에 발생하는 외부 단편화
  2. 물리 메모리보다 큰 프로세스를 실행할 수 없는 문제
- **가상 메모리**: 이러한 문제를 해결하는 운영체제의 메모리 관리 기술

### 가상 메모리

- 실행하고자 하는 프로그램의 일부만 메모리에 적재해, 실제 메모리보다 더 큰 프로세스를 실행할 수 있도록 만드는 메모리 관리 기법
- 대표적인 가상 메모리 관리 기법: 페이징, 세그멘테이션
  - 페이징이 많은 운영체제에서 더 범용적으로 사용됨

### 페이징

<img width="487" alt="Image" src="https://github.com/user-attachments/assets/3ff6e0bc-c396-447d-a751-a02988dae39a" />

- **페이징**: 프로세스의 논리 주소 공간을 **페이지** 라는 일정한 단위로 나눔 -> 물리 주소 공간을 페이지와 동일한 크기의 **프레임** 이라는 일정한 단위로 나눔 -> **페이지를 프레임에 할당하는 가상 메모리 관리 기법**
- 프로세스를 구성하는 페이지는 물리 메모리 내에 불연속적으로 배치될 수 있음
- 이 방식으로 메모리를 할당하면 외부 단편화가 발생하지 않음
- 페이징 기법에도 스와핑 사용될 수 있음

  - 프로세스 전체가 아닌 페이지 단위로 스왑 아웃/스왑 인 됨
  - **페이지 아웃**, **페이지 인**
  - 프로세스를 실행하기 위해 전체 프로세스가 메모리에 적재될 필요는 없다는 점 시사
  - 즉, 논리 주소 공간에는 RAM + 스왑 영역이 포함되기 때문에 물리 메모리보다 큰 크기의 프로세스도 실행 가능해짐

  <img width="590" alt="Image" src="https://github.com/user-attachments/assets/cc1fc532-dfed-4ebb-9363-85eb19c2a7a3" />

### 페이징의 내부 단편화 문제

<img width="561" alt="Image" src="https://github.com/user-attachments/assets/46d887aa-eb3c-4834-82cd-01417556bb8a" />

- 페이징은 외부 단편화 문제를 해결할 수는 있지만, 내부 단편화라는 또 다른 문제를 야기함
- 페이징은 프로세스의 논리 주소 공간을 페이지라는 일정한 크기의 단위로 나누는 방식이지만, 모든 프로세스가 페이지 크기에 딱 맞게 잘리지는 않음
- **내부 단편화**: 페이지 하나의 크기보다 작은 크기로 발생하게 되는 메모리 낭비

### 세그멘테이션

<img width="448" alt="Image" src="https://github.com/user-attachments/assets/4e31ab76-7839-423f-8569-307537a77652" />

- 프로세스를 일정한 크기의 페이지 단위가 아닌 가변적인 크기의 **세그먼트** 단위로 분할하는 방식
- 세그먼트의 크기가 일정하지 않기 때문에 외부 단편화 발생할 수 있음

### 페이지 테이블

- **페이지 테이블**: CPU가 프로세스를 이루는 어떤 페이지가 어떤 프레임에 적재돼 있는지 어떻게 알 수 있을까? 에 대한 문제를 해결하기 위해 프로세스의 페이지와 실제로 적재된 프레임을 짝지어주는 정보
- 페이지 테이블에는 페이지 번호와 실제로 적재된 프레임 번호가 대응되어 있음 -> CPU는 페이지 테이블 페이지 번호만 보고도 적재된 프레임 찾을 수 있음
- 프로세스마다 각자의 페이지 테이블 정보 가지고 있음 -> CPU가 서로 다른 프로세스를 실행할 때는 각 프로세스의 페이지 테이블을 참조하여 메모리에 접근함

  <img width="581" alt="Image" src="https://github.com/user-attachments/assets/efe91c1e-6443-41c0-9f28-253bda729ce0" />

#### 테이블 엔트리

<img width="565" alt="Image" src="https://github.com/user-attachments/assets/b97eb67d-9388-44fb-b3db-83648dd3a098" />

- **테이블 엔트리**: 페이지 테이블을 구성하고 있는 각각의 행들
- 테이블 엔트리에 포함되는 대표적 정보: 페이지 번호, 프레임 번호, 유효 비트, 보호 비트, 참조 비트, 수정 비트

**유효 비트**

- 해당 페이지에 접근 가능한지 여부를 알려 주는 매우 중요한 정보
- 현재 페이지가 메모리, 아니면 보조기억장치에 적재돼 있는지 알려주는 비트
- 페이지가 메모리에 적재돼 있다면 1, 아니면 0
- CPU는 보조기억장치에 저장된 페이지에 곧장 접근할 수 없으므로 보조기억장치에 저장된 페이지에 접근하려면 보조기억장치 속 페이지를 메모리로 적재한 뒤에 접근해야 함
- 만약 CPU가 메모리에 적재되지 않은 페이지, 즉 유효 비트가 0인 페이지에 접근하려고 하면 **페이지 폴트** 라는 예외 발생
- 페이지 폴트 처리 과정:
  1. 기존 작업 내역 백업
  2. 페이지 폴트 처리 루틴 실행. 원하는 페이지를 메모리로 가져와 유효 비트를 1로 변경
  3. 메모리에 적재된 페이지 실행

**보호 비트**

- 페이지 보호 기능을 위해 존재하는 비트
- 읽기: r, 쓰기: w, 실행: x 의 조합으로 페이지에 접근할 권한을 제한함으로써 페이지를 보호함
  - 100 -> 읽기만 가능
  - 111 -> 읽기/쓰기/실행 가능

**참조 비트**

- CPU가 해당 페이지에 접근한 적이 있는지의 여부를 나타내는 비트
- 페이지에 적재한 이후에 CPU가 읽거나 쓴 페이지는 참조 비트가 1로 설정됨, 적재한 이후에 한 번도 읽거나 쓴 적이 없는 페이지는 0으로 유지됨

**수정 비트(더티 비트)**

- 해당 페이지에 데이터를 쓴 적이 있는지의 여부를 알려주는 비트
- 수정 비트가 1이면 변경된 적이 있는 페이지, 0이면 변경된 적이 없는 페이지
- 수정 비트가 1일 경우, 즉 한 번이라도 페이지에 쓰기 작업을 한 경우에는 페이지를 메모리에서 삭제해야 할 때 페이지의 수정 내역을 보조기억장치에도 반영해야 하므로 보조기억장치에 대한 쓰기 작업이 필요

#### 페이지 테이블 베이스 레지스터

<img width="578" alt="Image" src="https://github.com/user-attachments/assets/204991bf-1175-4512-b2b0-6497035a4ae2" />

- 각 프로세스의 페이지 테이블은 메모리에 적재될 수 있음
- 어떤 프로세스를 실행하려면 이 프로세스의 페이지 테이블이 메모리에 적재된 위치를 알아야 함
- **페이지 테이블 베이스 레지스터(Page Table Base Register)**: 특정 프로세스의 페이지 테이블이 적재된 메모리 상의 위치를 가리키는 레지스터
- PTBR은 프로세스마다 가지는 정보이므로 각 PCB에 기록되며, 다른 프로세스로의 문맥 교환이 발생할 때 레지스터 값이 변경됨
- 모든 프로세스의 페이지테이블을 메모리에 두는 것은 지양함:
  1. 메모리 접근 횟수 많아짐
  2. 메모리 용량을 많이 차지하기 때문에 비효율

**1. 메모리 접근 횟수**

<img width="569" alt="Image" src="https://github.com/user-attachments/assets/f1fd3fc6-899c-42cb-ab87-ad2649474ca4" />

- 모든 프로세스의 페이지 테이블이 메모리에 적재돼 있을 경우, CPU는 페이지 테이블에 접근하기 위해 한 번, 실제 프레임에 접근하기 위해 한 번, 이렇게 총 두 번 메모리에 접근해야 함 -> 메모리에 접근하는 시간이 두 배로 늘어남
- 이를 해결하기 위해 **TLB(Translation Look-aside Buffer)** 라는 페이지 테이블의 캐시 메모리가 사용됨
- **TLB 히트**: CPU가 접근하려는 논리 주소의 페이지 번호가 TLB에 있을 경우, TLB는 CPU에게 해당 페이지 번호가 적재된 프레임 번호를 알려줌 -> 한 번만 메모리에 접근하면 됨
- **TLB 미스**: 페이지 번호가 TLB에 없는 경우 어쩔 수 없이 페이지가 적재된 프레임을 알기 위해 메모리 내의 페이지 테이블에 접근해야 함 -> 추가적인 메모리 접근이 필요하기 때문에 메모리 접근 횟수를 낮추려면 TLB 히트율을 높여야함

> 여기서 말하는 메모리는 물리 메모리겠지?

**2. 메모리 용량**

- 프로세스의 크기가 커지면 페이지 테이블 크기도 커지기 때문에 프로세스를 이루는 모든 페이지 테이블 엔트리들을 메모리에 두는 것은 큰 메모리 낭비임
- **계층적 페이징**: **페이지 테이블을 페이징** 하는 방식, 여러 단계의 페이지를 둔다는 점에서 **다단계 페이지 테이블**기법이라고도 불림
- 계층적 페이징 기법을 적용하지 않으면 페이지 테이블 전체가 메모리에 적재돼 잇어야 함

  <img width="146" alt="Image" src="https://github.com/user-attachments/assets/c265bdfb-b3d8-49fe-9143-7e0403d6faca" />

- 계층적 페이징은 아래 사진처럼 프로세스의 페이지 테이블을 여러 개의 페이지로 자르고, CPU와 가까이 위치한 바깥 쪽에 페이지 테이블(Outer 페이지 테이블)을 하나 더 두어 잘린 페이지 테이블의 페이지들을 가리키게 함
- 이렇게 하면 모든 페이지 테이블을 항상 메모리에 유지할 필요가 없어짐. CPU와 가장 가까이 위치한 페이지 테이블(Outer 페이지 테이블)만 멤뢰에 유지하면 잘린 페이지 테이블의 일부가 보조기억장치에 있더라도 Outer 페이지 테이블을 통해 언제든 접근할 수 있기 때문임

  <img width="405" alt="Image" src="https://github.com/user-attachments/assets/ecf9fe5d-d371-4c88-8f47-2e870b569ea9" />

> 보조기억장치에 있으면 상대적으로 접근이 느려지지 않나? 메모리 낭비와 접근 속도 사이의 트레이드오프인가?

### 페이징 주소 체계

<img width="583" alt="Image" src="https://github.com/user-attachments/assets/341e4ca8-c445-43c3-82bd-687ff350f293" />

- 하나의 페이지 내에는 여러 주소가 포함되어 있기 때문에 페이징 시스템의 논리 주소는 기본적으로 <페이지 번호, 변위>와 같은 형태로 이루어져 있음
- **페이지 번호**: 몇 번째 페이지 번호에 접근할지 나타냄.
  - 페이지 테이블을 참조하면 물리 메모리 내의 어떤 프레임에 접근할지를 알 수 잇음
- **변위**: 접근하려는 주소가 페이지(프레임) 시작 번지로부터 얼만큼 떨어져 있는지를 나타내는 정보.
- <페이지 번호, 변위>로 이루어진 논리 주소는 페이지 테이블을 통해 물리 주소 <프레임 번호, 변위>로 변환됨

- 예를 들어 현재 CPU와 페이지 테이블, 메모리 상태가 아래 그림과 같다고 해보자. 하나의 페이지 및 프레임이 4개의 구조로 구성돼 있는 상황임
  - 만약 CPU가 5번 페이지, 변위2라는 논리 주소 <5,2>에 접근한다면 실제로 CPU가 접근하게 될 물리 주소는 1번 프레임, 변위 2임 즉, 8번지 + 2 인 10번지에 접근하게 됨

## 페이지 교체 알고리즘

- **요구 페이징**: 메모리에 프로세스를 적재할 때 처음부터 모든 페이지를 적재하지 않고, 메모리에 필요한 페이지만 적재하는 기법
- 요구 페이징의 기본적인 양상
  1. CPU가 특정 페이지에 접근하는 명령어 실행
  2. 해당 페이지가 현재 메모리에 있으면(유효 비트1) CPU는 페이지가 적재된 프레임에 접근함
  3. 해당 페이지가 현재 메모리에 없으면(유효 비트0) 페이지 폴트가 발생
  4. 페이지 폴트 발생시 페이지 폴트 처리 루틴을 통해 해당 페이지를 메모리에 적재하고, 유효 비트를 1로 설정
  5. 다시 1의 과정 수행
- **순수 요구 페이징**: 아무런 페이지도 메모리에 적재하지 않은 채 무작정 프로세스를 실행하는 것
  - 첫 명령어를 실행하는 순간부터 페이지 폴트가 발생하게 되고, 실행에 필요한 페이지가 어느 정도 적재된 이후부터 페이지 폴트 발생 빈도 떨어짐
- 요구 페이징을 통해 페이지들을 메모리에 점차 적재하다 보면 언젠가는 메모리가 가득참, 메모리에 페이지가 가득 찬 상황에서 추가적으로 페이지를 적재해야 한다면 메모리에 적재된 일부 페이지를 스왑 아웃 해야함
- **페이지 교체 알고리즘**: 메모리에 적재된 페이지 중 보조기억장치로 내보낼 페이지를 선택하는 방법
- 페이지 교체 알고리즘은 페이지 폴트 발생 빈도와 직결 되기 때문에 컴퓨터 전체 성능과 직결됨
- **스래싱**: 프로세스가 실제로 실행되는 시간보다 페이징에 더 많은 시간을 소요하여 성능이 저하되는 문제

> 요구 페이징에서 메모리에 필요한 페이지를 처음에 적재한다고 돼있는데 어떤 것이 될 수 있을까?

### 페이지 폴트 종류

- 메이저 페이지 폴트: 보조기억 장치에서 CPU가 원하는 페이지를 읽어 들이기 위해 입출력 작업이 필요한 페이지 폴트
  - 지금까지 설명한 페이지 폴트 유형
  - CPU가 접근하려는 페이지가 물리 메모리에 없을 때 발생하는 페이지 폴트
- 마이너 페이지 폴트: 보조기억장치와의 입출력이 필요하지 않은 페이지 폴트
  - CPU가 요청한 페이지가 물리 메모리에는 존재하지만, 페이지 테이블 상에는 반영되지 않은 경우 발생
  - 일반적으로 메이저 페이지 폴트에 비해 성능 상의 악영향이 적은 페이지 폴트

> 마이너 페이지 폴트 예시 상황은?

### FIFO 페이지 교체 알고리즘

- 메모리에 가장 먼저 적재된 페이지부터 스왑 아웃하는 페이지 교체 알고리즘
- 단점: 초기에 적재되어 계속 참조되고 있는 페이지를 스왑 아웃할 우려 있음

### 최적 페이지 교체 알고리즘

- 앞으로의 사용 빈도가 가장 낮은 페이지를 교체하는 알고리즘
- 메모리에 적재된 페이지들 중 앞으로 가장 적게 사용할 페이지를 스왑 아웃해 가장 낮은 페이지 폴트율을 보장하는 알고리즘
- '앞으로 가장 적게 사용할 페이지'를 미리 예측하기 어려워서 실제 구현이 어려움

### LRU 페이지 교체 알고리즘

- 가장 적게 '사용한' 페이지를 교체하는 알고리즘
- 보편적으로 사용되는 페이지 교체 알고리즘의 원형으로, 이를 기반으로 만들어진 다양한 파생 알고리즘이 있음

> 파생 알고리즘 대표적인거 뭐가 있을까?

# 6. 파일 시스템

- 운영체제가 보조기억장치를 효과적으로 관리하는 방법에 대해 알아보자
- **파일 시스템**: 보조기억장치의 정보를 파일 및 디렉터리(폴더)의 형태로 저장하고 관리할 수 있도록 하는 운영체제 내부 프로그램
- 한 운영체제 내에서도 여러 파일 시스템을 사용할 수 있고, 파일 시스템이 달라지면 보조기억장치의 정보를 다루는 방법도 달라지게 됨

## 파일과 디렉터리

### 파일

- 파일의 구성: 파일 이름, 파일 실행을 위한 정보, 파일 관련 부가 정보
- 부가 정보를 **속성** 또는 **메타데이터**라고 부름
  - ex) 파일 형식, 위치, 크기 등 파일과 관련한 다양한 정보
- 파일을 다루는 모든 작업이 운영체제에 의해 이루어지기 때문에 응용 프로그램은 임의로 파일을 할당받아 조작하고 저장할 수 없고, 파일을 다루는 시스템 콜을 이용해야 함

**파일 디스크립터(파일 핸들)**

- 프로세스는 할당 받아 사용중인 파일들을 구분할 수 있어야함
- 프로세스가 파일을 구분해서 다루기 위한 0 이상의 정수값
- 운영체제는 프로세스가 새로 파일을 열거나 생성할 때 해당 파일에 대한 파일 디스크립터를 프로세스에 할당함
- 예시
  - open(): 파일을 여는데 사용되는 시스템 콜, 연 파일의 파일 디스크립터 반환

**파일 디스크립터는 파일만 식별하지 않는다**

- 파일뿐만 아니라 입출력장치, IPC 수단인 파이프, 소켓 또한 파일 디스크립터로 식별함
- open() 으로 파일을 열때 파일 디스크립터가 0부터 할당되지 않고 3부터 할당되는 이유는 파일 디스크립터 '0', '1', '2'가 이미 표준 입력, 표준 출력, 표준 에러를 나타내기 위해 할당되었기 때문임

  | 파일 디스크립터 | 활당                              |
  | --------------- | --------------------------------- |
  | 0               | 표준 입력(일반적으로 키보드 입력) |
  | 1               | 표준 출력(일반적으로 모니터)      |
  | 2               | 표준 에러                         |

### 디렉터리(폴더)

<img width="404" alt="Image" src="https://github.com/user-attachments/assets/f120a977-669a-47ec-a9e1-c862b75fd345" />

- 운영체제는 여러 파일들을 일목요연하게 관리하기 위해 디렉터리를 이용함
- 여러 계층을 가진 트리 구조 디렉터리로 관리됨(계층적 형태의 자료구조)
- 최상위 디렉터리와 최상위 디렉터리가 포함하고 있는 서브 디렉터리로 구성됨
  - 서브 디렉터리도 또 다른 서브 디렉터리를 포함할 수 있음
- 루트 디렉터리: 최상위 디렉터리, 슬래시(/)로 표현
- 슬래시(/): 디렉터리를 구분하는 구분자
- 경로: 디렉터리 정보를 활용해 파일 위치를 특정하는 정보
  - /, /this, /this/is, /this/is/cs
- 윈도우 운영체제
  - 최상위 디렉터리: 'C:\' 로 표현
  - 디렉터리 구분자: 백슬래시(\)

**디렉터리 엔트리**

- 많은 운영체제에서는 파일과 디렉터리를 별개의 것이라고 간주하지 않음, 디렉터리를 '디렉터리에 속한 요소의 관련 정보가 포함된 파일'로 간주함
- **디렉터리 엔트리**: 디렉터리에 속한 요소의 관련 정보는 테이블(표)의 형태로 표현되며, 테이블 형태로 표현된 정보의 행 하나 하나를 디렉터리 엔트리 라고 함
- 디렉터리 엔트리에는 '파일의 이름'과 '파일이 저장된 위치를 유추할 수 있는 정보'가 반드시 포함되어 있음
  - 일부 파일 시스템은 디렉터리 엔트리에 생성 시간, 수정된 시간, 크기를 명시하기도 함
- 디렉터리 엔트리를 통해 보조기억장치에 저장되어 있는 위치를 알 수 있기 때문에 디렉터리에 속한 파일의 위치를 읽어 실행할 수도 있고, 디렉터리에 속한 다른 디렉터리의 위치를 찾아 이동할 수도 있음

<img width="399" alt="Image" src="https://github.com/user-attachments/assets/c8c02770-40f1-418b-bbd6-1ae7d3eece36" />

<img width="572" alt="Image" src="https://github.com/user-attachments/assets/85780449-7dff-417a-8db0-614c4a988e43" />

**실제 운영체제 디렉터리 엔트리**

```c
struct dirent {
    ino_t d_ino;             // 파일의 아이노드 번호
    off_t d_off;             // 현재 디렉터리 엔트리의 오프셋: 엔트리 탐색 시 사용
    unsigned short d_reclen;  // 현재 디렉터리 엔트리의 길이
    unsigned char d_type;     // 파일 형식
    char d_name[256];         // 파일 이름
};
```

### 파일 할당

- 파일과 디렉터리가 어떻게 보조기억장치 안에 저장되는지 알아보자
- **블록**: 운영체제가 파일과 디렉터리를 읽고 쓰는 단위
- 하나의 파일이 보조기억장치에 저장될 때는 하나 이상의 블록을 할당받아 저장됨
- 블록 하나는 보통 4096바이트 정도임
- 아래 사진처럼 보조기억장치 내에 여러 블록이 있다고 가정해보자

  <img width="236" alt="Image" src="https://github.com/user-attachments/assets/243e2d84-97ae-4bb9-880c-a4fed4ae2c47" />

  - 블록 안에 적힌 번호는 블록 주소임
  - 파일 시스템에 따라 파일 및 디렉터리를 어떤 번호의 블록에 어떻게 할당할지가 달라질 수 있음

#### 블록 할당 방식

**연결 할당**

<img width="582" alt="Image" src="https://github.com/user-attachments/assets/cc5ef03c-a9eb-492c-913c-3f0cfc16ce2f" />

- 어떤 파일 시스템은 각 블록의 일부에 다음 블록 주소를 저장하여 각각의 블록이 다음 블록을 가리키는 형태로 할당함
- 디렉터리 엔트리에는 파일 이름, 파일을 이루는 첫 번째 블록 주소, 파일을 이루는 블록 단위의 길이가 명시됨
- 아래 그림처럼 디렉터리 엔트리만 보아도 어떤 파일이 어디에 저장돼 있는지 알 수 있음(블록 없다는건 -1로 표현했음)

**색인 할당**

<img width="528" alt="Image" src="https://github.com/user-attachments/assets/175cce43-9fbf-4f2a-a2ea-80d234591853" />

- 어떤 파일시스템은 파일을 이루는 모든 블록의 주소를 **색인 블록**이라는 특별한 블록에 모아 관리하는 방식으로 할당함
- 디렉터리 엔트리에는 파일 이름, 색인 블록 주소가 명시됨
- 색인 블록만 알면 접근하고자 하는 파일 데이터에 접근할 수 있음

> 같은 색인 블록임을 어떻게 연결지을까? 다른 블록들을 포인터로 가리키려나

## 파일 시스템

- 운영체제마다 각기 다른 파일 시스템을 지원함
- 같은 운영체제라도 다른 파일 시스템을 사용하거나 하나의 컴퓨터에서 여러 파일 시스템을 사용할 수 있음
- **포매팅**: 파일 시스템을 설정하여 어떤 방식으로 파일을 저장하고 관리할 것인지를 결정하고, 새로운 데이터를 쓸 준비를 하는 작업

### 파티셔닝

- 하나의 보조기억장치 내에는 다양한 종류의 파일 시스템이 사용될 수 있음
- 한 보조기억장치에 여러 파일 시스템을 적용하여 사용하려면 보조기억장치 내에 파일 시스템을 적용할 영역이 구분되어 있어야 함
- **파티셔닝**: 보조기억장치의 영역을 구획하는 작업
- **파티션**: 파티셔닝되어 나누어진 하나 하나의 영역
- 즉, 보조기억장치는 여러 파티션으로 나눌 수 있으며, 파티션마다 다른 파일 시스템을 사용할 수 있음

### 아이노드 기반 파일 시스템

- 리눅스 운영체제에서는 **아이노드**라는 색인 블록을 기반으로 파일을 할당함
- 파일마다 각각의 아이노드를 가지고 있으며, 아이노드에는 각각의 번호가 부여돼 있음
- 파일의 이름을 제외한, 파일이 저장된 위치와 속성 등 파일의 모든 것이 담겨져 있음

**실제 아이노드 기반 파일 시스템의 구성 - EXT4 파일 시스템**

<img width="564" alt="Image" src="https://github.com/user-attachments/assets/9baec915-eee7-4cb8-83c2-27ce775eb8f3" />

- EXT4는 여러 블록의 그룹으로 이루어져 있음
- 첫 번째 부트 블록 영역은 실질적인 파일 데이터가 아닌, 부팅과 파티션 관리를 위한 특별한 정보가 모여 있는 영역임
- 각 블록 그룹은 대략 슈퍼 블록, 그룹 식별자, 블록 비트맵, 아이노드 비트맵, 아이노드 테이블, 데이터 블록으로 구성됨
- 아이노드 기반 파일 시스템에서는 데이터 영역에 공간이 남아 있더라도 아이노드 영역이 가득 차 더 이상의 아이노드를 할당할 수 없다면 새로운 파일을 생성할 수 없음

> 엥 아이노드 블록 안의 데이터 블록이랑 데이터 영역이랑 다른건가? -> 아이노드 영역과 데이터 영역은 나뉘어져있는데, 아이노드의 데이터 블록에서 데이터 영역을 주소로 가리키는 것임

| 이름            | 설명                                                                           |
| --------------- | ------------------------------------------------------------------------------ |
| 슈퍼 블록       | 아이노드의 개수, 총 블록 개수, 블록 크기 등 전체적인 파일 시스템의 정보를 저장 |
| 그룹 실별자     | 블록 그룹에 대한 메타데이터를 저장                                             |
| 블록 비트맵     | 현재 블록 그룹 내에서 데이터가 어떻게 할당되었는지를 저장                      |
| 아이노드 비트맵 | 현재 블록 그룹 내에서 아이노드가 어떻게 할당되었는지를 저장                    |
| 아이노드 테이블 | 각 파일의 아이노드 정보를 저장                                                 |
| 데이터 블록     | 각 파일의 데이터를 저장                                                        |

### 하드 링크와 심볼링 링크

- 디렉터리 A에 속한 파일 A가 있다고 가정해보자. 디렉터리 엔트리에 파일 이름(A)와 아이노드 번호가 명시되어 있다면 해당 아이노드에 접근할 수 있고, 아이노드를 통해 파일 데이터에 접근할 수 있음

<img width="358" alt="Image" src="https://github.com/user-attachments/assets/c2934b31-abb5-4072-84d7-9f269e6cc0b9" />

- 이런 아이노드를 응용하면 동일한 파일 속성과 데이터 블록을 공유하는 다른 이름의 파일(**하드 링크 파일**)을 만들 수도 있고, 윈도우의 바로가기 파일처럼 파일을 가리키는 파일(**심볼링 링크 파일**)을 만들수도 있음

<img width="382" alt="Image" src="https://github.com/user-attachments/assets/7e7449ce-7ccf-4bda-b277-513fb261e67b" />

- **하드 링크 퍄일**: 원본 파일과 같은 아이노드를 공유하는 파일

  - 같은 아이노드 번호를 갖는 파일을 생성하는 작업이므로 하드 링크 파일과 원본 파일은 같은 파일 데이터를 공유
  - 하드 링크 파일을 변경하면 원본 파일도 변경됨
  - 하드 링크 파일이 남아있다면 원본 파일이 삭제되거나 이동되더라도 파일 데이터에 접근할 수 있음
  - 동일한 파일을 여러 이름으로 참조하고 싶을 때 사용

- **심볼링 링크 파일**: 원본 파일을 가리키는 파일

  - 같은 파일 데이터를 공유하지 않고 원본 파일의 위치만을 저장하기 때문에 원본 파일이 삭제되거나 이동되는 경우에는 사용이 불가능함
  - 복잡한 경로에 있는 파일을 바로가기 파일의 형태로 간단하게 참고하고 싶을 때 사용

> 심볼링 링크 파일에서 원본 파일 주소는 아이노드 어디에 저장될까?
> 심볼링 링크 파일은 바탕화면 바로가기로 예를 들 수 있을 것 같은데, 하드 링크 파일 예시는 뭐가 잇을까

### 마운트

- **마운트**: 어떤 저장장치의 파일 시스템에서 다른 저장장치의 파일 시스템으로 접근할 수 있도록 파일 시스템을 편입시키는 작업
- 마운트로 인해 USB 메모리를 데스크탑 컴퓨터에 연결하면 데스크톱 컴퓨터의 파일 시스템을 통해 USB 메모리의 파일 시스템에 접근할 수 있는 것임
- 아래와 같은 디렉터리 구조를 가진 데스크톱 컴퓨터의 저장 공간과 USB 메모리가 있다고 가정하자

<img width="576" alt="Image" src="https://github.com/user-attachments/assets/79e031f6-0b66-4d6f-927f-9a808c895ee5" />

- USB 메모리의 파일 시스템을 컴퓨터의 '/mnt' 경로로 마운트하면 아래 사진과 같이 됨
  - 이로써 데스크톱 컴퓨터의 '/mnt/homework/os/a.cpp' 경로를 통해 'a.cpp' 파일에 접근할 수 있음

<img width="572" alt="Image" src="https://github.com/user-attachments/assets/8f646f23-b7dc-4656-b27e-e300aa9a2e06" />
