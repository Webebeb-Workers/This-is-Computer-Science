# 2. 프로세스와 스레드

- 메모리에는 컴퓨터가 실행되는 순간 다양한 프로세스들이 적재되어 실행됨

## 프로세스의 유형

- 프그라운드 프로세스: 사용자가 보는 공간에서 사용자와 상호작용하며 실행되는 프로세스
- 백그라운드 프로세스:사용자가 보지 못하는 곳에서 실행되는 프로세스
  - 데몬(서비스): 사용자와 상호작용 없이 주어진 작업만 수행하는 특별한 백그라운드 프로세스

## 메모리 정보

![Image](https://github.com/user-attachments/assets/b6352048-f7cd-4a03-b4e3-bd2dfaa8406c)

- 프로세스 유형을 막론하고 하나의 프로세스를 구성하는 메모리 내의 정보는 크게 다르지 않음
- 커널 영역: 프로세스 제어 블록(PCB) 정보가 저장
- 사용자 영역: 코드 영역, 데이터 영역, 힙 영역, 스택 영역 저장

### 1. 코드 영역

- 실행 가능한 명령어가 저장되는 공간
- 텍스트 영역이라고도 부름
- 쓰기 금지 공간(read-only)
- 정적 할당 영역: 프로그램 실행 도중 크기가 변하지 않음

### 2. 데이터 영역

- 프로그램이 실행되는 동안 유지할 데이터가 저장되는 공간
- 정적 변수, 전역 변수가 저장됨
- BSS: 초기값이 있는 데이터는 데이터 영역에 저장, 초기값이 없는 데이터는 BSS 영역에 저장됨
- 정적 할당 영역: 프로그램 실행 도중 크기가 변하지 않음

### 3. 힙 영역

- 프로그램을 만드는 사용자(개발자)가 직접 할당 가능한 저장 공간
- 프로그램 실행 도중 비교적 자유롭게 할당하여 사용 가능한 메모리 공간
- 메모리 공간을 할당한 후 반환하지 않으면 메모리 낭비인 메모리 누수 문제 초래
- 가비지 컬렉션: 프로그래밍 언어에서 자체적으로 메모리를 해제하는 기능을 제공하기도 함

### 4. 스택 영역

- 일시적으로 사용할 값들이 저장되는 공간
- 함수의 실행이 끝나면 사라지는 매개변수, 지역변수, 함수 복귀 주소 등이 저장됨
- 스택 트레이스: 특정 시점에 스택 영역에 저장된 함수 호출 정보가 저장됨
  - 문제의 발생 지점을 추적할 수 있어, 디버깅에 유용함
    ![Image](https://github.com/user-attachments/assets/8ead8b0b-66b3-4d37-94fd-7b84f768b813)

## PCB와 문맥 교환

### PCB란

- PCB(Process Control Block): 운영체제가 메모리에 적재된 다수의 프로세스를 관리하기 위한, 프로세스를 식별할 수 있는 커널 영역 내의 정보
- 프로세스와 관련한 다양한 정보를 내포하는 구초제로, 새로운 프로세스가 메모리에 적재됐을 때 커널 영역에 만들어지고, 프로세스의 실행이 끝나면 폐기됨
- PCB에 담기는 정보
  - PID: 프로세스 식별 번호
  - 프로세스가 실행과정에서 사용한 레지스터 값
  - 프로세스 상태
  - CPU 스케줄링 정보: 어떤 순서로 CPU를 할당받을지
  - 메모리 관련 정보: 프로세스의 메모리상 적재 위치
  - 프로세스가 사용한 파일 및 입출력장치 관련 정보
- 예시(리눅스 운영체제의 PCB인 task_struct 구조체)
  ![Image](https://github.com/user-attachments/assets/02362b8d-1d11-41b3-9dfc-fdd459a25f42)

### 프로세스 테이블

![Image](https://github.com/user-attachments/assets/1835f447-879f-452f-8c04-18f584eb4b49)

- 프로세스 테이블: 여러 PCB들이 관리되는 형태, 실행중인 PCB들의 모음
- 새롭게 실행되는 프로세스가 있으면 해당 프로세스의 PCB를 프로세스 테이블에 추가하고, 필요한 자원을 할당함
- 종료되는 프로세스가 있다면 사용중이던 자원을 해제하고 PCB에도 프로세스 테이블에서 삭제됨
- 좀비 프로세스: 프로세스가 비정상 종료되어 사용한 자원이 회수되었음에도 프로세스 테이블에 종료된 프로세스의 PCB가 남아있는 프로세스

### 문맥

- 메모리에 적재된 프로세스들은 한정된 시간 동안 번갈아 가며 실행됨
- 프로세스가 실행된다: 운영체제에 의해 CPU의 자원을 할당받았다는 뜻
- 프로세스의 CPU 사용 시간은 타이머 인터럽트에 의해 제한됨
  - 타이머 인터럽트(타임아웃 인터럽트): 시간이 끝났음을 알림
- 프로세스는 자신의 차례가 되면 정해진 시간만큼 CPU를 이용하고, 타이머 인터럽트가 발생하면 자신의 차례를 양보하고 다음 차례가 올 때까지 기다림
- 다시 차례가 왔을 때 이전까지 실행했던 내용을 이어서 재개하기 위해 프로그램 카운터, 레지스터 값, 메모리 정보 등 지금까지의 중간 정보를 **백업**해야함
- 문맥: 프로세스의 수행을 재개하기 위해 기억해야 할 정보

### 문맥 교환

![Image](https://github.com/user-attachments/assets/48a1ccf5-c062-4d49-b106-a78536d1fa0f)

- 프로세스가 CPU를 사용할 수 있는 시간이 다 되거나 인터럽트가 발생하면 운영체제는 해당 프로세스의 PCB에 문맥을 백업하고 뒤이어 실행할 프로세스의 문맥을 복구함
- 문맥 교환: 기존 프로세스의 문맥을 PCB에 백업하고, PCB에서 문맥을 복구하여 새로운 프로세스를 실행하는 것
- 여러 프로세스가 끊임없이 빠르게 번갈아 가며 실행되는 원리
- 프로세스 간에 너무 잦은 문맥 교환이 발생하면 캐시 미스가 발생할 가능성이 높아져 메모리에 접근할 일이 많아지고, 이는 큰 오버헤드로 이어질 수 있음

## 프로세스의 상태

![Image](https://github.com/user-attachments/assets/6827641c-5b12-46d3-b0ff-f854743e2687)

- 하나의 프로세스는 여러 상태를 거치며 실행됨
- 운영체제는 PCB를 통해 프로세스의 상태를 인식하고 관리함
- 대표적인 상태: 생성, 준비, 실행, 대기, 종료

### 생성 상태

- 프로세스를 생성 중인 상태로, 메모리에 적재되어 PCB를 할당받은 상태
- 생성 상태를 거쳐 실행할 준비가 완료된 프로세스는 준비 상태가 되어 CPU의 할당을 기다림

### 준비 상태

- CPU를 할당받아 실행할 수 있지만, 자신의 차례가 아니기 때문에 기다리고 있는 상태
- 준비 상태인 프로세스가 CPU를 할당받으면 실행 상태가 되며, 준비 상태인 프로세스가 실행 상태로 전환되는 것을 디스패치(dispatch) 라고 함

### 실행 상태

- CPU를 할당받아 실행중인 상태
- 일정 시간동안만 CPU를 사용할 수 있음
- 타이머 인터럽트가 발생하여 프로세스가 할당된 시간을 모두 사용하면 다시 준비 상태가 됨
- 실행 도중 입출력장치를 사용하여 입출력장치의 작업이 끝날 때까지 기다려야 하면 대기 상태가 됨

### 대기 상태

- 프로세스가 입출력 작업을 요청하거나 바로 확보할 수 없는 자원을 요청하는 등 곧장 실행이 불가능한 조건에 놓이는 경우 대기 상태가 됨
- 입출력 작업을 요청하는 경우가 대표적임
- 대기 상태였던 해당 프로세스는 입출력 작업이 완료되는 등 실행 가능한 상태가 되면 다시 준비 상태가 되어 CPU 할당을 기다림

### 종료 상태

- 프로세스가 종료된 상태
- 프로세스가 종료되면 운영체제는 PCB와 프로세스가 사용한 메모리를 정리함

## 멀티프로세스와 멀티스레드

### 멀티프로세스

- 동시에 여러 프로세스가 실행되는 것
- 각기 다른 프로세스들이 기본적으로 자원을 공유하지 않고, 독립적으로 실행됨 -> 한 프로세스의 실행 과정에서 문제 발생하더라도 다른 프로세스에 영향 x

### 멀티스레드

![Image](https://github.com/user-attachments/assets/3540e9a4-5647-430e-b78e-a7209eb1e735)

- 프로세스를 동시에 실행하는 여러 스레드
- 하나의 스레드는 스레드를 식별할 수 있는 고유 정보인 스레드 ID, 프로그램 카운터, 레지스터 값, 스택 등으로 구성됨
- 스레드마다 각각의 프로그램 카운터 값과 스택을 가지고 있기 때문에 스레드마다 다음에 실행할 주소를 가질 수 있고, 연산 과정의 임시 저장 값을 가질 수 있음

### 멀티프로세스 vs 멀티스레드

- 가장 큰 차이점은 자원의 공유 여부임
- 서로 다른 프로세스들은 기본적으로 자원을 공유하지 않기 때문에 독립적으로 실행됨 -> 한 프로세스에 문제 생겨도 다른 프로세스에 지정 없거나 적음
- 같은 프로세스를 실행하는 여러 스레드들은 프로세스의 자원을 공유함 -> 한 스레드에 생긴 문제가 프로세스 전체의 문제가 될 수 있음
  - 코드/데이터/힙 영역, 열린 파일 등을 공유하기 때문에 쉽게 협력하고 통신할 수 있음

## 프로세스 간 통신

![Image](https://github.com/user-attachments/assets/a750779f-2fcc-43fb-a006-1d412df515cd)

- IPC(Inter-Process Communication): 프로세스 간에도 자원을 공유하고 데이터를 주고 받을 수 있는 방법
- 프로세스 간 통신이 이루어지는 방식: 공유 메모리, 메시지 전달

### 공유 메모리

- 데이터를 주고받는 프로세스가 공통적으로 사용할 메모리 영역을 두는 방식
- 공유 메모리라는 특별한 메모리 공간을 할당하여 프로세스가 해당 메모리 공간을 공유하여 읽고 쓸 수 있도록 함
- 공유 메모리 영역을 확보하는 시스템 콜을 기반으로 수행될 수도 있고, 간단하게 프로세스가 공유하는 변수나 파일을 활용할 수도 있음
- 각 프로세스가 마치 자신의 메모리 영역을 읽고 쓰는 것처럼 통신함
- 프로세스가 주고받는 데이터가 커널 영역을 거치지 않는 경우가 많음
- 각 프로세스가 단순히 각자의 메모리 영역을 읽고 쓰는 것일 뿐이므로 메시지 전달 방식보다 통신 속도가 빠름
- 레이스 컨디션: 메모리 영역을 동시에 읽고 쓸 경우, 데이터의 일관성이 훼손될 수 있음

### 메시지 전달

- 프로세스 간에 주고받을 데이터를 커널을 거쳐 메시지의 형태로 주고받는 방식
- 메시지를 보내고 받는 시스템콜이 명확하게 정해져있음
  - send(): 메시지를 보내는 시스템 콜
  - recv(): 메시지를 받는 시스템 콜
- 커널의 도움을 받으므로 레이스 컨디션, 동기화 등의 문제를 고려하는 일이 상대적으로 적음
- 데이터가 커널을 통해 송수신 되므로 공유 메모리 기반보다 통신 속도가 느림
- 대표적인 수단: 파이프, 시그널, 소켓, 원격 프로시저 호출(RPC) 등이 있음

> RPC가 뭐지

#### 파이프

![Image](https://github.com/user-attachments/assets/b4d1d7ae-4be7-4ffb-b58f-c65e713088fe)

- 단방향 프로세스 간의 통신 도구
- 양방향 통신을 수행할 경우, 읽기용 파이프와 쓰기용 파이프 2개 필요
- 익명 파이프: 양방향 통신을 지원하지 않고, 부모 프로세스와 자식 프로세스 간에만 통신 가능
- 지명 파이프: 양방향 통신을 지원하며, 임의의 프로세스 간에도 통신 가능

#### 시그널

![Image](https://github.com/user-attachments/assets/1dbd172c-b26c-4766-868c-21621ff96cdf)

- 프로세스에게 특정 이벤트가 발생했음을 알리는 비동기적 신호
- 시그널 자체는 IPC만을 위한 개념이 아니라 '시그널을 적절히 활용해 IPC를 수행할 수 있다' 임
- 리눅스 운영체제의 대표적인 시그널 예시
  - 대부분 인터럽트 관련 시그널이지만, 사용자 정의 시그널도 가능
    | 시그널 | 설명 | 기본 동작 |
    |-------|------|---------|
    | SIGCHLD | 자식 프로세스 종료 | 무시 |
    | SIGILL | 허용하지 않은 명령어 실행 | 코어 덤프 생성 후 종료 |
    | SIGINT | 키보드 인터럽트(Ctrl + C) | 종료 |
    | SIGKILL | 프로세스 종료(핸들러 재정의 불가능) | 종료 |
    | SIGSEGV | 잘못된 메모리 접근 | 코어 덤프 생성 후 종료 |
    | SIGTERM | 프로세스 종료(핸들러 재정의 가능) | 종료 |
    | SIGUSR1 | 사용자 정의 시그널 | 종료 |
    | SIGUSR2 | | 종료 |
- 프로세스는 시그널이 발생하면 인터럽트 처리 과정과 유사하게 하던일을 잠시 중단하고, 시그널 처리를 위한 **시그널 핸들러**를 실행한 뒤 실행을 재개함
- 프로세스는 직접 특정 시그널을 발생시킬 수 있고, 일부 시그널 핸들러를 (재)정의 할 수도 있음
- 시그널을 이용하는 방법은 직접적으로 메시지를 주고받지는 않지만, 비동기적으로 원하는 동작을 수행할 수 있는 좋은 수단임
- 코어 덤프: 주로 비정상적으로 종료하는 경우에 생성되는 파일로, 프로그램이 특정 시점에 작업하던 메모리 상태가 기록됨

  ```
  $ coredumpctl info
  PID: 7990 (python3)
  UID: 1000 (minchu1)
  GID: 1000 (minchu1)
  Signal: 11 (SEGV)
  Timestamp: Mon 2024-02-26 15:40:36 KST (1min 1s ago)
  Command Line: python3 coredumped.py
  Executable: /usr/bin/python3.8
  Control Group: /user.slice/user-1000.slice/session-33.scope
  Unit: session-33.scope
  Slice: user-1000.slice
  Session: 33
  Owner UID: 1000 (minchu1)
  Boot ID: abcdeabcde1234512345abcde12345ab
  Machine ID: abcde12345abcde12345abcde12345ab
  Hostname: homeserver
  Storage: /var/lib/systemd/coredump/core.python3.1000.abcdeabc...2345000000000000.123
  Message: Process 7990 (python3) of user 1000 dumped core.
    Stack trace of thread 7990:
    #0 0x00007f220dcb3f45 n/a (\_ctypes.cpython-38-x86_64-linux-gnu.so + 0x9f45)
    #1 0x00007f220e8efff5 n/a (libffi.so.7 + 0x6ff5)
    #2 0x00007f220e8ef40a n/a (libffi.so.7 + 0x640a)
    ...
    #15 0x0000000000673abb n/a (python3.8 + 0x273abb)
    #16 0x0000000000673b61 n/a (python3.8 + 0x273b61)
    #17 0x00000000006747e7 PyRun_SimpleFileExFlags (python3.8 + 0x2747e7)
    #18 0x000000000006b4072 Py_RunMain (python3.8 + 0x2b4072)
    #19 0x000000000006b43fd Py_BytesMain (python3.8 + 0x2b43fd)
    #20 0x00007f220e717083 \_\_libc_start_main (libc.so.6 + 0x24083)
    #21 0x000000000005da67e \_start (python3.8 + 0x1da67e)
  ```

> 재정의 가능/불가능한 시그널에는 뭐가 있을까?
> 특정 프로세스로 시그널을 어떻게 보낼 수 있는걸까?

#### 이 외의 방법들

- 이외에도 원격 프로시저 호출(RPC)나 네트워크 소켓을 통해 IPC를 수행할 수도 있음

**RPC**

- 원격 코드를 실행하는 IPC 기술
- 한 프로세스 내의 특정 코드 실행이 로컬 프로시저 호출이라면, 다른 프로세스의 원격 코드 실행이 원격 프로시저 호출인 셈
- RPC를 통해 프로그래밍 언어나 플랫폼과 무관하게 성능 저하를 최소화하고, 메시지 송수신이 가능하기 때문에 대규모 트래픽 처리 환경, 특히 서버 간 통신 환경에서 사용되는 경우가 많음

> RPC 자체가 뭔지 잘 이해가 안감

# 3. 동기화와 교착 상태

<img width="521" alt="Image" src="https://github.com/user-attachments/assets/192c45d0-56e8-4ecf-b32f-0f3ca2c2ce76" />

- 공유 자원: 프로세스 혹은 스레드가 공유하는 자원으로, 메모리나 파일이 될 수도 있고, 전역 변수나 입출력 장치가 될 수도 있음
- 임계 구역: 공유 자원에 접근하는 코드 중 동시에 실행했을 때 문제가 발생할 수 있는 코드
  - 즉, 동시에 실행되는 프로세스나 스레드가 동시에 임계 구역에 진입하여 실행되면 문제가 발생할 수 있음
- 레이스 컨디션: 프로세스 혹은 스레드가 동시에 임계 구역의 코드를 실행하여 문제가 발생하는 상황
  - 레이스 컨디션이 발생하면 자원의 일관성이 손상될 수 있기 때문에 2개 이상의 프로세스 혹은 스레드가 임계 영역에 진입하고자 한다면 둘 중 하나는 대기해야함
- 동기화: 레이스 컨디션을 방지하면서 임계 구역을 관리하기 위한 방법
  - 실행 순서 제어: 프로세스 및 스레드를 올바른 순서로 실행하기
  - 상호 배제: 동시에 접근해서는 안 되는 자원에 하나의 프로세스 및 스레드만 접근하기

## 프로세스 간 통신에서 임계 구역

- 프로세스 공유 메모리에 무언가를 쓰기 전에 메모리를 읽으려 할 경우 아직 쓰이지 않은 메모리이기 때문에 문제가 될 수 있음

- 즉, 프로세스 A의 '공유 메모리 공간에 데이터를 쓰는 코드'와 프로세스 B의 '공유 메모리 공간을 읽는 코드'는 임계 구역임
  <img width="500" alt="Image" src="https://github.com/user-attachments/assets/9e0bb504-b6fa-4752-ba45-2e131583900a" />
  - 실행 순서 제어를 위한 동기화가 필요함

## 스레드 간 통신에서 임계 구역

- 동시에 파일을 수정하는 스레드의 경우, 스레드 A와 B가 동시에 수행될 경우, 스레드 A의 작업 내역이 반영되지 않을 수 있음
  <img width="568" alt="Image" src="https://github.com/user-attachments/assets/3ebd50f9-58b5-49c6-846d-442e562be709" />

  - 각 스레드가 파일을 수정하는 코드는 임계 구역이 되며 상호 배제를 위한 동기화가 필요함

- 혹은 실행 도중에 문맥 교환이 발생하면 스레드 A의 작업이 반영되지 않을 수 있음
  <img width="571" alt="Image" src="https://github.com/user-attachments/assets/b2da367a-93d1-42ce-b05b-f075be95551c" />

  - 각 스레드가 파일을 수정하는 코드는 임계 구역이 되며 상호 배제를 위한 동기화가 필요함

## 동기화 기법

- 실행 순서 제어와 상호 배제를 보장하기 위한 동기화 기법 어떤 것이 있는지 알아보자

### 뮤텍스 락

- 뮤텍스 락: 동시에 접근해서는 안되는 자원에 동시 접근이 불가능하도록 상호 배제를 보장하는 동기화 도구 즉, 상호배제를 위한 락
- 원리: 임계 구역에 접근하고자 한다면 반드시 락(lock)을 획득해야 하고, 임계 구역에서의 작업이 끝났다면 락을 해제해야 함
- 작동 원리
  - 프로세스 및 스레드가 공유하는 변수(lock)와 2개의 함수(acquire, release)로 구현됨
  - acquire(): 락을 획득하기 위한 함수로, 특정 락에 대해 한 번만 호출이 가능한 함수
  - release(): 획득한 락을 해제하기 위한 함수
  - 임계 구역에 진입하려면 lock.acquire()을 호출해야하고, 이후 다른 프로세스 및 스레드가 lock.acquire()를 호출해도 락을 획득할 수 없고 락이 해제될 때 까지 기다려야 함
  - 임게 구역의 작업이 끝나면 락을 해제하기 위해 lock.release()를 호출하며, 대기하는 프로세스 혹은 스레드가 비로소 락을 획득하고 임계 구역에 진입하게 됨
  ```
  lock.acquire()
  // 임계 구역
  // lock.release()
  ```
- 예시: 공유 자원 1개, P1과 P2가 공유 자원에 접근하려는 프로세스, P1과 P2 순서로 임계 구역에 접근하는 상황
  <img width="559" alt="Image" src="https://github.com/user-attachments/assets/eb110672-45f1-4525-bd72-d3fd82f11933" />

### 세마포

- 세마포: 공유 자원이 여러 개 있는 상황에서도 동기화 해주는 도구
  - 뮤텍스 락은 공유 자원이 하나일 때만 고려하는 동기화 도구
- 작동 원리
  - 변수 S: 사용 가능한 공유 자원의 개수를 나타내는 변수
  - wait(): 임계 구역 진입 전 호출하는 함수
  - signal: 임계 구역 진입 후 호출하는 함수
  ```
  wait()
  // 임계 구역
  signal()
  ```
- 종류:
  - 이진 세마포: S가 0과 1의 값을 가지는 세마포, 사실상 뮤텍스 락과 유사하게 동작함
  - 카운팅 세마포: 공유 자원이 여러 개일 때 사용할 수 있는 세마포
  - 보통 세마포는 카운팅 세마포를 의미하는 경우가 많음

#### wait 함수

- wait 함수 호출 시
  1. '사용 가능한 공유 자원의 개수'를 나타내는 변수 S를 1 감소
  2. 변수 S의 값이 0보다 작은지 여부 확인하고, 0 이상이면 wait()를 호출한 프로세스 및 스레드는 임계 구역에 진입함.
  3. 0 미만이면 wait()를 호출한 프로세스 및 스레드는 대기 상태로 전환되어 임계 구역에 진입할 수 없게 됨
  ```
  wait() {
    S--;   // 1
    if(S < 0) { // 2
      sleep(); // 3
    }
  }
  ```

#### signal 함수

- signal은 함수 호출 시
  1. '사용 가능한 공유 자원의 개수'를 나타내는 변수 S를 1 증가
  2. 변수 S의 값이 0 이하인지를 확인하고 0이하이면 임계 구역에 진입하기 위해 대기하는 프로세스 또는 스레드가 존재하는 의미이므로
  3. 대기 상태로 접어든 프로세스 중 하나를 준비 상태로 전환함
  ```
  signal() {
    S++
    if(S <= 0) {
      wakeup(p)
    }
  }
  ```

#### 예시

- 공유 자원 2개, 접근 하려는 프로세스 3개(P1, P2, P3), P1 -> P2 -> P3 순서로 임계 구역 접근하는 상황

<img width="560" alt="Image" src="https://github.com/user-attachments/assets/7ee6cd9d-b671-4ae1-a046-2e3e437c1e7d" />

### 조건 변수와 모니터

#### 조건 변수

- 조건 변수: 실행 순서 제어를 위한 동기화 도구로, 특정 조건 하에 프로세스를 실행/일시 중단함으로써 프로세스나 스레드의 실행 순서를 제어할 수 있음
- 작동 원리
  - wait(): 호출한 프로세스 및 스레드의 상태를 대기 상태로 전환하는 함수
  - signal(): wait()으로 일시 중지된 프로세스 및 스레드의 실행을 재개하는 함수
  - 즉, 아직 특정 프로세스가 실행될 조건이 되지 않았을 때는 wait()을 통해 실행을 중단하고, 특정 프로세스가 실행될 조건이 충족됐을 때 signal()을 통해 실행을 재개함
- 예시:
  - cv라는 조건 변수가 있고, 프로세스 P1의 실행 도중에 조건 변수 cv에 대해 wait() 함수를 호출했다고 가정하자. 이 프로세스는 다른 스레드가 cv.signal()을 호출하기 전까지 대기 상태임
    <img width="242" alt="Image" src="https://github.com/user-attachments/assets/ccdc5614-65ca-4cfa-bbbc-b8d7575d3f68" />

> 182p. 예제코드 헷갈림, t1에서 cond.await()하고 t2에서 lock.lock하고 있는데 t1에서 lock.unlock 실행되지 않은 상태 아닌가? 어떻게 가능한거지?

#### 모니터

<img width="569" alt="Image" src="https://github.com/user-attachments/assets/9c1a61a9-7d07-4816-a626-0205379a4358" />

- 모니터: 공유 자원과 그 공유 자원을 다루는 함수로 구성된 동기화 도구로, 상호 배제를 위한 동기화뿐만 아니라 실행 순서 제어를 위한 동기화까지 가능함
- 작동 원리:
  - 프로세스 및 스레드는 공유 자원에 접근하기 위해 반드시 정해진 공유 자원 연산을 통해 모니터 내로 진입해야 함
  - 모니터 안에 진입하여 실행되는 프로세스 및 스레드는 항상 하나여야 함
  - 이미 모니터 내로 진입하여 실행 중인 프로세스 및 스레드가 있다면 큐에서 대기해야 함

#### 조건 변수와 모니터를 함께 활용

- 조건 변수와 모니터를 함께 활용하면 실행 순서 제어를 위한 동기화도 구현 할 수 잇음
- 예시: 동시에 실행되는 프로세스 A, B 중 반드시 A가 먼저 실행되고, 다음으로 B가 실행돼야 한다는 조건
  - 프로세스 B는 모니터 내에서 실행되기 전 프로세스 A의 실행이 끝났는지 검사 후 모니터 내로 진입하여 실행됨
    <img width="572" alt="Image" src="https://github.com/user-attachments/assets/2b90d27a-52aa-4550-9970-4a8127c8db7a" />
  - 만약 프로세스 B가 프로세스 A보다 먼저 모니터 내로 진입했을 경우, 특정 조건변수에 대해 cv.wait()를 호출해서 프로세스 B를 대기 상태로 접어들게 함
    <img width="535" alt="Image" src="https://github.com/user-attachments/assets/b7efe8ce-ae78-42d4-a7d0-962ca26982e3" />
  - 프로세스 B가 대기하고 있는 사이 프로세스 A가 모니터 내로 진입하여 실행될 수 있고, 실행 이후 cv.signal()을 호출하여 대기 상태에 있던 프로세스 B를 모니터 안으로 재진입시킬 수 있음
    <img width="575" alt="Image" src="https://github.com/user-attachments/assets/211efda9-b476-4cf8-8504-4fa00525ab34" />
  - 즉, 반드시 프로세스 A -> 프로세스 B 순서로 실행되므로 실행 순서 제어를 위한 동기화가 이루어짐

> 모니터랑 위의 세마포/뮤텍스 락과는 뭐가 다른거지??

### 스레드 안전

- 스레드 안전: 멀티스레드 환경에서 어떤 변수나 함수, 객체에 동시 접근이 이루어져도 실행에 문제가 없는 상태
  - 레이스 컨디션이 발생했다면 스레드 안전하지 않은 것을 의미
- 예시
  - 자바 Vector의 add 메서드 코드 내부가 모니터 기반의 동기화를 제공하는 synchronized 키워드로 구현돼있음 -> 여러 스레드가 동시에 실행돼도 안전함
  - 자바 ArrayList의 add 메서드는 코드 내부에 synchronized 키워드가 없음 -> 스레드 안전성이 보장되지 않기 때문에 여러 스레드로 동시에 실행하면 레이스 컨디션 발생할 수 있음

## 교착 상태

<img width="276" alt="Image" src="https://github.com/user-attachments/assets/ba7e5e6d-0e02-480d-875b-9aef5d39a203" />

- 프로세스를 실행하기 위해서는 자원이 필요함
- 2개 이상의 프로세스가 각자 가지고 있는 자원을 무작정 기다리면 어떤 프로세스도 진행할 수 없는 교착 상태가 발생할 수 있음
- 교착 상태: 일어나지 않을 사건을 기다리며 프로세스의 진행이 멈춰 버리는 현상
- 프로세스 A는 자원 X를 점유한 채 프로세스 B가 점유하고 있는 자원 Y의 사용이 끝나기를 기다리고, 프로세스 B는 자원 Y를 점유한 채 프로세스 A가 점유한 자원 X의 사용이 끝나기를 기다리면 결국 두 프로세스는 서로가 가진 자원을 기다리다가 프로세스를 실행하지 못할 수 있음 즉, 교착 상태 발생

### 교착 상태의 발생 조건

- 교착 상태가 발생하는 상황의 4가지 필요 조건: 상호 배제 ,점유와 대기, 비선점, 원형 대기
- 4가지 조건이 모두 만족할 때 교착 상태가 발생할 가능성이 생김
- 하나라도 만족하지 않는다면 교착 상태는 발생하지 않음

#### 1. 상호 배제

- 자원을 한 번에 하나의 프로세스만 사용 가능한 상황

#### 2. 점유와 대기

- 한 프로세스가 어떤 자원을 할당받은 상태에서 다른 자원을 할당받기를 기다리는 상황

#### 3. 비선점

- 어떤 프로세스도 다른 프로세스의 자원을 강제로 빼앗지 못하는 상황

#### 4. 원형 대기

<img width="575" alt="Image" src="https://github.com/user-attachments/assets/fee4a8f6-e51c-47b5-93ac-5f988841c2f3" />

- 프로세스와 프로세스가 요청한 자원이 원의 형태를 이루는 경우

### 교착 상태의 해결 방법

- 예방: 운영체제는 애초에 교착 상태의 발생 조건에 부합하지 않도록 자원을 분배하는 방식으로 교착 상태를 예방할 수 있음
- 회피: 교착 상태가 발생하지 않을 정도로 자원을 할당하다가 교착 상태의 위험이 있을 때 자원을 할당하지 않는 방식으로 교착 상태를 회피
- 검출한 후 회복: 자원을 제약 없이 할당하다가 교착 상태를 검출한 후 회복할 수도 있음

#### 1. 교착 상태 예방

- 교착 상태를 발생시키는 4가지 필요 조건 중 하나를 충족하지 못하게 하는 방법
- 예시

  - 한 프로세스에 필요한 자원들을 몰아주고, 그 다음에 다른 프로세스에 필요한 자원을 몰아주기 -> 점유와 대기 조건 만족 x
  - 할당 가능한 모든 자원에 번호를 매기고 오름차순으로 할당 -> 원형 대기 조건 x
    <img width="569" alt="Image" src="https://github.com/user-attachments/assets/9beae10a-9a9e-42bd-b1b1-2e7a0e4b0587" />

  > 이게 무슨 소리지?

#### 2. 교착 상태 회피

- 교착 상태가 발생하지 않을 정도로만 자원을 할당하는 방법
- 예시: 은행원 알고리즘

#### 3. 교착 상태 검출 후 회복

- 교착 상태의 발생을 인정하고 처리하는 사후 조치
- 운영체제는 프로세스가 자원을 요구할 때마다 그때 그때 자원을 할당하고 주기적으로 교착 상태의 발생 여부를 검사함
- 교착 상태가 검출되면 프로세스를 자원 선점을 통해 회복시키거나, 교착 상태에 놓인 프로세스를 강제 종료함으로써 회복시킴
- 자원 선점을 통한 회복: 교착 상태가 해결될 때까지 다른 프로세스로부터 강제로 자원을 빼앗아 한 프로세스에 몰아서 할당하는 것

# 4. CPU 스케줄링

- 운영체제는 다양한 프로세스와 스레드에 CPU의 사용을 배분함으로써 CPU 자원을 관리함
- CPU 스케줄링: CPU 배분 방법
- CPU 스케줄러: CPU 스케줄링 알고리즘을 결정하고 수행하는 운영체제의 일부분

## 우선순위

- 모든 프로세스는 CPU의 자원을 필요로 하기 때문에 운영체제는 공정하고 합리적인 방법으로 CPU의 자원을 프로세스에 할당해야 함
- 프로세스들은 우선순위가 다르기 때문에 단순히 돌아가면서 CPU를 배분하는 것은 공정하지 않음
- 운영체제는 프로세스별 우선순위를 판단하여 PCB에 명시하고, 우선순위가 높은 프로세스에는 CPU 자원을 더 빨리, 더 많이 할당함
- 사용자가 일부 프로세스의 우선순위를 직접 높일 수도 있음
- ps 명령어를 통해 프로세스의 우선순위를 확인할 수 있음

### 우선순위 할당 방식

- CPU 활용률: 전체 CPU의 가동 시간 중 작업을 처리하는 시간의 비율
- 운영체제는 높은 CPU 활용률을 유지하기 위해 기본적으로 입출력 작업이 많은 프로세스의 우선순위를 높게 유지함
- 대부분의 프로세스들은 CPU와 입출력장치를 모두 사용해 실행과 대기 상태를 오가며 실행됨
- CPU 버스트: 프로세스가 CPU를 이용하는 작업
- 입출력 버스트: 입출력장치를 기다리는 작업
- 프로세스마다 입출력장치를 이용하는 시간과 CPU를 이용하는 시간의 양에는 차이가 있음
  - 입출력 집중 프로세스(입출력 작업이 많은 프로세스): 비디오 재생, 디스크 백업
  - CPU 집중 프로세스(CPU 작업이 많은 프로세스): 복잡한 수학 연산, 그래픽 처리 작업

#### 입출력 집중 프로세스와 CPU 집중 프로세스

- 입출력 집중 프로세스는 입출력을 위한 대기 상태에 더 많이 머무르지만, CPU 집중 프로세스는 실행 상태에 더 많이 머무름
- 입출력 집중 프로세스를 가능한 빨리 실행시켜 끊임없이 입출력장치를 작동시킨 다음, CPU 집중 프로세스에 집중적으로 CPU를 할당하는 것이 합리적
- 이렇듯 상황에 맞게 프로세스마다 우선순위를 부여해 CPU를 배분하는 것이 효율적임

### 스케줄링 큐

<img width="352" alt="Image" src="https://github.com/user-attachments/assets/acb60d40-651a-44b3-a8d2-226f6cd831fa" />

- 운영체제는 프로세스들에게 '자원을 이용하고 싶으면 줄을 서서 기다릴 것'을 요구함
- 이 줄은 스케줄링 큐를 통해 구현되며 PCB를 큐에 삽입하여 줄 세움
- 운영체제는 큐에 삽입된 순서대로 실행하되, 우선순위가 높은 프로세스부터 먼저 실행함. 실행되는 프로세스가 할당받은 시간을 모두 소모할 경우(타이머 인터럽트 받을 경우) 준비 큐로 다시 이동하고, 실행 도중 입출력 작업을 수행하는 등 대기상태로 접어들어야 할 경우 대기 큐로 이동함

<img width="470" alt="Image" src="https://github.com/user-attachments/assets/9ea1bad6-45dc-45ae-959c-5ff3afc715a5" />

#### 준비 큐

- CPU를 이용하고 싶은 프로세스의 PCB가 서는 줄
- CPU의 차례를 기다림

#### 대기 큐

<img width="566" alt="Image" src="https://github.com/user-attachments/assets/510110ca-7c14-44b9-ba33-d7cc12d16428" />

- 대기 상태에 접어든 프로세스의 PCB가 서는 줄
- 입출력 작업을 수행하게 되면 대기큐에서 대기 상태로 입출력 완료 인터럽트를 기다리게 됨
- 같은 입출력장치를 요구한 프로세스들은 같은 대기큐에서 기다림
- 입출력이 완료되어 완료 인터럽트가 발생하면 운영체제는 대기 큐에서 작업이 완료된 PCB를 찾고, 이 PCB를 준비 상태로 변경한 뒤 대기 큐에서 제거

## 선점형 스케줄링과 비선점형 스케줄링

- 스케줄링은 기본적으로 프로세스의 실행이 끝나면 이뤄지지만 프로세스가 종료되지 않았음에도 실행 도중 스케줄링이 수행될 때도 있음

  1. 실행 상태에서 입출력 작업을 위해 대기 상태로 전환될 때
  2. 실행 상태에서 타이머 인터럽트가 발생해 준비 상탤 변경될 때

- 선점형 스케줄링은 1,2 상황에서 모두 발생 가능
- 비선점형 스케줄링은 1 상황에서만 발생 가능

### 선점형 스케줄링

- 운영체제가 프로세스로부터 CPU 자원을 강제로 빼앗아 다른 프로세스에 할당할 수 있는 스케줄링
- 타이머 인터럽트 기반 스케줄링: 선점형 스케줄링의 일종, 프로세스마다 정해진 시간만큼 CPU를 이용하고 운영체제가 CPU 자원을 빼앗아 다음 프로세스에게 할당하는 방식이기 때문
- 장점: 더 급한 프로세스가 끼어들어 CPU를 사용할 수 있기 때문에 한 프로세스의 독점을 막고 여러 프로세스에 골고루 CPU 자원을 배분할 수 있음
- 단점: 문맥 교환 과정에서 오버헤드가 발생할 수 있음

### 비선점형 스케줄링

- 어떤 프로세스가 CPU를 사용하고 있을 때 그 프로세스가 종료되거나 스스로 대기 상태에 들어가기 전까지 다른 프로세스가 끼어들 수 없는 스케줄링 방식
- 장점: 문맥 교환 횟수가 적어서 상대적으로 오버헤드 발생이 적음
- 단점: 어떤 프로세스가 CPU를 사용중이라면 당장 CPU를 사용해야하는 프로세스라도 무작정 기다리는 수밖에 없음

## CPU 스케줄링 알고리즘

- CPU 스케줄링 알고리즘: 운영체제가 프로세스에 CPU를 배분하는 방법
- 각 스케줄링 알고리즘들의 작동 방식과 장단점을 이해하자

### 1. 선입 선처리 스케줄링

<img width="568" alt="Image" src="https://github.com/user-attachments/assets/9a4956c4-cf2c-47fb-a73d-118c9ff82ce6" />

- 단순히 준비 큐에 삽입된 순서대로 먼저 CPU를 요청한 프로세스부터 CPU를 할당하는 스케줄링 방식
- 단점: 프로세스들이 기다리는 시간이 매우 길어질 수 있음
- 호위 효과: 먼저 삽입된 프로세스의 오랜 실행 시간으로 인해 나중에 삽입된 프로세스의 실행이 지연되는 문제

### 2. 최단 작업 우선 스케줄링

- 준비 큐에 삽입된 프로세스 중 CPU를 이용하는 시간의 길이가 가장 짧은 프로세스부터 먼저 실행하는 스케줄링 방식
- 기본적으로 비선점형 스케줄링 알고리즘이지만 '최소 잔여 시간 우선 스케줄링' 처럼 선점형으로 구현될 수도 있음

> CPU를 이용하는 시간의 길이가 짧다는건 어떻게 미리 알 수 있을까?

### 3. 라운드 로빈 스케줄링

- 선입 선처리 스케줄링에 타임 슬라이스라는 개념이 더해진 스케줄링 방식
- 타임 슬라이스: 프로세스가 CPU를 사용하도록 정해진 시간
- 즉, 큐에 삽입된 순서로 프로세스들이 CPU를 이용하되, 정해진 타임 슬라이스만큼만 CPU를 이용하는 선점형 스케줄링 방식
- 프로세스가 정해진 시간을 모두 사용하고도 완료되지 않으면 문맥 교환이 발생해 다시 큐의 맨 뒤에 삽입됨

### 4. 최소 잔여 시간 우선 스케줄링

- 최단 작업 우선 스케줄링 방식 + 라운드 로빈 스케줄링 방식
- 프로세스가 정해진 타임 슬라이스만큼 CPU를 이용하되, 남아 있는 작업 시간이 가장 적은 프로세스를 먼저 실행

### 5. 우선순위 스케줄링

- 프로세스에 우선순위를 부여하고, 가장 높은 우선순위를 가진 프로세스부터 실행하는 스케줄링 방식
- 아사 현상: 우선순위가 낮은 프로세스는 계속해서 실행이 연기되는 현상
- 에이징: 아사 현상을 방지하기 위한 기법, 오랫동안 대기한 프로세스의 우선순위를 점차 높이는 방식

### 6. 다단계 큐 스케줄링

<img width="569" alt="Image" src="https://github.com/user-attachments/assets/0b3cfcf0-a7af-4a6d-a5ba-d44668f636a4" />

- 우선순위 스케줄링의 발전된 형태, 우선순위별로 여러 개의 준비큐를 사용하는 스케줄링 방식
- 우선순위가 가장 높은 큐에 있는 프로세스 먼저 처리 -> 그 다음 우선순위가 높은 큐에 있는 프로세스 처리 -> ...
- 단점: 프로세스들이 큐 사이를 이동할 수 없어서 우선순위가 낮은 프로세스의 작업이 계속해서 연기될 수 있음

### 7. 다단계 피드백 큐 스케줄링

<img width="572" alt="Image" src="https://github.com/user-attachments/assets/4f048644-5619-4da6-897d-dee6e1784482" />

- 다단계 큐 스케줄링 + 프로세스들이 큐 사이를 이동할 수 있음
- 새롭게 진입하는 프로세스는 우선순위가 가장 높은 우선순위 큐에 삽입되고 타임 슬라이스 동안 실행됨 -> 실행이 끝나지 않으면 다음 우선순위 큐에 삽입되어 실행됨
- 즉, 오래 CPU를 사용해야 하는 프로세스의 우선순위가 점차 낮아지게 됨
- 자연스럽게 비교적 CPU를 오래 사용해야 하는 CPU 집중 프로세스들은 우선순위가 낮아지고, 비교적 CPU를 적게 사용하는 입출력 집중 프로세스들은 우선순위가 높은 큐에서 실행이 끝나게 됨
- 에이징 기법 적용 가능: 아사 현상을 예방하기 위해 낮은 우선순위 큐에서 오래 기다리고 있는 프로세스들을 높은 우선순위 큐로 이동 -> 비교적 CPU를 오래 사용하지 못한 프로세스의 우선순위가 높아짐

## 리눅스 CPU 스케줄링

- 리눅스에서는 상황에 따라 다양한 스케줄링 알고리즘이 사용될 수 있음
- 스케줄링 정책: 새로운 프로세스를 언제 어떻게 선택하여 실행할지를 결정하기 위한 규칙 집합

| 스케줄링 정책 | 적용 상황                                                                      |
| ------------- | ------------------------------------------------------------------------------ |
| SCHED_FIFO    | 실시간성 프로세스에 적용되는 정책<br>(매우 높은 우선순위를 할당함)             |
| SCHED_RR      | 실시간성 프로세스에 적용되는 정책                                              |
| SCHED_NORMAL  | 일반적인 프로세스에 적용되는 정책                                              |
| SCHED_BATCH   | 일반적인 프로세스만큼 자주 선점하지 않는 배치 작업에 적용되는 정책             |
| SCHED_IDLE    | 우선순위가 매우 낮은 프로세스에 적용되는 정책<br>(매우 낮은 우선순위를 할당함) |

### SCHED_FIFO, SCHED_RR

- FIFO(선입 선출), RR(라운드 로빈)
- RT(Real Time) 스케줄러에 의해 이뤄지는 스케줄링
- 실시간성이 강조된 프로세스에 적용되는 스케줄링 정책

### SCHED_NORMAL

- 일반적인 프로세스에 적용되는 스케줄링 정책
- CFS라는 CPU 스케줄러에 의해 스케줄링이 이뤄짐
- CFS: 프로세스에 대해 '완전히 공평한 CPU 시간 배분'을 지향하는 CPU 스케줄러
- 리눅스에서는 프로세스마다 가상 실행 시간(vruntime) 정보를 유지하는데, CFS는 이 vruntime이 가장 작은 프로세스부터 스케줄링함
- vruntime: 프로세스의 가중치를 고려한 가상의 실행 시간, 프로세스의 우선순위가 높아질수록 가중치가 높아지고 가중치가 높을수록 vruntime이 줄어들기 때문에 먼저 스케줄링될 확률이 높음

  <img width="344" alt="Image" src="https://github.com/user-attachments/assets/69d9bdff-0bca-4077-b710-92e798c3befb" />

  > CPU를 할당받아 실행된 시간은 뭘로 계산하는거지?

- CFS로 스케줄링되는 프로세스들의 타임 슬라이스는 프로세스의 가중치에 따라 결정됨. 프로세스 우선순위가 높을수록 가중치도 높아지고 가중치가 높아지면 타임 슬라이스도 크게 할당받게됨

<img width="523" alt="Image" src="https://github.com/user-attachments/assets/eb79b3e7-6bf7-4a5a-892e-ca4ad27278f9" />

- vruntime과 가중치는 리눅스에서 `proc/<PID>/sched` 라는 파일을 출력하는 명령어를 통해 확인할 수 있음
  <img width="262" alt="Image" src="https://github.com/user-attachments/assets/e0dbd8fc-06e0-46c1-9b53-45f5192aaf69" />
- 커널(CFS 스케줄러)은 수많은 프로세스 중 vruntime이 가장 작은 프로세스를 빠르게 선별하기 위해 Red Black 트리라는 자료구조를 활용함
  <img width="383" alt="Image" src="https://github.com/user-attachments/assets/8d20f78e-7543-4e68-aa33-227a787d090d" />
  - Red Black 트리는 여러 값 중 최소값과 최대값을 빠르고 효율적으로 찾아낼 수 있는 자료구조의 일종임
